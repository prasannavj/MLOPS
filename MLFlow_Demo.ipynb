{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLFlow Demo.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VN5SmsixqCbM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b70813c2-8432-4dd2-f492-7b6eadb8b9a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 17.0 MB 18.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 77 kB 5.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 52.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 146 kB 45.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 6.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 49.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 209 kB 49.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 78 kB 3.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 54 kB 1.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.2 MB/s \n",
            "\u001b[?25h  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install mlflow --quiet\n",
        "get_ipython().system_raw(\"mlflow ui --port 5000 &\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kqY82sO_w_w3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok --quiet\n",
        "\n",
        "from pyngrok import ngrok\n",
        "from getpass import getpass\n",
        "\n",
        "# Terminate open tunnels if exist\n",
        "ngrok.kill()\n",
        "\n",
        "# Setting the authtoken (optional)\n",
        "# Get your authtoken from https://dashboard.ngrok.com/auth\n",
        "NGROK_AUTH_TOKEN = getpass('6wNJu5rVZrQ4pmP8NBBhW_4X5JwATLCSWL6N8nBwerJ')\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "# Open an HTTPs tunnel on port 5000 for http://localhost:5000\n",
        "ngrok_tunnel = ngrok.connect(addr=\"5000\", proto=\"http\", bind_tls=True)\n",
        "print(\"MLflow Tracking UI:\", ngrok_tunnel.public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b4Uyd4BxUd4",
        "outputId": "66d8b980-355d-46e6-f9c7-74abbb1011a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |▍                               | 10 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |▉                               | 20 kB 28.4 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30 kB 33.7 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40 kB 37.7 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61 kB 34.3 MB/s eta 0:00:01\r\u001b[K     |███                             | 71 kB 35.6 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 81 kB 30.4 MB/s eta 0:00:01\r\u001b[K     |████                            | 92 kB 31.9 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 102 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 112 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 122 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 133 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 143 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 153 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |███████                         | 163 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 174 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |████████                        | 184 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 194 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 204 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 215 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 225 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 235 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 245 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 256 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 266 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 276 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 286 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 296 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 307 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 317 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 327 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 337 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 348 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 358 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 368 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 378 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 389 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 399 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 409 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 419 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 430 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 440 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 450 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 460 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 471 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 481 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 491 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 501 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 512 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 522 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 532 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 542 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 552 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 563 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 573 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 583 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 593 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 604 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 614 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 624 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 634 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 645 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 655 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 665 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 675 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 686 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 696 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 706 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 716 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 727 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 737 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 745 kB 33.4 MB/s \n",
            "\u001b[?25h  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "6wNJu5rVZrQ4pmP8NBBhW_4X5JwATLCSWL6N8nBwerJ··········\n",
            "MLflow Tracking UI: https://5159-35-236-216-240.ngrok.io\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "seed = 10 #Specify a seed value.\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = seed, stratify = y)\n"
      ],
      "metadata": {
        "id": "9eMrwyZFyO7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "current_run = mlflow.start_run()\n",
        "\n",
        "#Logging the seed value to passed to the train_test_split function. \n",
        "mlflow.log_param(\"seed\", seed)\n",
        "\n",
        "estimators = int(input(\"Estimator(s): \"))\n",
        "\n",
        "#Model definition.\n",
        "rclf = RandomForestClassifier(n_estimators = estimators)\n",
        "\n",
        "mlflow.sklearn.autolog()\n",
        "rclf.fit(X_train, y_train)\n",
        "metrics = mlflow.sklearn.eval_and_log_metrics(rclf, X_test, y_test, prefix=\"val_\")\n",
        "mlflow.end_run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvJsWeZoyO4D",
        "outputId": "b56f6c84-c53c-4551-854a-7a9588273f76"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Estimator(s): 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hello WOrld starting with experiment."
      ],
      "metadata": {
        "id": "kD_ssNcYc2RG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9o4M6I7zxnPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "import os\n",
        "from random import random, randint\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "\n",
        "print(\"MLflow Version:\", mlflow.version.VERSION)\n",
        "print(\"Pandas Version:\", pd.__version__)\n",
        "print (\"Scikit-learn Version:\", sklearn.__version__)\n",
        "print(\"Matplotlib Version:\", matplotlib.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjqFs5SDc0M_",
        "outputId": "50a9fc27-0926-4b37-e6dd-223c119ca32c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLflow Version: 1.28.0\n",
            "Pandas Version: 1.3.5\n",
            "Scikit-learn Version: 1.0.2\n",
            "Matplotlib Version: 3.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(mlflow)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u75DNhyDc0Ke",
        "outputId": "0e41b3d6-d98e-40f2-a5fb-872eb31fcd30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on package mlflow:\n",
            "\n",
            "NAME\n",
            "    mlflow\n",
            "\n",
            "DESCRIPTION\n",
            "    The ``mlflow`` module provides a high-level \"fluent\" API for starting and managing MLflow runs.\n",
            "    For example:\n",
            "    \n",
            "    .. code:: python\n",
            "    \n",
            "        import mlflow\n",
            "    \n",
            "        mlflow.start_run()\n",
            "        mlflow.log_param(\"my\", \"param\")\n",
            "        mlflow.log_metric(\"score\", 100)\n",
            "        mlflow.end_run()\n",
            "    \n",
            "    You can also use the context manager syntax like this:\n",
            "    \n",
            "    .. code:: python\n",
            "    \n",
            "        with mlflow.start_run() as run:\n",
            "            mlflow.log_param(\"my\", \"param\")\n",
            "            mlflow.log_metric(\"score\", 100)\n",
            "    \n",
            "    which automatically terminates the run at the end of the ``with`` block.\n",
            "    \n",
            "    The fluent tracking API is not currently threadsafe. Any concurrent callers to the tracking API must\n",
            "    implement mutual exclusion manually.\n",
            "    \n",
            "    For a lower level API, see the :py:mod:`mlflow.client` module.\n",
            "\n",
            "PACKAGE CONTENTS\n",
            "    _spark_autologging\n",
            "    artifacts (package)\n",
            "    azure (package)\n",
            "    azureml (package)\n",
            "    catboost\n",
            "    cli\n",
            "    client\n",
            "    data\n",
            "    db\n",
            "    deployments (package)\n",
            "    diviner\n",
            "    entities (package)\n",
            "    environment_variables\n",
            "    exceptions\n",
            "    experiments\n",
            "    fastai (package)\n",
            "    gluon (package)\n",
            "    h2o\n",
            "    keras\n",
            "    lightgbm\n",
            "    mleap\n",
            "    models (package)\n",
            "    onnx\n",
            "    paddle (package)\n",
            "    pipelines (package)\n",
            "    pmdarima\n",
            "    projects (package)\n",
            "    prophet\n",
            "    protos (package)\n",
            "    pyfunc (package)\n",
            "    pyspark (package)\n",
            "    pytorch (package)\n",
            "    rfunc (package)\n",
            "    runs\n",
            "    sagemaker (package)\n",
            "    server (package)\n",
            "    shap\n",
            "    sklearn (package)\n",
            "    spacy\n",
            "    spark\n",
            "    statsmodels\n",
            "    store (package)\n",
            "    tensorflow (package)\n",
            "    tracking (package)\n",
            "    types (package)\n",
            "    utils (package)\n",
            "    version\n",
            "    xgboost (package)\n",
            "\n",
            "CLASSES\n",
            "    builtins.object\n",
            "        mlflow.tracking.client.MlflowClient\n",
            "    mlflow.entities.run.Run(mlflow.entities._mlflow_object._MLflowObject)\n",
            "        mlflow.tracking.fluent.ActiveRun\n",
            "    \n",
            "    class ActiveRun(mlflow.entities.run.Run)\n",
            "     |  ActiveRun(run)\n",
            "     |  \n",
            "     |  Wrapper around :py:class:`mlflow.entities.Run` to enable using Python ``with`` syntax.\n",
            "     |  \n",
            "     |  Method resolution order:\n",
            "     |      ActiveRun\n",
            "     |      mlflow.entities.run.Run\n",
            "     |      mlflow.entities._mlflow_object._MLflowObject\n",
            "     |      builtins.object\n",
            "     |  \n",
            "     |  Methods defined here:\n",
            "     |  \n",
            "     |  __enter__(self)\n",
            "     |  \n",
            "     |  __exit__(self, exc_type, exc_val, exc_tb)\n",
            "     |  \n",
            "     |  __init__(self, run)\n",
            "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from mlflow.entities.run.Run:\n",
            "     |  \n",
            "     |  to_dictionary(self)\n",
            "     |  \n",
            "     |  to_proto(self)\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Class methods inherited from mlflow.entities.run.Run:\n",
            "     |  \n",
            "     |  from_proto(proto) from builtins.type\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors inherited from mlflow.entities.run.Run:\n",
            "     |  \n",
            "     |  data\n",
            "     |      The run data, including metrics, parameters, and tags.\n",
            "     |      \n",
            "     |      :rtype: :py:class:`mlflow.entities.RunData`\n",
            "     |  \n",
            "     |  info\n",
            "     |      The run metadata, such as the run id, start time, and status.\n",
            "     |      \n",
            "     |      :rtype: :py:class:`mlflow.entities.RunInfo`\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from mlflow.entities._mlflow_object._MLflowObject:\n",
            "     |  \n",
            "     |  __iter__(self)\n",
            "     |  \n",
            "     |  __repr__(self)\n",
            "     |      Return repr(self).\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Class methods inherited from mlflow.entities._mlflow_object._MLflowObject:\n",
            "     |  \n",
            "     |  from_dictionary(the_dict) from builtins.type\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors inherited from mlflow.entities._mlflow_object._MLflowObject:\n",
            "     |  \n",
            "     |  __dict__\n",
            "     |      dictionary for instance variables (if defined)\n",
            "     |  \n",
            "     |  __weakref__\n",
            "     |      list of weak references to the object (if defined)\n",
            "    \n",
            "    class MlflowClient(builtins.object)\n",
            "     |  MlflowClient(tracking_uri: Union[str, NoneType] = None, registry_uri: Union[str, NoneType] = None)\n",
            "     |  \n",
            "     |  Client of an MLflow Tracking Server that creates and manages experiments and runs, and of an\n",
            "     |  MLflow Registry Server that creates and manages registered models and model versions. It's a\n",
            "     |  thin wrapper around TrackingServiceClient and RegistryClient so there is a unified API but we\n",
            "     |  can keep the implementation of the tracking and registry clients independent from each other.\n",
            "     |  \n",
            "     |  Methods defined here:\n",
            "     |  \n",
            "     |  __init__(self, tracking_uri: Union[str, NoneType] = None, registry_uri: Union[str, NoneType] = None)\n",
            "     |      :param tracking_uri: Address of local or remote tracking server. If not provided, defaults\n",
            "     |                           to the service set by ``mlflow.tracking.set_tracking_uri``. See\n",
            "     |                           `Where Runs Get Recorded <../tracking.html#where-runs-get-recorded>`_\n",
            "     |                           for more info.\n",
            "     |      :param registry_uri: Address of local or remote model registry server. If not provided,\n",
            "     |                           defaults to the service set by ``mlflow.tracking.set_registry_uri``. If\n",
            "     |                           no such service was set, defaults to the tracking uri of the client.\n",
            "     |  \n",
            "     |  create_experiment(self, name: str, artifact_location: Union[str, NoneType] = None, tags: Union[Dict[str, Any], NoneType] = None) -> str\n",
            "     |      Create an experiment.\n",
            "     |      \n",
            "     |      :param name: The experiment name. Must be unique.\n",
            "     |      :param artifact_location: The location to store run artifacts.\n",
            "     |                                If not provided, the server picks an appropriate default.\n",
            "     |      :param tags: A dictionary of key-value pairs that are converted into\n",
            "     |                              :py:class:`mlflow.entities.ExperimentTag` objects, set as\n",
            "     |                              experiment tags upon experiment creation.\n",
            "     |      :return: String as an integer ID of the created experiment.\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Example\n",
            "     |      \n",
            "     |          from pathlib import Path\n",
            "     |          from mlflow import MlflowClient\n",
            "     |      \n",
            "     |          # Create an experiment with a name that is unique and case sensitive.\n",
            "     |          client = MlflowClient()\n",
            "     |          experiment_id = client.create_experiment(\n",
            "     |              \"Social NLP Experiments\",\n",
            "     |              artifact_location=Path.cwd().joinpath(\"mlruns\").as_uri(),\n",
            "     |              tags={\"version\": \"v1\", \"priority\": \"P1\"},\n",
            "     |          )\n",
            "     |          client.set_experiment_tag(experiment_id, \"nlp.framework\", \"Spark NLP\")\n",
            "     |      \n",
            "     |          # Fetch experiment metadata information\n",
            "     |          experiment = client.get_experiment(experiment_id)\n",
            "     |          print(\"Name: {}\".format(experiment.name))\n",
            "     |          print(\"Experiment_id: {}\".format(experiment.experiment_id))\n",
            "     |          print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
            "     |          print(\"Tags: {}\".format(experiment.tags))\n",
            "     |          print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |          :caption: Output\n",
            "     |      \n",
            "     |          Name: Social NLP Experiments\n",
            "     |          Experiment_id: 1\n",
            "     |          Artifact Location: file:///.../mlruns\n",
            "     |          Tags: {'version': 'v1', 'priority': 'P1', 'nlp.framework': 'Spark NLP'}\n",
            "     |          Lifecycle_stage: active\n",
            "     |  \n",
            "     |  create_model_version(self, name: str, source: str, run_id: Union[str, NoneType] = None, tags: Union[Dict[str, Any], NoneType] = None, run_link: Union[str, NoneType] = None, description: Union[str, NoneType] = None, await_creation_for: int = 300) -> mlflow.entities.model_registry.model_version.ModelVersion\n",
            "     |      Create a new model version from given source (artifact URI).\n",
            "     |      \n",
            "     |      :param name: Name for the containing registered model.\n",
            "     |      :param source: Source path where the MLflow model is stored.\n",
            "     |      :param run_id: Run ID from MLflow tracking server that generated the model\n",
            "     |      :param tags: A dictionary of key-value pairs that are converted into\n",
            "     |                   :py:class:`mlflow.entities.model_registry.ModelVersionTag` objects.\n",
            "     |      :param run_link: Link to the run from an MLflow tracking server that generated this model.\n",
            "     |      :param description: Description of the version.\n",
            "     |      :param await_creation_for: Number of seconds to wait for the model version to finish being\n",
            "     |                                  created and is in ``READY`` status. By default, the function\n",
            "     |                                  waits for five minutes. Specify 0 or None to skip waiting.\n",
            "     |      :return: Single :py:class:`mlflow.entities.model_registry.ModelVersion` object created by\n",
            "     |               backend.\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Example\n",
            "     |      \n",
            "     |          import mlflow.sklearn\n",
            "     |          from mlflow.store.artifact.runs_artifact_repo import RunsArtifactRepository\n",
            "     |          from mlflow import MlflowClient\n",
            "     |          from sklearn.ensemble import RandomForestRegressor\n",
            "     |      \n",
            "     |          mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
            "     |          params = {\"n_estimators\": 3, \"random_state\": 42}\n",
            "     |          name = \"RandomForestRegression\"\n",
            "     |          rfr = RandomForestRegressor(**params).fit([[0, 1]], [1])\n",
            "     |          # Log MLflow entities\n",
            "     |          with mlflow.start_run() as run:\n",
            "     |              mlflow.log_params(params)\n",
            "     |              mlflow.sklearn.log_model(rfr, artifact_path=\"sklearn-model\")\n",
            "     |      \n",
            "     |          # Register model name in the model registry\n",
            "     |          client = MlflowClient()\n",
            "     |          client.create_registered_model(name)\n",
            "     |      \n",
            "     |          # Create a new version of the rfr model under the registered model name\n",
            "     |          desc = \"A new version of the model\"\n",
            "     |          runs_uri = \"runs:/{}/sklearn-model\".format(run.info.run_id)\n",
            "     |          model_src = RunsArtifactRepository.get_underlying_uri(runs_uri)\n",
            "     |          mv = client.create_model_version(name, model_src, run.info.run_id, description=desc)\n",
            "     |          print(\"Name: {}\".format(mv.name))\n",
            "     |          print(\"Version: {}\".format(mv.version))\n",
            "     |          print(\"Description: {}\".format(mv.description))\n",
            "     |          print(\"Status: {}\".format(mv.status))\n",
            "     |          print(\"Stage: {}\".format(mv.current_stage))\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |          :caption: Output\n",
            "     |      \n",
            "     |          Name: RandomForestRegression\n",
            "     |          Version: 1\n",
            "     |          Description: A new version of the model\n",
            "     |          Status: READY\n",
            "     |          Stage: None\n",
            "     |  \n",
            "     |  create_registered_model(self, name: str, tags: Union[Dict[str, Any], NoneType] = None, description: Union[str, NoneType] = None) -> mlflow.entities.model_registry.registered_model.RegisteredModel\n",
            "     |      Create a new registered model in backend store.\n",
            "     |      \n",
            "     |      :param name: Name of the new model. This is expected to be unique in the backend store.\n",
            "     |      :param tags: A dictionary of key-value pairs that are converted into\n",
            "     |                   :py:class:`mlflow.entities.model_registry.RegisteredModelTag` objects.\n",
            "     |      :param description: Description of the model.\n",
            "     |      :return: A single object of :py:class:`mlflow.entities.model_registry.RegisteredModel`\n",
            "     |               created by backend.\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Example\n",
            "     |      \n",
            "     |          import mlflow\n",
            "     |          from mlflow import MlflowClient\n",
            "     |      \n",
            "     |          def print_registered_model_info(rm):\n",
            "     |              print(\"name: {}\".format(rm.name))\n",
            "     |              print(\"tags: {}\".format(rm.tags))\n",
            "     |              print(\"description: {}\".format(rm.description))\n",
            "     |      \n",
            "     |          name = \"SocialMediaTextAnalyzer\"\n",
            "     |          tags = {\"nlp.framework\": \"Spark NLP\"}\n",
            "     |          desc = \"This sentiment analysis model classifies the tone-happy, sad, angry.\"\n",
            "     |      \n",
            "     |          mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
            "     |          client = MlflowClient()\n",
            "     |          client.create_registered_model(name, tags, desc)\n",
            "     |          print_registered_model_info(client.get_registered_model(name))\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |          :caption: Output\n",
            "     |      \n",
            "     |          name: SocialMediaTextAnalyzer\n",
            "     |          tags: {'nlp.framework': 'Spark NLP'}\n",
            "     |          description: This sentiment analysis model classifies the tone-happy, sad, angry.\n",
            "     |  \n",
            "     |  create_run(self, experiment_id: str, start_time: Union[int, NoneType] = None, tags: Union[Dict[str, Any], NoneType] = None) -> mlflow.entities.run.Run\n",
            "     |      Create a :py:class:`mlflow.entities.Run` object that can be associated with\n",
            "     |      metrics, parameters, artifacts, etc.\n",
            "     |      Unlike :py:func:`mlflow.projects.run`, creates objects but does not run code.\n",
            "     |      Unlike :py:func:`mlflow.start_run`, does not change the \"active run\" used by\n",
            "     |      :py:func:`mlflow.log_param`.\n",
            "     |      \n",
            "     |      :param experiment_id: The string ID of the experiment to create a run in.\n",
            "     |      :param start_time: If not provided, use the current timestamp.\n",
            "     |      :param tags: A dictionary of key-value pairs that are converted into\n",
            "     |                   :py:class:`mlflow.entities.RunTag` objects.\n",
            "     |      :return: :py:class:`mlflow.entities.Run` that was created.\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Example\n",
            "     |      \n",
            "     |          from mlflow import MlflowClient\n",
            "     |      \n",
            "     |          # Create a run with a tag under the default experiment (whose id is '0').\n",
            "     |          tags = {\"engineering\": \"ML Platform\"}\n",
            "     |          client = MlflowClient()\n",
            "     |          experiment_id = \"0\"\n",
            "     |          run = client.create_run(experiment_id, tags=tags)\n",
            "     |      \n",
            "     |          # Show newly created run metadata info\n",
            "     |          print(\"Run tags: {}\".format(run.data.tags))\n",
            "     |          print(\"Experiment id: {}\".format(run.info.experiment_id))\n",
            "     |          print(\"Run id: {}\".format(run.info.run_id))\n",
            "     |          print(\"lifecycle_stage: {}\".format(run.info.lifecycle_stage))\n",
            "     |          print(\"status: {}\".format(run.info.status))\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |          :caption: Output\n",
            "     |      \n",
            "     |          Run tags: {'engineering': 'ML Platform'}\n",
            "     |          Experiment id: 0\n",
            "     |          Run id: 65fb9e2198764354bab398105f2e70c1\n",
            "     |          lifecycle_stage: active\n",
            "     |          status: RUNNING\n",
            "     |  \n",
            "     |  delete_experiment(self, experiment_id: str) -> None\n",
            "     |      Delete an experiment from the backend store.\n",
            "     |      \n",
            "     |      :param experiment_id: The experiment ID returned from ``create_experiment``.\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Example\n",
            "     |      \n",
            "     |          from mlflow import MlflowClient\n",
            "     |      \n",
            "     |          # Create an experiment with a name that is unique and case sensitive\n",
            "     |          client = MlflowClient()\n",
            "     |          experiment_id = client.create_experiment(\"New Experiment\")\n",
            "     |          client.delete_experiment(experiment_id)\n",
            "     |      \n",
            "     |          # Examine the deleted experiment details.\n",
            "     |          experiment = client.get_experiment(experiment_id)\n",
            "     |          print(\"Name: {}\".format(experiment.name))\n",
            "     |          print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
            "     |          print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |          :caption: Output\n",
            "     |      \n",
            "     |          Name: New Experiment\n",
            "     |          Artifact Location: file:///.../mlruns/1\n",
            "     |          Lifecycle_stage: deleted\n",
            "     |  \n",
            "     |  delete_model_version(self, name: str, version: str) -> None\n",
            "     |      Delete model version in backend.\n",
            "     |      \n",
            "     |      :param name: Name of the containing registered model.\n",
            "     |      :param version: Version number of the model version.\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Example\n",
            "     |      \n",
            "     |          import mlflow.sklearn\n",
            "     |          from mlflow import MlflowClient\n",
            "     |          from sklearn.ensemble import RandomForestRegressor\n",
            "     |      \n",
            "     |          def print_models_info(mv):\n",
            "     |              for m in mv:\n",
            "     |                  print(\"name: {}\".format(m.name))\n",
            "     |                  print(\"latest version: {}\".format(m.version))\n",
            "     |                  print(\"run_id: {}\".format(m.run_id))\n",
            "     |                  print(\"current_stage: {}\".format(m.current_stage))\n",
            "     |      \n",
            "     |          mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
            "     |      \n",
            "     |          # Create two runs and log MLflow entities\n",
            "     |          with mlflow.start_run() as run1:\n",
            "     |              params = {\"n_estimators\": 3, \"random_state\": 42}\n",
            "     |              rfr = RandomForestRegressor(**params).fit([[0, 1]], [1])\n",
            "     |              mlflow.log_params(params)\n",
            "     |              mlflow.sklearn.log_model(rfr, artifact_path=\"sklearn-model\")\n",
            "     |      \n",
            "     |          with mlflow.start_run() as run2:\n",
            "     |              params = {\"n_estimators\": 6, \"random_state\": 42}\n",
            "     |              rfr = RandomForestRegressor(**params).fit([[0, 1]], [1])\n",
            "     |              mlflow.log_params(params)\n",
            "     |              mlflow.sklearn.log_model(rfr, artifact_path=\"sklearn-model\")\n",
            "     |      \n",
            "     |          # Register model name in the model registry\n",
            "     |          name = \"RandomForestRegression\"\n",
            "     |          client = MlflowClient()\n",
            "     |          client.create_registered_model(name)\n",
            "     |      \n",
            "     |          # Create a two versions of the rfr model under the registered model name\n",
            "     |          for run_id in [run1.info.run_id, run2.info.run_id]:\n",
            "     |              model_uri = \"runs:/{}/sklearn-model\".format(run_id)\n",
            "     |              mv = client.create_model_version(name, model_uri, run_id)\n",
            "     |              print(\"model version {} created\".format(mv.version))\n",
            "     |      \n",
            "     |          print(\"--\")\n",
            "     |      \n",
            "     |          # Fetch latest version; this will be version 2\n",
            "     |          models = client.get_latest_versions(name, stages=[\"None\"])\n",
            "     |          print_models_info(models)\n",
            "     |          print(\"--\")\n",
            "     |      \n",
            "     |          # Delete the latest model version 2\n",
            "     |          print(\"Deleting model version {}\".format(mv.version))\n",
            "     |          client.delete_model_version(name, mv.version)\n",
            "     |          models = client.get_latest_versions(name, stages=[\"None\"])\n",
            "     |          print_models_info(models)\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |          :caption: Output\n",
            "     |      \n",
            "     |          model version 1 created\n",
            "     |          model version 2 created\n",
            "     |          --\n",
            "     |          name: RandomForestRegression\n",
            "     |          latest version: 2\n",
            "     |          run_id: 9881172ef10f4cb08df3ed452c0c362b\n",
            "     |          current_stage: None\n",
            "     |          --\n",
            "     |          Deleting model version 2\n",
            "     |          name: RandomForestRegression\n",
            "     |          latest version: 1\n",
            "     |          run_id: 9165d4f8aa0a4d069550824bdc55caaf\n",
            "     |          current_stage: None\n",
            "     |  \n",
            "     |  delete_model_version_tag(self, name: str, version: str = None, key: str = None, stage: str = None) -> None\n",
            "     |      Delete a tag associated with the model version.\n",
            "     |      When stage is set, tag will be deleted for latest model version of the stage.\n",
            "     |      Setting both version and stage parameter will result in error.\n",
            "     |      \n",
            "     |      :param name: Registered model name.\n",
            "     |      :param version: Registered model version.\n",
            "     |      :param key: Tag key. key is required.\n",
            "     |      :param stage: Registered model stage.\n",
            "     |      :return: None\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Example\n",
            "     |      \n",
            "     |          import mlflow.sklearn\n",
            "     |          from mlflow import MlflowClient\n",
            "     |          from sklearn.ensemble import RandomForestRegressor\n",
            "     |      \n",
            "     |          def print_model_version_info(mv):\n",
            "     |              print(\"Name: {}\".format(mv.name))\n",
            "     |              print(\"Version: {}\".format(mv.version))\n",
            "     |              print(\"Tags: {}\".format(mv.tags))\n",
            "     |      \n",
            "     |          mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
            "     |          params = {\"n_estimators\": 3, \"random_state\": 42}\n",
            "     |          name = \"RandomForestRegression\"\n",
            "     |          rfr = RandomForestRegressor(**params).fit([[0, 1]], [1])\n",
            "     |      \n",
            "     |          # Log MLflow entities\n",
            "     |          with mlflow.start_run() as run:\n",
            "     |              mlflow.log_params(params)\n",
            "     |              mlflow.sklearn.log_model(rfr, artifact_path=\"sklearn-model\")\n",
            "     |      \n",
            "     |          # Register model name in the model registry\n",
            "     |          client = MlflowClient()\n",
            "     |          client.create_registered_model(name)\n",
            "     |      \n",
            "     |          # Create a new version of the rfr model under the registered model name\n",
            "     |          # and delete a tag\n",
            "     |          model_uri = \"runs:/{}/sklearn-model\".format(run.info.run_id)\n",
            "     |          tags = {'t': \"1\", \"t1\" : \"2\"}\n",
            "     |          mv = client.create_model_version(name, model_uri, run.info.run_id, tags=tags)\n",
            "     |          print_model_version_info(mv)\n",
            "     |          print(\"--\")\n",
            "     |          #using version to delete tag\n",
            "     |          client.delete_model_version_tag(name, mv.version, \"t\")\n",
            "     |      \n",
            "     |          #using stage to delete tag\n",
            "     |          client.delete_model_version_tag(name, key=\"t1\", stage=mv.current_stage)\n",
            "     |          mv = client.get_model_version(name, mv.version)\n",
            "     |          print_model_version_info(mv)\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |          :caption: Output\n",
            "     |      \n",
            "     |          Name: RandomForestRegression\n",
            "     |          Version: 1\n",
            "     |          Tags: {'t': '1', 't1': '2'}\n",
            "     |          --\n",
            "     |          Name: RandomForestRegression\n",
            "     |          Version: 1\n",
            "     |          Tags: {}\n",
            "     |  \n",
            "     |  delete_registered_model(self, name: str)\n",
            "     |      Delete registered model.\n",
            "     |      Backend raises exception if a registered model with given name does not exist.\n",
            "     |      \n",
            "     |      :param name: Name of the registered model to delete.\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Example\n",
            "     |      \n",
            "     |          import mlflow\n",
            "     |          from mlflow import MlflowClient\n",
            "     |      \n",
            "     |          def print_registered_models_info(r_models):\n",
            "     |              print(\"--\")\n",
            "     |              for rm in r_models:\n",
            "     |                  print(\"name: {}\".format(rm.name))\n",
            "     |                  print(\"tags: {}\".format(rm.tags))\n",
            "     |                  print(\"description: {}\".format(rm.description))\n",
            "     |      \n",
            "     |          mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
            "     |          client = MlflowClient()\n",
            "     |      \n",
            "     |          # Register a couple of models with respective names, tags, and descriptions\n",
            "     |          for name, tags, desc in [(\"name1\", {\"t1\": \"t1\"}, 'description1'),\n",
            "     |                                   (\"name2\", {\"t2\": \"t2\"}, 'description2')]:\n",
            "     |              client.create_registered_model(name, tags, desc)\n",
            "     |      \n",
            "     |          # Fetch all registered models\n",
            "     |          print_registered_models_info(client.list_registered_models())\n",
            "     |      \n",
            "     |          # Delete one registered model and fetch again\n",
            "     |          client.delete_registered_model(\"name1\")\n",
            "     |          print_registered_models_info(client.list_registered_models())\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |          :caption: Output\n",
            "     |      \n",
            "     |          --\n",
            "     |          name: name1\n",
            "     |          tags: {'t1': 't1'}\n",
            "     |          description: description1\n",
            "     |          name: name2\n",
            "     |          tags: {'t2': 't2'}\n",
            "     |          description: description2\n",
            "     |          --\n",
            "     |          name: name2\n",
            "     |          tags: {'t2': 't2'}\n",
            "     |          description: description2\n",
            "     |  \n",
            "     |  delete_registered_model_tag(self, name: str, key: str) -> None\n",
            "     |      Delete a tag associated with the registered model.\n",
            "     |      \n",
            "     |      :param name: Registered model name.\n",
            "     |      :param key: Registered model tag key.\n",
            "     |      :return: None\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Example\n",
            "     |      \n",
            "     |          import mlflow\n",
            "     |          from mlflow import MlflowClient\n",
            "     |      \n",
            "     |          def print_registered_models_info(r_models):\n",
            "     |              print(\"--\")\n",
            "     |              for rm in r_models:\n",
            "     |                  print(\"name: {}\".format(rm.name))\n",
            "     |                  print(\"tags: {}\".format(rm.tags))\n",
            "     |      \n",
            "     |          mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
            "     |          client = MlflowClient()\n",
            "     |      \n",
            "     |          # Register a couple of models with respective names and tags\n",
            "     |          for name, tags in [(\"name1\", {\"t1\": \"t1\"}),(\"name2\", {\"t2\": \"t2\"})]:\n",
            "     |              client.create_registered_model(name, tags)\n",
            "     |      \n",
            "     |          # Fetch all registered models\n",
            "     |          print_registered_models_info(client.list_registered_models())\n",
            "     |      \n",
            "     |          # Delete a tag from model `name2`\n",
            "     |          client.delete_registered_model_tag(\"name2\", 't2')\n",
            "     |          print_registered_models_info(client.list_registered_models())\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |          :caption: Output\n",
            "     |      \n",
            "     |          --\n",
            "     |          name: name1\n",
            "     |          tags: {'t1': 't1'}\n",
            "     |          name: name2\n",
            "     |          tags: {'t2': 't2'}\n",
            "     |          --\n",
            "     |          name: name1\n",
            "     |          tags: {'t1': 't1'}\n",
            "     |          name: name2\n",
            "     |          tags: {}\n",
            "     |  \n",
            "     |  delete_run(self, run_id: str) -> None\n",
            "     |      Deletes a run with the given ID.\n",
            "     |      \n",
            "     |      :param run_id: The unique run id to delete.\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Example\n",
            "     |      \n",
            "     |          from mlflow import MlflowClient\n",
            "     |      \n",
            "     |          # Create a run under the default experiment (whose id is '0').\n",
            "     |          client = MlflowClient()\n",
            "     |          experiment_id = \"0\"\n",
            "     |          run = client.create_run(experiment_id)\n",
            "     |          run_id = run.info.run_id\n",
            "     |          print(\"run_id: {}; lifecycle_stage: {}\".format(run_id, run.info.lifecycle_stage))\n",
            "     |          print(\"--\")\n",
            "     |          client.delete_run(run_id)\n",
            "     |          del_run = client.get_run(run_id)\n",
            "     |          print(\"run_id: {}; lifecycle_stage: {}\".format(run_id, del_run.info.lifecycle_stage))\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |          :caption: Output\n",
            "     |      \n",
            "     |          run_id: a61c7a1851324f7094e8d5014c58c8c8; lifecycle_stage: active\n",
            "     |          run_id: a61c7a1851324f7094e8d5014c58c8c8; lifecycle_stage: deleted\n",
            "     |  \n",
            "     |  delete_tag(self, run_id: str, key: str) -> None\n",
            "     |      Delete a tag from a run. This is irreversible.\n",
            "     |      \n",
            "     |      :param run_id: String ID of the run\n",
            "     |      :param key: Name of the tag\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Example\n",
            "     |      \n",
            "     |          from mlflow import MlflowClient\n",
            "     |      \n",
            "     |          def print_run_info(run):\n",
            "     |              print(\"run_id: {}\".format(run.info.run_id))\n",
            "     |              print(\"Tags: {}\".format(run.data.tags))\n",
            "     |      \n",
            "     |          # Create a run under the default experiment (whose id is '0').\n",
            "     |          client = MlflowClient()\n",
            "     |          tags = {\"t1\": 1, \"t2\": 2}\n",
            "     |          experiment_id = \"0\"\n",
            "     |          run = client.create_run(experiment_id, tags=tags)\n",
            "     |          print_run_info(run)\n",
            "     |          print(\"--\")\n",
            "     |      \n",
            "     |          # Delete tag and fetch updated info\n",
            "     |          client.delete_tag(run.info.run_id, \"t1\")\n",
            "     |          run = client.get_run(run.info.run_id)\n",
            "     |          print_run_info(run)\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |          :caption: Output\n",
            "     |      \n",
            "     |          run_id: b7077267a59a45d78cd9be0de4bc41f5\n",
            "     |          Tags: {'t2': '2', 't1': '1'}\n",
            "     |          --\n",
            "     |          run_id: b7077267a59a45d78cd9be0de4bc41f5\n",
            "     |          Tags: {'t2': '2'}\n",
            "     |  \n",
            "     |  download_artifacts(self, run_id: str, path: str, dst_path: Union[str, NoneType] = None) -> str\n",
            "     |      Download an artifact file or directory from a run to a local directory if applicable,\n",
            "     |      and return a local path for it.\n",
            "     |      \n",
            "     |      :param run_id: The run to download artifacts from.\n",
            "     |      :param path: Relative source path to the desired artifact.\n",
            "     |      :param dst_path: Absolute path of the local filesystem destination directory to which to\n",
            "     |                       download the specified artifacts. This directory must already exist.\n",
            "     |                       If unspecified, the artifacts will either be downloaded to a new\n",
            "     |                       uniquely-named directory on the local filesystem or will be returned\n",
            "     |                       directly in the case of the LocalArtifactRepository.\n",
            "     |      :return: Local path of desired artifact.\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Example\n",
            "     |      \n",
            "     |          import os\n",
            "     |          import mlflow\n",
            "     |          from mlflow import MlflowClient\n",
            "     |      \n",
            "     |          features = \"rooms, zipcode, median_price, school_rating, transport\"\n",
            "     |          with open(\"features.txt\", 'w') as f:\n",
            "     |              f.write(features)\n",
            "     |      \n",
            "     |          # Log artifacts\n",
            "     |          with mlflow.start_run() as run:\n",
            "     |              mlflow.log_artifact(\"features.txt\", artifact_path=\"features\")\n",
            "     |      \n",
            "     |          # Download artifacts\n",
            "     |          client = MlflowClient()\n",
            "     |          local_dir = \"/tmp/artifact_downloads\"\n",
            "     |          if not os.path.exists(local_dir):\n",
            "     |              os.mkdir(local_dir)\n",
            "     |          local_path = client.download_artifacts(run.info.run_id, \"features\", local_dir)\n",
            "     |          print(\"Artifacts downloaded in: {}\".format(local_path))\n",
            "     |          print(\"Artifacts: {}\".format(os.listdir(local_path)))\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |          :caption: Output\n",
            "     |      \n",
            "     |          Artifacts downloaded in: /tmp/artifact_downloads/features\n",
            "     |          Artifacts: ['features.txt']\n",
            "     |  \n",
            "     |  get_experiment(self, experiment_id: str) -> mlflow.entities.experiment.Experiment\n",
            "     |      Retrieve an experiment by experiment_id from the backend store\n",
            "     |      \n",
            "     |      :param experiment_id: The experiment ID returned from ``create_experiment``.\n",
            "     |      :return: :py:class:`mlflow.entities.Experiment`\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Example\n",
            "     |      \n",
            "     |          from mlflow import MlflowClient\n",
            "     |      \n",
            "     |          client = MlflowClient()\n",
            "     |          exp_id = client.create_experiment(\"Experiment\")\n",
            "     |          experiment = client.get_experiment(exp_id)\n",
            "     |      \n",
            "     |          # Show experiment info\n",
            "     |          print(\"Name: {}\".format(experiment.name))\n",
            "     |          print(\"Experiment ID: {}\".format(experiment.experiment_id))\n",
            "     |          print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
            "     |          print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |          :caption: Output\n",
            "     |      \n",
            "     |          Name: Experiment\n",
            "     |          Experiment ID: 1\n",
            "     |          Artifact Location: file:///.../mlruns/1\n",
            "     |          Lifecycle_stage: active\n",
            "     |  \n",
            "     |  get_experiment_by_name(self, name: str) -> Union[mlflow.entities.experiment.Experiment, NoneType]\n",
            "     |      Retrieve an experiment by experiment name from the backend store\n",
            "     |      \n",
            "     |      :param name: The experiment name, which is case sensitive.\n",
            "     |      :return: An instance of :py:class:`mlflow.entities.Experiment`\n",
            "     |               if an experiment with the specified name exists, otherwise None.\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Example\n",
            "     |      \n",
            "     |          from mlflow import MlflowClient\n",
            "     |      \n",
            "     |          # Case-sensitive name\n",
            "     |          client = MlflowClient()\n",
            "     |          experiment = client.get_experiment_by_name(\"Default\")\n",
            "     |      \n",
            "     |          # Show experiment info\n",
            "     |          print(\"Name: {}\".format(experiment.name))\n",
            "     |          print(\"Experiment ID: {}\".format(experiment.experiment_id))\n",
            "     |          print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
            "     |          print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |          :caption: Output\n",
            "     |      \n",
            "     |          Name: Default\n",
            "     |          Experiment ID: 0\n",
            "     |          Artifact Location: file:///.../mlruns/0\n",
            "     |          Lifecycle_stage: active\n",
            "     |  \n",
            "     |  get_latest_versions(self, name: str, stages: List[str] = None) -> List[mlflow.entities.model_registry.model_version.ModelVersion]\n",
            "     |      Latest version models for each requests stage. If no ``stages`` provided, returns the\n",
            "     |      latest version for each stage.\n",
            "     |      \n",
            "     |      :param name: Name of the registered model from which to get the latest versions.\n",
            "     |      :param stages: List of desired stages. If input list is None, return latest versions for\n",
            "     |                     for ALL_STAGES.\n",
            "     |      :return: List of :py:class:`mlflow.entities.model_registry.ModelVersion` objects.\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Example\n",
            "     |      \n",
            "     |          import mlflow.sklearn\n",
            "     |          from mlflow import MlflowClient\n",
            "     |          from sklearn.ensemble import RandomForestRegressor\n",
            "     |      \n",
            "     |          def print_models_info(mv):\n",
            "     |              for m in mv:\n",
            "     |                  print(\"name: {}\".format(m.name))\n",
            "     |                  print(\"latest version: {}\".format(m.version))\n",
            "     |                  print(\"run_id: {}\".format(m.run_id))\n",
            "     |                  print(\"current_stage: {}\".format(m.current_stage))\n",
            "     |      \n",
            "     |          mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
            "     |      \n",
            "     |          # Create two runs Log MLflow entities\n",
            "     |          with mlflow.start_run() as run1:\n",
            "     |              params = {\"n_estimators\": 3, \"random_state\": 42}\n",
            "     |              rfr = RandomForestRegressor(**params).fit([[0, 1]], [1])\n",
            "     |              mlflow.log_params(params)\n",
            "     |              mlflow.sklearn.log_model(rfr, artifact_path=\"sklearn-model\")\n",
            "     |      \n",
            "     |          with mlflow.start_run() as run2:\n",
            "     |              params = {\"n_estimators\": 6, \"random_state\": 42}\n",
            "     |              rfr = RandomForestRegressor(**params).fit([[0, 1]], [1])\n",
            "     |              mlflow.log_params(params)\n",
            "     |              mlflow.sklearn.log_model(rfr, artifact_path=\"sklearn-model\")\n",
            "     |      \n",
            "     |          # Register model name in the model registry\n",
            "     |          name = \"RandomForestRegression\"\n",
            "     |          client = MlflowClient()\n",
            "     |          client.create_registered_model(name)\n",
            "     |      \n",
            "     |          # Create a two versions of the rfr model under the registered model name\n",
            "     |          for run_id in [run1.info.run_id, run2.info.run_id]:\n",
            "     |              model_uri = \"runs:/{}/sklearn-model\".format(run_id)\n",
            "     |              mv = client.create_model_version(name, model_uri, run_id)\n",
            "     |              print(\"model version {} created\".format(mv.version))\n",
            "     |      \n",
            "     |          # Fetch latest version; this will be version 2\n",
            "     |          print(\"--\")\n",
            "     |          print_models_info(client.get_latest_versions(name, stages=[\"None\"]))\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |          :caption: Output\n",
            "     |      \n",
            "     |          model version 1 created\n",
            "     |          model version 2 created\n",
            "     |          --\n",
            "     |          name: RandomForestRegression\n",
            "     |          latest version: 2\n",
            "     |          run_id: 31165664be034dc698c52a4bdeb71663\n",
            "     |          current_stage: None\n",
            "     |  \n",
            "     |  get_metric_history(self, run_id: str, key: str) -> List[mlflow.entities.metric.Metric]\n",
            "     |      Return a list of metric objects corresponding to all values logged for a given metric.\n",
            "     |      \n",
            "     |      :param run_id: Unique identifier for run\n",
            "     |      :param key: Metric name within the run\n",
            "     |      \n",
            "     |      :return: A list of :py:class:`mlflow.entities.Metric` entities if logged, else empty list\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Example\n",
            "     |      \n",
            "     |          from mlflow import MlflowClient\n",
            "     |      \n",
            "     |          def print_metric_info(history):\n",
            "     |              for m in history:\n",
            "     |                  print(\"name: {}\".format(m.key))\n",
            "     |                  print(\"value: {}\".format(m.value))\n",
            "     |                  print(\"step: {}\".format(m.step))\n",
            "     |                  print(\"timestamp: {}\".format(m.timestamp))\n",
            "     |                  print(\"--\")\n",
            "     |      \n",
            "     |          # Create a run under the default experiment (whose id is \"0\"). Since this is low-level\n",
            "     |          # CRUD operation, the method will create a run. To end the run, you'll have\n",
            "     |          # to explicitly end it.\n",
            "     |          client = MlflowClient()\n",
            "     |          experiment_id = \"0\"\n",
            "     |          run = client.create_run(experiment_id)\n",
            "     |          print(\"run_id: {}\".format(run.info.run_id))\n",
            "     |          print(\"--\")\n",
            "     |      \n",
            "     |          # Log couple of metrics, update their initial value, and fetch each\n",
            "     |          # logged metrics' history.\n",
            "     |          for k, v in [(\"m1\", 1.5), (\"m2\", 2.5)]:\n",
            "     |              client.log_metric(run.info.run_id, k, v, step=0)\n",
            "     |              client.log_metric(run.info.run_id, k, v + 1, step=1)\n",
            "     |              print_metric_info(client.get_metric_history(run.info.run_id, k))\n",
            "     |          client.set_terminated(run.info.run_id)\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |          :caption: Output\n",
            "     |      \n",
            "     |          run_id: c360d15714994c388b504fe09ea3c234\n",
            "     |          --\n",
            "     |          name: m1\n",
            "     |          value: 1.5\n",
            "     |          step: 0\n",
            "     |          timestamp: 1603423788607\n",
            "     |          --\n",
            "     |          name: m1\n",
            "     |          value: 2.5\n",
            "     |          step: 1\n",
            "     |          timestamp: 1603423788608\n",
            "     |          --\n",
            "     |          name: m2\n",
            "     |          value: 2.5\n",
            "     |          step: 0\n",
            "     |          timestamp: 1603423788609\n",
            "     |          --\n",
            "     |          name: m2\n",
            "     |          value: 3.5\n",
            "     |          step: 1\n",
            "     |          timestamp: 1603423788610\n",
            "     |          --\n",
            "     |  \n",
            "     |  get_model_version(self, name: str, version: str) -> mlflow.entities.model_registry.model_version.ModelVersion\n",
            "     |      :param name: Name of the containing registered model.\n",
            "     |      :param version: Version number as an integer of the model version.\n",
            "     |      :return: A single :py:class:`mlflow.entities.model_registry.ModelVersion` object.\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Example\n",
            "     |      \n",
            "     |          import mlflow.sklearn\n",
            "     |          from mlflow import MlflowClient\n",
            "     |          from sklearn.ensemble import RandomForestRegressor\n",
            "     |      \n",
            "     |          # Create two runs Log MLflow entities\n",
            "     |          with mlflow.start_run() as run1:\n",
            "     |              params = {\"n_estimators\": 3, \"random_state\": 42}\n",
            "     |              rfr = RandomForestRegressor(**params).fit([[0, 1]], [1])\n",
            "     |              mlflow.log_params(params)\n",
            "     |              mlflow.sklearn.log_model(rfr, artifact_path=\"sklearn-model\")\n",
            "     |      \n",
            "     |          with mlflow.start_run() as run2:\n",
            "     |              params = {\"n_estimators\": 6, \"random_state\": 42}\n",
            "     |              rfr = RandomForestRegressor(**params).fit([[0, 1]], [1])\n",
            "     |              mlflow.log_params(params)\n",
            "     |              mlflow.sklearn.log_model(rfr, artifact_path=\"sklearn-model\")\n",
            "     |      \n",
            "     |          # Register model name in the model registry\n",
            "     |          name = \"RandomForestRegression\"\n",
            "     |          client = MlflowClient()\n",
            "     |          client.create_registered_model(name)\n",
            "     |      \n",
            "     |          # Create a two versions of the rfr model under the registered model name\n",
            "     |          for run_id in [run1.info.run_id, run2.info.run_id]:\n",
            "     |              model_uri = \"runs:/{}/sklearn-model\".format(run_id)\n",
            "     |              mv = client.create_model_version(name, model_uri, run_id)\n",
            "     |              print(\"model version {} created\".format(mv.version))\n",
            "     |          print(\"--\")\n",
            "     |      \n",
            "     |          # Fetch the last version; this will be version 2\n",
            "     |          mv = client.get_model_version(name, mv.version)\n",
            "     |          print_model_version_info(mv)\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |          :caption: Output\n",
            "     |      \n",
            "     |          model version 1 created\n",
            "     |          model version 2 created\n",
            "     |          --\n",
            "     |          Name: RandomForestRegression\n",
            "     |          Version: 2\n",
            "     |  \n",
            "     |  get_model_version_download_uri(self, name: str, version: str) -> str\n",
            "     |      Get the download location in Model Registry for this model version.\n",
            "     |      \n",
            "     |      :param name: Name of the containing registered model.\n",
            "     |      :param version: Version number as an integer of the model version.\n",
            "     |      :return: A single URI location that allows reads for downloading.\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Example\n",
            "     |      \n",
            "     |          import mlflow.sklearn\n",
            "     |          from mlflow import MlflowClient\n",
            "     |          from sklearn.ensemble import RandomForestRegressor\n",
            "     |      \n",
            "     |          mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
            "     |          params = {\"n_estimators\": 3, \"random_state\": 42}\n",
            "     |          name = \"RandomForestRegression\"\n",
            "     |          rfr = RandomForestRegressor(**params).fit([[0, 1]], [1])\n",
            "     |      \n",
            "     |          # Log MLflow entities\n",
            "     |          with mlflow.start_run() as run:\n",
            "     |              mlflow.log_params(params)\n",
            "     |              mlflow.sklearn.log_model(rfr, artifact_path=\"models/sklearn-model\")\n",
            "     |      \n",
            "     |          # Register model name in the model registry\n",
            "     |          client = MlflowClient()\n",
            "     |          client.create_registered_model(name)\n",
            "     |      \n",
            "     |          # Create a new version of the rfr model under the registered model name\n",
            "     |          model_uri = \"runs:/{}/models/sklearn-model\".format(run.info.run_id)\n",
            "     |          mv = client.create_model_version(name, model_uri, run.info.run_id)\n",
            "     |          artifact_uri = client.get_model_version_download_uri(name, mv.version)\n",
            "     |          print(\"Download URI: {}\".format(artifact_uri))\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |          :caption: Output\n",
            "     |      \n",
            "     |          Download URI: runs:/44e04097ac364cd895f2039eaccca9ac/models/sklearn-model\n",
            "     |  \n",
            "     |  get_model_version_stages(self, name: str, version: str) -> List[str]\n",
            "     |      :return: A list of valid stages.\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Example\n",
            "     |      \n",
            "     |          import mlflow.sklearn\n",
            "     |          from mlflow import MlflowClient\n",
            "     |          from sklearn.ensemble import RandomForestRegressor\n",
            "     |      \n",
            "     |          mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
            "     |          params = {\"n_estimators\": 3, \"random_state\": 42}\n",
            "     |          name = \"RandomForestRegression\"\n",
            "     |          rfr = RandomForestRegressor(**params).fit([[0, 1]], [1])\n",
            "     |      \n",
            "     |          # Log MLflow entities\n",
            "     |          with mlflow.start_run() as run:\n",
            "     |              mlflow.log_params(params)\n",
            "     |              mlflow.sklearn.log_model(rfr, artifact_path=\"models/sklearn-model\")\n",
            "     |      \n",
            "     |          # Register model name in the model registry\n",
            "     |          client = MlflowClient()\n",
            "     |          client.create_registered_model(name)\n",
            "     |      \n",
            "     |          # Create a new version of the rfr model under the registered model name\n",
            "     |          # fetch valid stages\n",
            "     |          model_uri = \"runs:/{}/models/sklearn-model\".format(run.info.run_id)\n",
            "     |          mv = client.create_model_version(name, model_uri, run.info.run_id)\n",
            "     |          stages = client.get_model_version_stages(name, mv.version)\n",
            "     |          print(\"Model list of valid stages: {}\".format(stages))\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |          :caption: Output\n",
            "     |      \n",
            "     |          Model list of valid stages: ['None', 'Staging', 'Production', 'Archived']\n",
            "     |  \n",
            "     |  get_registered_model(self, name: str) -> mlflow.entities.model_registry.registered_model.RegisteredModel\n",
            "     |      :param name: Name of the registered model to get.\n",
            "     |      :return: A single :py:class:`mlflow.entities.model_registry.RegisteredModel` object.\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Example\n",
            "     |      \n",
            "     |          import mlflow\n",
            "     |          from mlflow import MlflowClient\n",
            "     |      \n",
            "     |          def print_model_info(rm):\n",
            "     |              print(\"--\")\n",
            "     |              print(\"name: {}\".format(rm.name))\n",
            "     |              print(\"tags: {}\".format(rm.tags))\n",
            "     |              print(\"description: {}\".format(rm.description))\n",
            "     |      \n",
            "     |          name = \"SocialMediaTextAnalyzer\"\n",
            "     |          tags = {\"nlp.framework\": \"Spark NLP\"}\n",
            "     |          desc = \"This sentiment analysis model classifies the tone-happy, sad, angry.\"\n",
            "     |          mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
            "     |          client = MlflowClient()\n",
            "     |      \n",
            "     |          # Create and fetch the registered model\n",
            "     |          client.create_registered_model(name, tags, desc)\n",
            "     |          model = client.get_registered_model(name)\n",
            "     |          print_model_info(model)\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |          :caption: Output\n",
            "     |      \n",
            "     |          --\n",
            "     |          name: SocialMediaTextAnalyzer\n",
            "     |          tags: {'nlp.framework': 'Spark NLP'}\n",
            "     |          description: This sentiment analysis model classifies the tone-happy, sad, angry.\n",
            "     |  \n",
            "     |  get_run(self, run_id: str) -> mlflow.entities.run.Run\n",
            "     |      Fetch the run from backend store. The resulting :py:class:`Run <mlflow.entities.Run>`\n",
            "     |      contains a collection of run metadata -- :py:class:`RunInfo <mlflow.entities.RunInfo>`,\n",
            "     |      as well as a collection of run parameters, tags, and metrics --\n",
            "     |      :py:class:`RunData <mlflow.entities.RunData>`. In the case where multiple metrics with the\n",
            "     |      same key are logged for the run, the :py:class:`RunData <mlflow.entities.RunData>` contains\n",
            "     |      the most recently logged value at the largest step for each metric.\n",
            "     |      \n",
            "     |      :param run_id: Unique identifier for the run.\n",
            "     |      \n",
            "     |      :return: A single :py:class:`mlflow.entities.Run` object, if the run exists. Otherwise,\n",
            "     |               raises an exception.\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Example\n",
            "     |      \n",
            "     |          import mlflow\n",
            "     |          from mlflow import MlflowClient\n",
            "     |      \n",
            "     |          with mlflow.start_run() as run:\n",
            "     |              mlflow.log_param(\"p\", 0)\n",
            "     |      \n",
            "     |          # The run has finished since we have exited the with block\n",
            "     |          # Fetch the run\n",
            "     |          client = MlflowClient()\n",
            "     |          run = client.get_run(run.info.run_id)\n",
            "     |          print(\"run_id: {}\".format(run.info.run_id))\n",
            "     |          print(\"params: {}\".format(run.data.params))\n",
            "     |          print(\"status: {}\".format(run.info.status))\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |          :caption: Output\n",
            "     |      \n",
            "     |          run_id: e36b42c587a1413ead7c3b6764120618\n",
            "     |          params: {'p': '0'}\n",
            "     |          status: FINISHED\n",
            "     |  \n",
            "     |  list_artifacts(self, run_id: str, path=None) -> List[mlflow.entities.file_info.FileInfo]\n",
            "     |      List the artifacts for a run.\n",
            "     |      \n",
            "     |      :param run_id: The run to list artifacts from.\n",
            "     |      :param path: The run's relative artifact path to list from. By default it is set to None\n",
            "     |                   or the root artifact path.\n",
            "     |      :return: List of :py:class:`mlflow.entities.FileInfo`\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Example\n",
            "     |      \n",
            "     |          from mlflow import MlflowClient\n",
            "     |      \n",
            "     |           def print_artifact_info(artifact):\n",
            "     |              print(\"artifact: {}\".format(artifact.path))\n",
            "     |              print(\"is_dir: {}\".format(artifact.is_dir))\n",
            "     |              print(\"size: {}\".format(artifact.file_size))\n",
            "     |      \n",
            "     |          features = \"rooms zipcode, median_price, school_rating, transport\"\n",
            "     |          labels = \"price\"\n",
            "     |      \n",
            "     |          # Create a run under the default experiment (whose id is '0').\n",
            "     |          client = MlflowClient()\n",
            "     |          experiment_id = \"0\"\n",
            "     |          run = client.create_run(experiment_id)\n",
            "     |      \n",
            "     |          # Create some artifacts and log under the above run\n",
            "     |          for file, content in [(\"features\", features), (\"labels\", labels)]:\n",
            "     |              with open(\"{}.txt\".format(file), 'w') as f:\n",
            "     |                  f.write(content)\n",
            "     |              client.log_artifact(run.info.run_id, \"{}.txt\".format(file))\n",
            "     |      \n",
            "     |          # Fetch the logged artifacts\n",
            "     |          artifacts = client.list_artifacts(run.info.run_id)\n",
            "     |          for artifact in artifacts:\n",
            "     |              print_artifact_info(artifact)\n",
            "     |          client.set_terminated(run.info.run_id)\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |          :caption: Output\n",
            "     |      \n",
            "     |          artifact: features.txt\n",
            "     |          is_dir: False\n",
            "     |          size: 53\n",
            "     |          artifact: labels.txt\n",
            "     |          is_dir: False\n",
            "     |          size: 5\n",
            "     |  \n",
            "     |  list_experiments(self, view_type: int = 1, max_results: Union[int, NoneType] = None, page_token: Union[str, NoneType] = None) -> mlflow.store.entities.paged_list.PagedList[mlflow.entities.experiment.Experiment]\n",
            "     |      :param view_type: Qualify requested type of experiments.\n",
            "     |      :param max_results: If passed, specifies the maximum number of experiments desired. If not\n",
            "     |                          passed, all experiments will be returned for the File and SQL backends.\n",
            "     |                          For the REST backend, the server will pick a maximum number of results\n",
            "     |                          to return.\n",
            "     |      :param page_token: Token specifying the next page of results. It should be obtained from\n",
            "     |                          a ``list_experiments`` call.\n",
            "     |      :return: A :py:class:`PagedList <mlflow.store.entities.PagedList>` of\n",
            "     |               :py:class:`Experiment <mlflow.entities.Experiment>` objects. The pagination token\n",
            "     |               for the next page can be obtained via the ``token`` attribute of the object.\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Example\n",
            "     |      \n",
            "     |          from mlflow import MlflowClient\n",
            "     |          from mlflow.entities import ViewType\n",
            "     |      \n",
            "     |          def print_experiment_info(experiments):\n",
            "     |              for e in experiments:\n",
            "     |                  print(\"- experiment_id: {}, name: {}, lifecycle_stage: {}\"\n",
            "     |                        .format(e.experiment_id, e.name, e.lifecycle_stage))\n",
            "     |      \n",
            "     |          client = MlflowClient()\n",
            "     |          for name in [\"Experiment 1\", \"Experiment 2\"]:\n",
            "     |              exp_id = client.create_experiment(name)\n",
            "     |      \n",
            "     |          # Delete the last experiment\n",
            "     |          client.delete_experiment(exp_id)\n",
            "     |      \n",
            "     |          # Fetch experiments by view type\n",
            "     |          print(\"Active experiments:\")\n",
            "     |          print_experiment_info(client.list_experiments(view_type=ViewType.ACTIVE_ONLY))\n",
            "     |          print(\"Deleted experiments:\")\n",
            "     |          print_experiment_info(client.list_experiments(view_type=ViewType.DELETED_ONLY))\n",
            "     |          print(\"All experiments:\")\n",
            "     |          print_experiment_info(client.list_experiments(view_type=ViewType.ALL))\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |          :caption: Output\n",
            "     |      \n",
            "     |          Active experiments:\n",
            "     |          - experiment_id: 0, name: Default, lifecycle_stage: active\n",
            "     |          - experiment_id: 1, name: Experiment 1, lifecycle_stage: active\n",
            "     |          Deleted experiments:\n",
            "     |          - experiment_id: 2, name: Experiment 2, lifecycle_stage: deleted\n",
            "     |          All experiments:\n",
            "     |          - experiment_id: 0, name: Default, lifecycle_stage: active\n",
            "     |          - experiment_id: 1, name: Experiment 1, lifecycle_stage: active\n",
            "     |          - experiment_id: 2, name: Experiment 2, lifecycle_stage: deleted\n",
            "     |  \n",
            "     |  list_registered_models(self, max_results: int = 100, page_token: Union[str, NoneType] = None) -> mlflow.store.entities.paged_list.PagedList[mlflow.entities.model_registry.registered_model.RegisteredModel]\n",
            "     |      List of all registered models\n",
            "     |      \n",
            "     |      :param max_results: Maximum number of registered models desired.\n",
            "     |      :param page_token: Token specifying the next page of results. It should be obtained from\n",
            "     |                         a ``list_registered_models`` call.\n",
            "     |      :return: A PagedList of :py:class:`mlflow.entities.model_registry.RegisteredModel` objects\n",
            "     |               that can satisfy the search expressions. The pagination token for the next page\n",
            "     |               can be obtained via the ``token`` attribute of the object.\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Example\n",
            "     |      \n",
            "     |          import mlflow\n",
            "     |          from mlflow import MlflowClient\n",
            "     |      \n",
            "     |          def print_model_info(models):\n",
            "     |              for m in models:\n",
            "     |                  print(\"--\")\n",
            "     |                  print(\"name: {}\".format(m.name))\n",
            "     |                  print(\"tags: {}\".format(m.tags))\n",
            "     |                  print(\"description: {}\".format(m.description))\n",
            "     |      \n",
            "     |          mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
            "     |          client = MlflowClient()\n",
            "     |      \n",
            "     |          # Register a couple of models with respective names, tags, and descriptions\n",
            "     |          for name, tags, desc in [(\"name1\", {\"t1\": \"t1\"}, 'description1'),\n",
            "     |                                   (\"name2\", {\"t2\": \"t2\"}, 'description2')]:\n",
            "     |              client.create_registered_model(name, tags, desc)\n",
            "     |      \n",
            "     |          # Fetch all registered models\n",
            "     |          print_model_info(client.list_registered_models())\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |          :caption: Output\n",
            "     |      \n",
            "     |          --\n",
            "     |          name: name1\n",
            "     |          tags: {'t1': 't1'}\n",
            "     |          description: description1\n",
            "     |          --\n",
            "     |          name: name2\n",
            "     |          tags: {'t2': 't2'}\n",
            "     |          description: description2\n",
            "     |  \n",
            "     |  list_run_infos(self, experiment_id: str, run_view_type: int = 1, max_results: int = 1000, order_by: Union[List[str], NoneType] = None, page_token: Union[str, NoneType] = None) -> mlflow.store.entities.paged_list.PagedList[mlflow.entities.run_info.RunInfo]\n",
            "     |      Return run information for runs which belong to the experiment_id.\n",
            "     |      \n",
            "     |      :param experiment_id: The experiment id which to search\n",
            "     |      :param run_view_type: ACTIVE_ONLY, DELETED_ONLY, or ALL runs\n",
            "     |      :param max_results: Maximum number of results desired.\n",
            "     |      :param order_by: List of order_by clauses. Currently supported values are\n",
            "     |          are ``metric.key``, ``parameter.key``, ``tag.key``, ``attribute.key``.\n",
            "     |          For example, ``order_by=[\"tag.release ASC\", \"metric.click_rate DESC\"]``.\n",
            "     |      \n",
            "     |      :return: A :py:class:`PagedList <mlflow.store.entities.PagedList>` of\n",
            "     |          :py:class:`RunInfo <mlflow.entities.RunInfo>` objects that satisfy the search\n",
            "     |          expressions. If the underlying tracking store supports pagination, the token for the\n",
            "     |          next page may be obtained via the ``token`` attribute of the returned object.\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Example\n",
            "     |      \n",
            "     |          import mlflow\n",
            "     |          from mlflow import MlflowClient\n",
            "     |          from mlflow.entities import ViewType\n",
            "     |      \n",
            "     |          def print_run_infos(run_infos):\n",
            "     |              for r in run_infos:\n",
            "     |                  print(\"- run_id: {}, lifecycle_stage: {}\".format(r.run_id, r.lifecycle_stage))\n",
            "     |      \n",
            "     |          # Create two runs\n",
            "     |          with mlflow.start_run() as run1:\n",
            "     |              mlflow.log_metric(\"click_rate\", 1.55)\n",
            "     |      \n",
            "     |          with mlflow.start_run() as run2:\n",
            "     |              mlflow.log_metric(\"click_rate\", 2.50)\n",
            "     |      \n",
            "     |          # Delete the last run\n",
            "     |          client = MlflowClient()\n",
            "     |          client.delete_run(run2.info.run_id)\n",
            "     |      \n",
            "     |          # Get all runs under the default experiment (whose id is 0)\n",
            "     |          print(\"Active runs:\")\n",
            "     |          print_run_infos(mlflow.list_run_infos(\"0\", run_view_type=ViewType.ACTIVE_ONLY))\n",
            "     |      \n",
            "     |          print(\"Deleted runs:\")\n",
            "     |          print_run_infos(mlflow.list_run_infos(\"0\", run_view_type=ViewType.DELETED_ONLY))\n",
            "     |      \n",
            "     |          print(\"All runs:\")\n",
            "     |          print_run_infos(mlflow.list_run_infos(\"0\", run_view_type=ViewType.ALL,\n",
            "     |                          order_by=[\"metric.click_rate DESC\"]))\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |          :caption: Output\n",
            "     |      \n",
            "     |          Active runs:\n",
            "     |          - run_id: 47b11b33f9364ee2b148c41375a30a68, lifecycle_stage: active\n",
            "     |          Deleted runs:\n",
            "     |          - run_id: bc4803439bdd4a059103811267b6b2f4, lifecycle_stage: deleted\n",
            "     |          All runs:\n",
            "     |          - run_id: bc4803439bdd4a059103811267b6b2f4, lifecycle_stage: deleted\n",
            "     |          - run_id: 47b11b33f9364ee2b148c41375a30a68, lifecycle_stage: active\n",
            "     |  \n",
            "     |  log_artifact(self, run_id, local_path, artifact_path=None) -> None\n",
            "     |      Write a local file or directory to the remote ``artifact_uri``.\n",
            "     |      \n",
            "     |      :param local_path: Path to the file or directory to write.\n",
            "     |      :param artifact_path: If provided, the directory in ``artifact_uri`` to write to.\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Example\n",
            "     |      \n",
            "     |          from mlflow import MlflowClient\n",
            "     |      \n",
            "     |          features = \"rooms, zipcode, median_price, school_rating, transport\"\n",
            "     |          with open(\"features.txt\", 'w') as f:\n",
            "     |              f.write(features)\n",
            "     |      \n",
            "     |          # Create a run under the default experiment (whose id is '0').\n",
            "     |          client = MlflowClient()\n",
            "     |          experiment_id = \"0\"\n",
            "     |          run = client.create_run(experiment_id)\n",
            "     |      \n",
            "     |          # log and fetch the artifact\n",
            "     |          client.log_artifact(run.info.run_id, \"features.txt\")\n",
            "     |          artifacts = client.list_artifacts(run.info.run_id)\n",
            "     |          for artifact in artifacts:\n",
            "     |              print(\"artifact: {}\".format(artifact.path))\n",
            "     |              print(\"is_dir: {}\".format(artifact.is_dir))\n",
            "     |          client.set_terminated(run.info.run_id)\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |          :caption: Output\n",
            "     |      \n",
            "     |          artifact: features.txt\n",
            "     |          is_dir: False\n",
            "     |  \n",
            "     |  log_artifacts(self, run_id: str, local_dir: str, artifact_path: Union[str, NoneType] = None) -> None\n",
            "     |      Write a directory of files to the remote ``artifact_uri``.\n",
            "     |      \n",
            "     |      :param local_dir: Path to the directory of files to write.\n",
            "     |      :param artifact_path: If provided, the directory in ``artifact_uri`` to write to.\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Example\n",
            "     |      \n",
            "     |          import os\n",
            "     |          import json\n",
            "     |      \n",
            "     |          # Create some artifacts data to preserve\n",
            "     |          features = \"rooms, zipcode, median_price, school_rating, transport\"\n",
            "     |          data = {\"state\": \"TX\", \"Available\": 25, \"Type\": \"Detached\"}\n",
            "     |      \n",
            "     |          # Create couple of artifact files under the local directory \"data\"\n",
            "     |          os.makedirs(\"data\", exist_ok=True)\n",
            "     |          with open(\"data/data.json\", 'w', encoding='utf-8') as f:\n",
            "     |              json.dump(data, f, indent=2)\n",
            "     |          with open(\"data/features.txt\", 'w') as f:\n",
            "     |              f.write(features)\n",
            "     |      \n",
            "     |          # Create a run under the default experiment (whose id is '0'), and log\n",
            "     |          # all files in \"data\" to root artifact_uri/states\n",
            "     |          client = MlflowClient()\n",
            "     |          experiment_id = \"0\"\n",
            "     |          run = client.create_run(experiment_id)\n",
            "     |          client.log_artifacts(run.info.run_id, \"data\", artifact_path=\"states\")\n",
            "     |          artifacts = client.list_artifacts(run.info.run_id)\n",
            "     |          for artifact in artifacts:\n",
            "     |              print(\"artifact: {}\".format(artifact.path))\n",
            "     |              print(\"is_dir: {}\".format(artifact.is_dir))\n",
            "     |          client.set_terminated(run.info.run_id)\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |          :caption: Output\n",
            "     |      \n",
            "     |          artifact: states\n",
            "     |          is_dir: True\n",
            "     |  \n",
            "     |  log_batch(self, run_id: str, metrics: Sequence[mlflow.entities.metric.Metric] = (), params: Sequence[mlflow.entities.param.Param] = (), tags: Sequence[mlflow.entities.run_tag.RunTag] = ()) -> None\n",
            "     |      Log multiple metrics, params, and/or tags.\n",
            "     |      \n",
            "     |      :param run_id: String ID of the run\n",
            "     |      :param metrics: If provided, List of Metric(key, value, timestamp) instances.\n",
            "     |      :param params: If provided, List of Param(key, value) instances.\n",
            "     |      :param tags: If provided, List of RunTag(key, value) instances.\n",
            "     |      \n",
            "     |      Raises an MlflowException if any errors occur.\n",
            "     |      :return: None\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Example\n",
            "     |      \n",
            "     |          import time\n",
            "     |      \n",
            "     |          from mlflow import MlflowClient\n",
            "     |          from mlflow.entities import Metric, Param, RunTag\n",
            "     |      \n",
            "     |          def print_run_info(r):\n",
            "     |              print(\"run_id: {}\".format(r.info.run_id))\n",
            "     |              print(\"params: {}\".format(r.data.params))\n",
            "     |              print(\"metrics: {}\".format(r.data.metrics))\n",
            "     |              print(\"tags: {}\".format(r.data.tags))\n",
            "     |              print(\"status: {}\".format(r.info.status))\n",
            "     |      \n",
            "     |          # Create MLflow entities and a run under the default experiment (whose id is '0').\n",
            "     |          timestamp = int(time.time() * 1000)\n",
            "     |          metrics = [Metric('m', 1.5, timestamp, 1)]\n",
            "     |          params = [Param(\"p\", 'p')]\n",
            "     |          tags = [RunTag(\"t\", \"t\")]\n",
            "     |          experiment_id = \"0\"\n",
            "     |          client = MlflowClient()\n",
            "     |          run = client.create_run(experiment_id)\n",
            "     |      \n",
            "     |          # Log entities, terminate the run, and fetch run status\n",
            "     |          client.log_batch(run.info.run_id, metrics=metrics, params=params, tags=tags)\n",
            "     |          client.set_terminated(run.info.run_id)\n",
            "     |          run = client.get_run(run.info.run_id)\n",
            "     |          print_run_info(run)\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |          :caption: Output\n",
            "     |      \n",
            "     |          run_id: ef0247fa3205410595acc0f30f620871\n",
            "     |          params: {'p': 'p'}\n",
            "     |          metrics: {'m': 1.5}\n",
            "     |          tags: {'t': 't'}\n",
            "     |          status: FINISHED\n",
            "     |  \n",
            "     |  log_dict(self, run_id: str, dictionary: Any, artifact_file: str) -> None\n",
            "     |      Log a JSON/YAML-serializable object (e.g. `dict`) as an artifact. The serialization\n",
            "     |      format (JSON or YAML) is automatically inferred from the extension of `artifact_file`.\n",
            "     |      If the file extension doesn't exist or match any of [\".json\", \".yml\", \".yaml\"],\n",
            "     |      JSON format is used.\n",
            "     |      \n",
            "     |      :param run_id: String ID of the run.\n",
            "     |      :param dictionary: Dictionary to log.\n",
            "     |      :param artifact_file: The run-relative artifact file path in posixpath format to which\n",
            "     |                            the dictionary is saved (e.g. \"dir/data.json\").\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Example\n",
            "     |      \n",
            "     |          from mlflow import MlflowClient\n",
            "     |      \n",
            "     |          client = MlflowClient()\n",
            "     |          run = client.create_run(experiment_id=\"0\")\n",
            "     |          run_id = run.info.run_id\n",
            "     |      \n",
            "     |          dictionary = {\"k\": \"v\"}\n",
            "     |      \n",
            "     |          # Log a dictionary as a JSON file under the run's root artifact directory\n",
            "     |          client.log_dict(run_id, dictionary, \"data.json\")\n",
            "     |      \n",
            "     |          # Log a dictionary as a YAML file in a subdirectory of the run's root artifact directory\n",
            "     |          client.log_dict(run_id, dictionary, \"dir/data.yml\")\n",
            "     |      \n",
            "     |          # If the file extension doesn't exist or match any of [\".json\", \".yaml\", \".yml\"],\n",
            "     |          # JSON format is used.\n",
            "     |          mlflow.log_dict(run_id, dictionary, \"data\")\n",
            "     |          mlflow.log_dict(run_id, dictionary, \"data.txt\")\n",
            "     |  \n",
            "     |  log_figure(self, run_id: str, figure: Union[ForwardRef('matplotlib.figure.Figure'), ForwardRef('plotly.graph_objects.Figure')], artifact_file: str) -> None\n",
            "     |      Log a figure as an artifact. The following figure objects are supported:\n",
            "     |      \n",
            "     |      - `matplotlib.figure.Figure`_\n",
            "     |      - `plotly.graph_objects.Figure`_\n",
            "     |      \n",
            "     |      .. _matplotlib.figure.Figure:\n",
            "     |          https://matplotlib.org/api/_as_gen/matplotlib.figure.Figure.html\n",
            "     |      \n",
            "     |      .. _plotly.graph_objects.Figure:\n",
            "     |          https://plotly.com/python-api-reference/generated/plotly.graph_objects.Figure.html\n",
            "     |      \n",
            "     |      :param run_id: String ID of the run.\n",
            "     |      :param figure: Figure to log.\n",
            "     |      :param artifact_file: The run-relative artifact file path in posixpath format to which\n",
            "     |                            the figure is saved (e.g. \"dir/file.png\").\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Matplotlib Example\n",
            "     |      \n",
            "     |          import mlflow\n",
            "     |          import matplotlib.pyplot as plt\n",
            "     |      \n",
            "     |          fig, ax = plt.subplots()\n",
            "     |          ax.plot([0, 1], [2, 3])\n",
            "     |      \n",
            "     |          run = client.create_run(experiment_id=\"0\")\n",
            "     |          client.log_figure(run.info.run_id, fig, \"figure.png\")\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Plotly Example\n",
            "     |      \n",
            "     |          import mlflow\n",
            "     |          from plotly import graph_objects as go\n",
            "     |      \n",
            "     |          fig = go.Figure(go.Scatter(x=[0, 1], y=[2, 3]))\n",
            "     |      \n",
            "     |          run = client.create_run(experiment_id=\"0\")\n",
            "     |          client.log_figure(run.info.run_id, fig, \"figure.html\")\n",
            "     |  \n",
            "     |  log_image(self, run_id: str, image: Union[ForwardRef('numpy.ndarray'), ForwardRef('PIL.Image.Image')], artifact_file: str) -> None\n",
            "     |      Log an image as an artifact. The following image objects are supported:\n",
            "     |      \n",
            "     |      - `numpy.ndarray`_\n",
            "     |      - `PIL.Image.Image`_\n",
            "     |      \n",
            "     |      .. _numpy.ndarray:\n",
            "     |          https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html\n",
            "     |      \n",
            "     |      .. _PIL.Image.Image:\n",
            "     |          https://pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.Image\n",
            "     |      \n",
            "     |      Numpy array support\n",
            "     |          - data type (( ) represents a valid value range):\n",
            "     |      \n",
            "     |              - bool\n",
            "     |              - integer (0 ~ 255)\n",
            "     |              - unsigned integer (0 ~ 255)\n",
            "     |              - float (0.0 ~ 1.0)\n",
            "     |      \n",
            "     |              .. warning::\n",
            "     |      \n",
            "     |                  - Out-of-range integer values will be **clipped** to [0, 255].\n",
            "     |                  - Out-of-range float values will be **clipped** to [0, 1].\n",
            "     |      \n",
            "     |          - shape (H: height, W: width):\n",
            "     |      \n",
            "     |              - H x W (Grayscale)\n",
            "     |              - H x W x 1 (Grayscale)\n",
            "     |              - H x W x 3 (an RGB channel order is assumed)\n",
            "     |              - H x W x 4 (an RGBA channel order is assumed)\n",
            "     |      \n",
            "     |      :param run_id: String ID of the run.\n",
            "     |      :param image: Image to log.\n",
            "     |      :param artifact_file: The run-relative artifact file path in posixpath format to which\n",
            "     |                            the image is saved (e.g. \"dir/image.png\").\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Numpy Example\n",
            "     |      \n",
            "     |          import mlflow\n",
            "     |          import numpy as np\n",
            "     |      \n",
            "     |          image = np.random.randint(0, 256, size=(100, 100, 3), dtype=np.uint8)\n",
            "     |      \n",
            "     |          run = client.create_run(experiment_id=\"0\")\n",
            "     |          client.log_image(run.info.run_id, image, \"image.png\")\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Pillow Example\n",
            "     |      \n",
            "     |          import mlflow\n",
            "     |          from PIL import Image\n",
            "     |      \n",
            "     |          image = Image.new(\"RGB\", (100, 100))\n",
            "     |      \n",
            "     |          run = client.create_run(experiment_id=\"0\")\n",
            "     |          client.log_image(run.info.run_id, image, \"image.png\")\n",
            "     |  \n",
            "     |  log_metric(self, run_id: str, key: str, value: float, timestamp: Union[int, NoneType] = None, step: Union[int, NoneType] = None) -> None\n",
            "     |      Log a metric against the run ID.\n",
            "     |      \n",
            "     |      :param run_id: The run id to which the metric should be logged.\n",
            "     |      :param key: Metric name (string). This string may only contain alphanumerics, underscores\n",
            "     |                  (_), dashes (-), periods (.), spaces ( ), and slashes (/).\n",
            "     |                  All backend stores will support keys up to length 250, but some may\n",
            "     |                  support larger keys.\n",
            "     |      :param value: Metric value (float). Note that some special values such\n",
            "     |                    as +/- Infinity may be replaced by other values depending on the store. For\n",
            "     |                    example, the SQLAlchemy store replaces +/- Inf with max / min float values.\n",
            "     |                    All backend stores will support values up to length 5000, but some\n",
            "     |                    may support larger values.\n",
            "     |      :param timestamp: Time when this metric was calculated. Defaults to the current system time.\n",
            "     |      :param step: Integer training step (iteration) at which was the metric calculated.\n",
            "     |                   Defaults to 0.\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Example\n",
            "     |      \n",
            "     |          from mlflow import MlflowClient\n",
            "     |      \n",
            "     |          def print_run_info(r):\n",
            "     |              print(\"run_id: {}\".format(r.info.run_id))\n",
            "     |              print(\"metrics: {}\".format(r.data.metrics))\n",
            "     |              print(\"status: {}\".format(r.info.status))\n",
            "     |      \n",
            "     |          # Create a run under the default experiment (whose id is '0').\n",
            "     |          # Since these are low-level CRUD operations, this method will create a run.\n",
            "     |          # To end the run, you'll have to explicitly end it.\n",
            "     |          client = MlflowClient()\n",
            "     |          experiment_id = \"0\"\n",
            "     |          run = client.create_run(experiment_id)\n",
            "     |          print_run_info(run)\n",
            "     |          print(\"--\")\n",
            "     |      \n",
            "     |          # Log the metric. Unlike mlflow.log_metric this method\n",
            "     |          # does not start a run if one does not exist. It will log\n",
            "     |          # the metric for the run id in the backend store.\n",
            "     |          client.log_metric(run.info.run_id, \"m\", 1.5)\n",
            "     |          client.set_terminated(run.info.run_id)\n",
            "     |          run = client.get_run(run.info.run_id)\n",
            "     |          print_run_info(run)\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |          :caption: Output\n",
            "     |      \n",
            "     |          run_id: 95e79843cb2c463187043d9065185e24\n",
            "     |          metrics: {}\n",
            "     |          status: RUNNING\n",
            "     |          --\n",
            "     |          run_id: 95e79843cb2c463187043d9065185e24\n",
            "     |          metrics: {'m': 1.5}\n",
            "     |          status: FINISHED\n",
            "     |  \n",
            "     |  log_param(self, run_id: str, key: str, value: Any) -> None\n",
            "     |      Log a parameter (e.g. model hyperparameter) against the run ID.\n",
            "     |      \n",
            "     |      :param run_id: The run id to which the param should be logged.\n",
            "     |      :param key: Parameter name (string). This string may only contain alphanumerics, underscores\n",
            "     |                  (_), dashes (-), periods (.), spaces ( ), and slashes (/).\n",
            "     |                  All backend stores support keys up to length 250, but some may\n",
            "     |                  support larger keys.\n",
            "     |      :param value: Parameter value (string, but will be string-ified if not).\n",
            "     |                    All backend stores support values up to length 500, but some\n",
            "     |                    may support larger values.\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Example\n",
            "     |      \n",
            "     |          from mlflow import MlflowClient\n",
            "     |      \n",
            "     |          def print_run_info(r):\n",
            "     |              print(\"run_id: {}\".format(r.info.run_id))\n",
            "     |              print(\"params: {}\".format(r.data.params))\n",
            "     |              print(\"status: {}\".format(r.info.status))\n",
            "     |      \n",
            "     |          # Create a run under the default experiment (whose id is '0').\n",
            "     |          # Since these are low-level CRUD operations, this method will create a run.\n",
            "     |          # To end the run, you'll have to explicitly end it.\n",
            "     |          client = MlflowClient()\n",
            "     |          experiment_id = \"0\"\n",
            "     |          run = client.create_run(experiment_id)\n",
            "     |          print_run_info(run)\n",
            "     |          print(\"--\")\n",
            "     |      \n",
            "     |          # Log the parameter. Unlike mlflow.log_param this method\n",
            "     |          # does not start a run if one does not exist. It will log\n",
            "     |          # the parameter in the backend store\n",
            "     |          client.log_param(run.info.run_id, \"p\", 1)\n",
            "     |          client.set_terminated(run.info.run_id)\n",
            "     |          run = client.get_run(run.info.run_id)\n",
            "     |          print_run_info(run)\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |          :caption: Output\n",
            "     |      \n",
            "     |          run_id: e649e49c7b504be48ee3ae33c0e76c93\n",
            "     |          params: {}\n",
            "     |          status: RUNNING\n",
            "     |          --\n",
            "     |          run_id: e649e49c7b504be48ee3ae33c0e76c93\n",
            "     |          params: {'p': '1'}\n",
            "     |          status: FINISHED\n",
            "     |  \n",
            "     |  log_text(self, run_id: str, text: str, artifact_file: str) -> None\n",
            "     |      Log text as an artifact.\n",
            "     |      \n",
            "     |      :param run_id: String ID of the run.\n",
            "     |      :param text: String containing text to log.\n",
            "     |      :param artifact_file: The run-relative artifact file path in posixpath format to which\n",
            "     |                            the text is saved (e.g. \"dir/file.txt\").\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Example\n",
            "     |      \n",
            "     |          from mlflow import MlflowClient\n",
            "     |      \n",
            "     |          client = MlflowClient()\n",
            "     |          run = client.create_run(experiment_id=\"0\")\n",
            "     |      \n",
            "     |          # Log text to a file under the run's root artifact directory\n",
            "     |          client.log_text(run.info.run_id, \"text1\", \"file1.txt\")\n",
            "     |      \n",
            "     |          # Log text in a subdirectory of the run's root artifact directory\n",
            "     |          client.log_text(run.info.run_id, \"text2\", \"dir/file2.txt\")\n",
            "     |      \n",
            "     |          # Log HTML text\n",
            "     |          client.log_text(run.info.run_id, \"<h1>header</h1>\", \"index.html\")\n",
            "     |  \n",
            "     |  rename_experiment(self, experiment_id: str, new_name: str) -> None\n",
            "     |      Update an experiment's name. The new name must be unique.\n",
            "     |      \n",
            "     |      :param experiment_id: The experiment ID returned from ``create_experiment``.\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Example\n",
            "     |      \n",
            "     |          from mlflow import MlflowClient\n",
            "     |      \n",
            "     |          def print_experiment_info(experiment):\n",
            "     |              print(\"Name: {}\".format(experiment.name))\n",
            "     |              print(\"Experiment_id: {}\".format(experiment.experiment_id))\n",
            "     |              print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))\n",
            "     |      \n",
            "     |          # Create an experiment with a name that is unique and case sensitive\n",
            "     |          client = MlflowClient()\n",
            "     |          experiment_id = client.create_experiment(\"Social NLP Experiments\")\n",
            "     |      \n",
            "     |          # Fetch experiment metadata information\n",
            "     |          experiment = client.get_experiment(experiment_id)\n",
            "     |          print_experiment_info(experiment)\n",
            "     |          print(\"--\")\n",
            "     |      \n",
            "     |          # Rename and fetch experiment metadata information\n",
            "     |          client.rename_experiment(experiment_id, \"Social Media NLP Experiments\")\n",
            "     |          experiment = client.get_experiment(experiment_id)\n",
            "     |          print_experiment_info(experiment)\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |          :caption: Output\n",
            "     |      \n",
            "     |          Name: Social NLP Experiments\n",
            "     |          Experiment_id: 1\n",
            "     |          Lifecycle_stage: active\n",
            "     |          --\n",
            "     |          Name: Social Media NLP Experiments\n",
            "     |          Experiment_id: 1\n",
            "     |          Lifecycle_stage: active\n",
            "     |  \n",
            "     |  rename_registered_model(self, name: str, new_name: str) -> mlflow.entities.model_registry.registered_model.RegisteredModel\n",
            "     |      Update registered model name.\n",
            "     |      \n",
            "     |      :param name: Name of the registered model to update.\n",
            "     |      :param new_name: New proposed name for the registered model.\n",
            "     |      \n",
            "     |      :return: A single updated :py:class:`mlflow.entities.model_registry.RegisteredModel` object.\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Example\n",
            "     |      \n",
            "     |          import mlflow\n",
            "     |          from mlflow import MlflowClient\n",
            "     |      \n",
            "     |          def print_registered_model_info(rm):\n",
            "     |              print(\"name: {}\".format(rm.name))\n",
            "     |              print(\"tags: {}\".format(rm.tags))\n",
            "     |              print(\"description: {}\".format(rm.description))\n",
            "     |      \n",
            "     |          name = \"SocialTextAnalyzer\"\n",
            "     |          tags = {\"nlp.framework\": \"Spark NLP\"}\n",
            "     |          desc = \"This sentiment analysis model classifies the tone-happy, sad, angry.\"\n",
            "     |      \n",
            "     |          # create a new registered model name\n",
            "     |          mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
            "     |          client = MlflowClient()\n",
            "     |          client.create_registered_model(name, tags, desc)\n",
            "     |          print_registered_model_info(client.get_registered_model(name))\n",
            "     |          print(\"--\")\n",
            "     |      \n",
            "     |          # rename the model\n",
            "     |          new_name = \"SocialMediaTextAnalyzer\"\n",
            "     |          client.rename_registered_model(name, new_name)\n",
            "     |          print_registered_model_info(client.get_registered_model(new_name))\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Output\n",
            "     |      \n",
            "     |          name: SocialTextAnalyzer\n",
            "     |          tags: {'nlp.framework': 'Spark NLP'}\n",
            "     |          description: This sentiment analysis model classifies the tone-happy, sad, angry.\n",
            "     |          --\n",
            "     |          name: SocialMediaTextAnalyzer\n",
            "     |          tags: {'nlp.framework': 'Spark NLP'}\n",
            "     |          description: This sentiment analysis model classifies the tone-happy, sad, angry.\n",
            "     |  \n",
            "     |  restore_experiment(self, experiment_id: str) -> None\n",
            "     |      Restore a deleted experiment unless permanently deleted.\n",
            "     |      \n",
            "     |      :param experiment_id: The experiment ID returned from ``create_experiment``.\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Example\n",
            "     |      \n",
            "     |          from mlflow import MlflowClient\n",
            "     |      \n",
            "     |          def print_experiment_info(experiment):\n",
            "     |              print(\"Name: {}\".format(experiment.name))\n",
            "     |              print(\"Experiment Id: {}\".format(experiment.experiment_id))\n",
            "     |              print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))\n",
            "     |      \n",
            "     |          # Create and delete an experiment\n",
            "     |          client = MlflowClient()\n",
            "     |          experiment_id = client.create_experiment(\"New Experiment\")\n",
            "     |          client.delete_experiment(experiment_id)\n",
            "     |      \n",
            "     |          # Examine the deleted experiment details.\n",
            "     |          experiment = client.get_experiment(experiment_id)\n",
            "     |          print_experiment_info(experiment)\n",
            "     |          print(\"--\")\n",
            "     |      \n",
            "     |          # Restore the experiment and fetch its info\n",
            "     |          client.restore_experiment(experiment_id)\n",
            "     |          experiment = client.get_experiment(experiment_id)\n",
            "     |          print_experiment_info(experiment)\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |          :caption: Output\n",
            "     |      \n",
            "     |          Name: New Experiment\n",
            "     |          Experiment Id: 1\n",
            "     |          Lifecycle_stage: deleted\n",
            "     |          --\n",
            "     |          Name: New Experiment\n",
            "     |          Experiment Id: 1\n",
            "     |          Lifecycle_stage: active\n",
            "     |  \n",
            "     |  restore_run(self, run_id: str) -> None\n",
            "     |      Restores a deleted run with the given ID.\n",
            "     |      \n",
            "     |      :param run_id: The unique run id to restore.\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Example\n",
            "     |      \n",
            "     |          from mlflow import MlflowClient\n",
            "     |      \n",
            "     |          # Create a run under the default experiment (whose id is '0').\n",
            "     |          client = MlflowClient()\n",
            "     |          experiment_id = \"0\"\n",
            "     |          run = client.create_run(experiment_id)\n",
            "     |          run_id = run.info.run_id\n",
            "     |          print(\"run_id: {}; lifecycle_stage: {}\".format(run_id, run.info.lifecycle_stage))\n",
            "     |          client.delete_run(run_id)\n",
            "     |          del_run = client.get_run(run_id)\n",
            "     |          print(\"run_id: {}; lifecycle_stage: {}\".format(run_id, del_run.info.lifecycle_stage))\n",
            "     |          client.restore_run(run_id)\n",
            "     |          rest_run = client.get_run(run_id)\n",
            "     |          print(\"run_id: {}; lifecycle_stage: {}\".format(run_id, res_run.info.lifecycle_stage))\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |          :caption: Output\n",
            "     |      \n",
            "     |          run_id: 7bc59754d7e74534a7917d62f2873ac0; lifecycle_stage: active\n",
            "     |          run_id: 7bc59754d7e74534a7917d62f2873ac0; lifecycle_stage: deleted\n",
            "     |          run_id: 7bc59754d7e74534a7917d62f2873ac0; lifecycle_stage: active\n",
            "     |  \n",
            "     |  search_experiments(self, view_type: int = 1, max_results: Union[int, NoneType] = 1000, filter_string: Union[str, NoneType] = None, order_by: Union[List[str], NoneType] = None, page_token=None) -> mlflow.store.entities.paged_list.PagedList[mlflow.entities.experiment.Experiment]\n",
            "     |      .. Note:: Experimental: This method may change or be removed in a future release without warning.\n",
            "     |      \n",
            "     |      \n",
            "     |      Search for experiments that match the specified search query.\n",
            "     |      \n",
            "     |      :param view_type: One of enum values ``ACTIVE_ONLY``, ``DELETED_ONLY``, or ``ALL``\n",
            "     |                        defined in :py:class:`mlflow.entities.ViewType`.\n",
            "     |      :param max_results: Maximum number of experiments desired. Certain server backend may apply\n",
            "     |                          its own limit.\n",
            "     |      :param filter_string:\n",
            "     |          Filter query string (e.g., ``\"name = 'my_experiment'\"``), defaults to searching for all\n",
            "     |          experiments. The following identifiers, comparators, and logical operators are\n",
            "     |          supported.\n",
            "     |      \n",
            "     |          Identifiers\n",
            "     |            - ``name``: Experiment name.\n",
            "     |            - ``tags.<tag_key>``: Experiment tag. If ``tag_key`` contains\n",
            "     |              spaces, it must be wrapped with backticks (e.g., ``\"tags.`extra key`\"``).\n",
            "     |      \n",
            "     |          Comparators\n",
            "     |            - ``=``: Equal to.\n",
            "     |            - ``!=``: Not equal to.\n",
            "     |            - ``LIKE``: Case-sensitive pattern match.\n",
            "     |            - ``ILIKE``: Case-insensitive pattern match.\n",
            "     |      \n",
            "     |          Logical operators\n",
            "     |            - ``AND``: Combines two sub-queries and returns True if both of them are True.\n",
            "     |      \n",
            "     |      :param order_by:\n",
            "     |          List of columns to order by. The ``order_by`` column can contain an optional ``DESC`` or\n",
            "     |          ``ASC`` value (e.g., ``\"name DESC\"``). The default is ``ASC`` so ``\"name\"`` is\n",
            "     |          equivalent to ``\"name ASC\"``. The following identifiers are supported.\n",
            "     |      \n",
            "     |          - ``name``: Experiment name.\n",
            "     |          - ``experiment_id``: Experiment ID.\n",
            "     |      \n",
            "     |      :param page_token: Token specifying the next page of results. It should be obtained from\n",
            "     |                         a ``search_experiments`` call.\n",
            "     |      :return: A :py:class:`PagedList <mlflow.store.entities.PagedList>` of\n",
            "     |               :py:class:`Experiment <mlflow.entities.Experiment>` objects. The pagination token\n",
            "     |               for the next page can be obtained via the ``token`` attribute of the object.\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Example\n",
            "     |      \n",
            "     |          import mlflow\n",
            "     |      \n",
            "     |      \n",
            "     |          def assert_experiment_names_equal(experiments, expected_names):\n",
            "     |              actual_names = [e.name for e in experiments if e.name != \"Default\"]\n",
            "     |              assert actual_names == expected_names, (actual_names, expected_names)\n",
            "     |      \n",
            "     |      \n",
            "     |          mlflow.set_tracking_uri(\"sqlite:///:memory:\")\n",
            "     |          client = mlflow.MlflowClient()\n",
            "     |      \n",
            "     |          # Create experiments\n",
            "     |          for name, tags in [\n",
            "     |              (\"a\", None),\n",
            "     |              (\"b\", None),\n",
            "     |              (\"ab\", {\"k\": \"v\"}),\n",
            "     |              (\"bb\", {\"k\": \"V\"}),\n",
            "     |          ]:\n",
            "     |              client.create_experiment(name, tags=tags)\n",
            "     |      \n",
            "     |          # Search for experiments with name \"a\"\n",
            "     |          experiments = client.search_experiments(filter_string=\"name = 'a'\")\n",
            "     |          assert_experiment_names_equal(experiments, [\"a\"])\n",
            "     |      \n",
            "     |          # Search for experiments with name starting with \"a\"\n",
            "     |          experiments = client.search_experiments(filter_string=\"name LIKE 'a%'\")\n",
            "     |          assert_experiment_names_equal(experiments, [\"ab\", \"a\"])\n",
            "     |      \n",
            "     |          # Search for experiments with tag key \"k\" and value ending with \"v\" or \"V\"\n",
            "     |          experiments = client.search_experiments(filter_string=\"tags.k ILIKE '%v'\")\n",
            "     |          assert_experiment_names_equal(experiments, [\"bb\", \"ab\"])\n",
            "     |      \n",
            "     |          # Search for experiments with name ending with \"b\" and tag {\"k\": \"v\"}\n",
            "     |          experiments = client.search_experiments(filter_string=\"name LIKE '%b' AND tags.k = 'v'\")\n",
            "     |          assert_experiment_names_equal(experiments, [\"ab\"])\n",
            "     |      \n",
            "     |          # Sort experiments by name in ascending order\n",
            "     |          experiments = client.search_experiments(order_by=[\"name\"])\n",
            "     |          assert_experiment_names_equal(experiments, [\"a\", \"ab\", \"b\", \"bb\"])\n",
            "     |      \n",
            "     |          # Sort experiments by ID in descending order\n",
            "     |          experiments = client.search_experiments(order_by=[\"experiment_id DESC\"])\n",
            "     |          assert_experiment_names_equal(experiments, [\"bb\", \"ab\", \"b\", \"a\"])\n",
            "     |  \n",
            "     |  search_model_versions(self, filter_string: str) -> mlflow.store.entities.paged_list.PagedList[mlflow.entities.model_registry.model_version.ModelVersion]\n",
            "     |      Search for model versions in backend that satisfy the filter criteria.\n",
            "     |      \n",
            "     |      :param filter_string: Filter query string\n",
            "     |          (e.g., ``\"name = 'a_model_name' and tag.key = 'value1'\"``),\n",
            "     |          defaults to searching for all model versions. The following identifiers, comparators,\n",
            "     |          and logical operators are supported.\n",
            "     |      \n",
            "     |          Identifiers\n",
            "     |            - ``name``: model name.\n",
            "     |            - ``source_path``: model version source path.\n",
            "     |            - ``run_id``: The id of the mlflow run that generates the model version.\n",
            "     |            - ``tags.<tag_key>``: model version tag. If ``tag_key`` contains spaces, it must be\n",
            "     |              wrapped with backticks (e.g., ``\"tags.`extra key`\"``).\n",
            "     |      \n",
            "     |          Comparators\n",
            "     |            - ``=``: Equal to.\n",
            "     |            - ``!=``: Not equal to.\n",
            "     |            - ``LIKE``: Case-sensitive pattern match.\n",
            "     |            - ``ILIKE``: Case-insensitive pattern match.\n",
            "     |            - ``IN``: In a value list. Only ``run_id`` identifier supports ``IN`` comparator.\n",
            "     |      \n",
            "     |          Logical operators\n",
            "     |            - ``AND``: Combines two sub-queries and returns True if both of them are True.\n",
            "     |      \n",
            "     |      :return: PagedList of :py:class:`mlflow.entities.model_registry.ModelVersion` objects.\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Example\n",
            "     |      \n",
            "     |          import mlflow\n",
            "     |          from mlflow import MlflowClient\n",
            "     |      \n",
            "     |          client = MlflowClient()\n",
            "     |      \n",
            "     |          # Get all versions of the model filtered by name\n",
            "     |          model_name = \"CordobaWeatherForecastModel\"\n",
            "     |          filter_string = \"name='{}'\".format(model_name)\n",
            "     |          results = client.search_model_versions(filter_string)\n",
            "     |          print(\"-\" * 80)\n",
            "     |          for res in results:\n",
            "     |              print(\"name={}; run_id={}; version={}\".format(res.name, res.run_id, res.version))\n",
            "     |      \n",
            "     |          # Get the version of the model filtered by run_id\n",
            "     |          run_id = \"e14afa2f47a040728060c1699968fd43\"\n",
            "     |          filter_string = \"run_id='{}'\".format(run_id)\n",
            "     |          results = client.search_model_versions(filter_string)\n",
            "     |          print(\"-\" * 80)\n",
            "     |          for res in results:\n",
            "     |              print(\"name={}; run_id={}; version={}\".format(res.name, res.run_id, res.version))\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |          :caption: Output\n",
            "     |      \n",
            "     |          ------------------------------------------------------------------------------------\n",
            "     |          name=CordobaWeatherForecastModel; run_id=eaef868ee3d14d10b4299c4c81ba8814; version=1\n",
            "     |          name=CordobaWeatherForecastModel; run_id=e14afa2f47a040728060c1699968fd43; version=2\n",
            "     |          ------------------------------------------------------------------------------------\n",
            "     |          name=CordobaWeatherForecastModel; run_id=e14afa2f47a040728060c1699968fd43; version=2\n",
            "     |  \n",
            "     |  search_registered_models(self, filter_string: Union[str, NoneType] = None, max_results: int = 100, order_by: Union[List[str], NoneType] = None, page_token: Union[str, NoneType] = None) -> mlflow.store.entities.paged_list.PagedList[mlflow.entities.model_registry.registered_model.RegisteredModel]\n",
            "     |      Search for registered models in backend that satisfy the filter criteria.\n",
            "     |      \n",
            "     |      :param filter_string: Filter query string\n",
            "     |          (e.g., ``\"name = 'a_model_name' and tag.key = 'value1'\"``),\n",
            "     |          defaults to searching for all registered models. The following identifiers, comparators,\n",
            "     |          and logical operators are supported.\n",
            "     |      \n",
            "     |          Identifiers\n",
            "     |            - ``name``: registered model name.\n",
            "     |            - ``tags.<tag_key>``: registered model tag. If ``tag_key`` contains spaces, it must be\n",
            "     |              wrapped with backticks (e.g., ``\"tags.`extra key`\"``).\n",
            "     |      \n",
            "     |          Comparators\n",
            "     |            - ``=``: Equal to.\n",
            "     |            - ``!=``: Not equal to.\n",
            "     |            - ``LIKE``: Case-sensitive pattern match.\n",
            "     |            - ``ILIKE``: Case-insensitive pattern match.\n",
            "     |      \n",
            "     |          Logical operators\n",
            "     |            - ``AND``: Combines two sub-queries and returns True if both of them are True.\n",
            "     |      \n",
            "     |      :param max_results: Maximum number of registered models desired.\n",
            "     |      :param order_by: List of column names with ASC|DESC annotation, to be used for ordering\n",
            "     |                       matching search results.\n",
            "     |      :param page_token: Token specifying the next page of results. It should be obtained from\n",
            "     |                          a ``search_registered_models`` call.\n",
            "     |      :return: A PagedList of :py:class:`mlflow.entities.model_registry.RegisteredModel` objects\n",
            "     |              that satisfy the search expressions. The pagination token for the next page can be\n",
            "     |              obtained via the ``token`` attribute of the object.\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Example\n",
            "     |      \n",
            "     |          import mlflow\n",
            "     |          from mlflow import MlflowClient\n",
            "     |      \n",
            "     |          client = MlflowClient()\n",
            "     |      \n",
            "     |          # Get search results filtered by the registered model name\n",
            "     |          model_name=\"CordobaWeatherForecastModel\"\n",
            "     |          filter_string = \"name='{}'\".format(model_name)\n",
            "     |          results = client.search_registered_models(filter_string=filter_string)\n",
            "     |          print(\"-\" * 80)\n",
            "     |          for res in results:\n",
            "     |              for mv in res.latest_versions:\n",
            "     |                  print(\"name={}; run_id={}; version={}\".format(mv.name, mv.run_id, mv.version))\n",
            "     |      \n",
            "     |          # Get search results filtered by the registered model name that matches\n",
            "     |          # prefix pattern\n",
            "     |          filter_string = \"name LIKE 'Boston%'\"\n",
            "     |          results = client.search_registered_models(filter_string=filter_string)\n",
            "     |          for res in results:\n",
            "     |              for mv in res.latest_versions:\n",
            "     |              print(\"name={}; run_id={}; version={}\".format(mv.name, mv.run_id, mv.version))\n",
            "     |      \n",
            "     |          # Get all registered models and order them by ascending order of the names\n",
            "     |          results = client.search_registered_models(order_by=[\"name ASC\"])\n",
            "     |          print(\"-\" * 80)\n",
            "     |          for res in results:\n",
            "     |              for mv in res.latest_versions:\n",
            "     |                  print(\"name={}; run_id={}; version={}\".format(mv.name, mv.run_id, mv.version))\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |          :caption: Output\n",
            "     |      \n",
            "     |          ------------------------------------------------------------------------------------\n",
            "     |          name=CordobaWeatherForecastModel; run_id=eaef868ee3d14d10b4299c4c81ba8814; version=1\n",
            "     |          name=CordobaWeatherForecastModel; run_id=e14afa2f47a040728060c1699968fd43; version=2\n",
            "     |          ------------------------------------------------------------------------------------\n",
            "     |          name=BostonWeatherForecastModel; run_id=ddc51b9407a54b2bb795c8d680e63ff6; version=1\n",
            "     |          name=BostonWeatherForecastModel; run_id=48ac94350fba40639a993e1b3d4c185d; version=2\n",
            "     |          -----------------------------------------------------------------------------------\n",
            "     |          name=AzureWeatherForecastModel; run_id=5fcec6c4f1c947fc9295fef3fa21e52d; version=1\n",
            "     |          name=AzureWeatherForecastModel; run_id=8198cb997692417abcdeb62e99052260; version=3\n",
            "     |          name=BostonWeatherForecastModel; run_id=ddc51b9407a54b2bb795c8d680e63ff6; version=1\n",
            "     |          name=BostonWeatherForecastModel; run_id=48ac94350fba40639a993e1b3d4c185d; version=2\n",
            "     |          name=CordobaWeatherForecastModel; run_id=eaef868ee3d14d10b4299c4c81ba8814; version=1\n",
            "     |          name=CordobaWeatherForecastModel; run_id=e14afa2f47a040728060c1699968fd43; version=2\n",
            "     |  \n",
            "     |  search_runs(self, experiment_ids: List[str], filter_string: str = '', run_view_type: int = 1, max_results: int = 1000, order_by: Union[List[str], NoneType] = None, page_token: Union[str, NoneType] = None) -> mlflow.store.entities.paged_list.PagedList[mlflow.entities.run.Run]\n",
            "     |      Search experiments that fit the search criteria.\n",
            "     |      \n",
            "     |      :param experiment_ids: List of experiment IDs, or a single int or string id.\n",
            "     |      :param filter_string: Filter query string, defaults to searching all runs.\n",
            "     |      :param run_view_type: one of enum values ACTIVE_ONLY, DELETED_ONLY, or ALL runs\n",
            "     |                            defined in :py:class:`mlflow.entities.ViewType`.\n",
            "     |      :param max_results: Maximum number of runs desired.\n",
            "     |      :param order_by: List of columns to order by (e.g., \"metrics.rmse\"). The ``order_by`` column\n",
            "     |                   can contain an optional ``DESC`` or ``ASC`` value. The default is ``ASC``.\n",
            "     |                   The default ordering is to sort by ``start_time DESC``, then ``run_id``.\n",
            "     |      :param page_token: Token specifying the next page of results. It should be obtained from\n",
            "     |          a ``search_runs`` call.\n",
            "     |      \n",
            "     |      :return: A :py:class:`PagedList <mlflow.store.entities.PagedList>` of\n",
            "     |          :py:class:`Run <mlflow.entities.Run>` objects that satisfy the search expressions.\n",
            "     |          If the underlying tracking store supports pagination, the token for the next page may\n",
            "     |          be obtained via the ``token`` attribute of the returned object.\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Example\n",
            "     |      \n",
            "     |          import mlflow\n",
            "     |          from mlflow import MlflowClient\n",
            "     |          from mlflow.entities import ViewType\n",
            "     |      \n",
            "     |          def print_run_info(runs):\n",
            "     |              for r in runs:\n",
            "     |                  print(\"run_id: {}\".format(r.info.run_id))\n",
            "     |                  print(\"lifecycle_stage: {}\".format(r.info.lifecycle_stage))\n",
            "     |                  print(\"metrics: {}\".format(r.data.metrics))\n",
            "     |      \n",
            "     |                  # Exclude mlflow system tags\n",
            "     |                  tags = {k: v for k, v in r.data.tags.items() if not k.startswith(\"mlflow.\")}\n",
            "     |                  print(\"tags: {}\".format(tags))\n",
            "     |      \n",
            "     |          # Create an experiment and log two runs with metrics and tags under the experiment\n",
            "     |          experiment_id = mlflow.create_experiment(\"Social NLP Experiments\")\n",
            "     |          with mlflow.start_run(experiment_id=experiment_id) as run:\n",
            "     |              mlflow.log_metric(\"m\", 1.55)\n",
            "     |              mlflow.set_tag(\"s.release\", \"1.1.0-RC\")\n",
            "     |          with mlflow.start_run(experiment_id=experiment_id):\n",
            "     |              mlflow.log_metric(\"m\", 2.50)\n",
            "     |              mlflow.set_tag(\"s.release\", \"1.2.0-GA\")\n",
            "     |      \n",
            "     |          # Search all runs under experiment id and order them by\n",
            "     |          # descending value of the metric 'm'\n",
            "     |          client = MlflowClient()\n",
            "     |          runs = client.search_runs(experiment_id, order_by=[\"metrics.m DESC\"])\n",
            "     |          print_run_info(runs)\n",
            "     |          print(\"--\")\n",
            "     |      \n",
            "     |          # Delete the first run\n",
            "     |          client.delete_run(run_id=run.info.run_id)\n",
            "     |      \n",
            "     |          # Search only deleted runs under the experiment id and use a case insensitive pattern\n",
            "     |          # in the filter_string for the tag.\n",
            "     |          filter_string = \"tags.s.release ILIKE '%rc%'\"\n",
            "     |          runs = client.search_runs(experiment_id, run_view_type=ViewType.DELETED_ONLY,\n",
            "     |                                      filter_string=filter_string)\n",
            "     |          print_run_info(runs)\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |          :caption: Output\n",
            "     |      \n",
            "     |          run_id: 0efb2a68833d4ee7860a964fad31cb3f\n",
            "     |          lifecycle_stage: active\n",
            "     |          metrics: {'m': 2.5}\n",
            "     |          tags: {'s.release': '1.2.0-GA'}\n",
            "     |          run_id: 7ab027fd72ee4527a5ec5eafebb923b8\n",
            "     |          lifecycle_stage: active\n",
            "     |          metrics: {'m': 1.55}\n",
            "     |          tags: {'s.release': '1.1.0-RC'}\n",
            "     |          --\n",
            "     |          run_id: 7ab027fd72ee4527a5ec5eafebb923b8\n",
            "     |          lifecycle_stage: deleted\n",
            "     |          metrics: {'m': 1.55}\n",
            "     |          tags: {'s.release': '1.1.0-RC'}\n",
            "     |  \n",
            "     |  set_experiment_tag(self, experiment_id: str, key: str, value: Any) -> None\n",
            "     |      Set a tag on the experiment with the specified ID. Value is converted to a string.\n",
            "     |      \n",
            "     |      :param experiment_id: String ID of the experiment.\n",
            "     |      :param key: Name of the tag.\n",
            "     |      :param value: Tag value (converted to a string).\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Example\n",
            "     |      \n",
            "     |          from mlflow import MlflowClient\n",
            "     |      \n",
            "     |          # Create an experiment and set its tag\n",
            "     |          client = MlflowClient()\n",
            "     |          experiment_id = client.create_experiment(\"Social Media NLP Experiments\")\n",
            "     |          client.set_experiment_tag(experiment_id, \"nlp.framework\", \"Spark NLP\")\n",
            "     |      \n",
            "     |          # Fetch experiment metadata information\n",
            "     |          experiment = client.get_experiment(experiment_id)\n",
            "     |          print(\"Name: {}\".format(experiment.name))\n",
            "     |          print(\"Tags: {}\".format(experiment.tags))\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |          :caption: Output\n",
            "     |      \n",
            "     |          Name: Social Media NLP Experiments\n",
            "     |          Tags: {'nlp.framework': 'Spark NLP'}\n",
            "     |  \n",
            "     |  set_model_version_tag(self, name: str, version: str = None, key: str = None, value: Any = None, stage: str = None) -> None\n",
            "     |      Set a tag for the model version.\n",
            "     |      When stage is set, tag will be set for latest model version of the stage.\n",
            "     |      Setting both version and stage parameter will result in error.\n",
            "     |      \n",
            "     |      :param name: Registered model name.\n",
            "     |      :param version: Registered model version.\n",
            "     |      :param key: Tag key to log. key is required.\n",
            "     |      :param value: Tag value to log. value is required.\n",
            "     |      :param stage: Registered model stage.\n",
            "     |      :return: None\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Example\n",
            "     |      \n",
            "     |          import mlflow.sklearn\n",
            "     |          from mlflow import MlflowClient\n",
            "     |          from sklearn.ensemble import RandomForestRegressor\n",
            "     |      \n",
            "     |          def print_model_version_info(mv):\n",
            "     |              print(\"Name: {}\".format(mv.name))\n",
            "     |              print(\"Version: {}\".format(mv.version))\n",
            "     |              print(\"Tags: {}\".format(mv.tags))\n",
            "     |      \n",
            "     |          mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
            "     |          params = {\"n_estimators\": 3, \"random_state\": 42}\n",
            "     |          name = \"RandomForestRegression\"\n",
            "     |          rfr = RandomForestRegressor(**params).fit([[0, 1]], [1])\n",
            "     |      \n",
            "     |          # Log MLflow entities\n",
            "     |          with mlflow.start_run() as run:\n",
            "     |              mlflow.log_params(params)\n",
            "     |              mlflow.sklearn.log_model(rfr, artifact_path=\"sklearn-model\")\n",
            "     |      \n",
            "     |          # Register model name in the model registry\n",
            "     |          client = MlflowClient()\n",
            "     |          client.create_registered_model(name)\n",
            "     |      \n",
            "     |          # Create a new version of the rfr model under the registered model name\n",
            "     |          # and set a tag\n",
            "     |          model_uri = \"runs:/{}/sklearn-model\".format(run.info.run_id)\n",
            "     |          mv = client.create_model_version(name, model_uri, run.info.run_id)\n",
            "     |          print_model_version_info(mv)\n",
            "     |          print(\"--\")\n",
            "     |      \n",
            "     |          # Tag using model version\n",
            "     |          client.set_model_version_tag(name, mv.version, \"t\", \"1\")\n",
            "     |      \n",
            "     |          # Tag using model stage\n",
            "     |          client.set_model_version_tag(name, key=\"t1\", value=\"1\", stage=mv.current_stage)\n",
            "     |      \n",
            "     |          mv = client.get_model_version(name, mv.version)\n",
            "     |          print_model_version_info(mv)\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |          :caption: Output\n",
            "     |      \n",
            "     |          Name: RandomForestRegression\n",
            "     |          Version: 1\n",
            "     |          Tags: {}\n",
            "     |          --\n",
            "     |          Name: RandomForestRegression\n",
            "     |          Version: 1\n",
            "     |          Tags: {'t': '1', 't1': '1'}\n",
            "     |  \n",
            "     |  set_registered_model_tag(self, name, key, value) -> None\n",
            "     |      Set a tag for the registered model.\n",
            "     |      \n",
            "     |      :param name: Registered model name.\n",
            "     |      :param key: Tag key to log.\n",
            "     |      :param value: Tag value log.\n",
            "     |      :return: None\n",
            "     |      \n",
            "     |      .. code-block:: Python\n",
            "     |          :caption: Example\n",
            "     |      \n",
            "     |          import mlflow\n",
            "     |          from mlflow import MlflowClient\n",
            "     |      \n",
            "     |          def print_model_info(rm):\n",
            "     |              print(\"--\")\n",
            "     |              print(\"name: {}\".format(rm.name))\n",
            "     |              print(\"tags: {}\".format(rm.tags))\n",
            "     |      \n",
            "     |          name = \"SocialMediaTextAnalyzer\"\n",
            "     |          tags = {\"nlp.framework1\": \"Spark NLP\"}\n",
            "     |          mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
            "     |          client = MlflowClient()\n",
            "     |      \n",
            "     |          # Create registered model, set an additional tag, and fetch\n",
            "     |          # update model info\n",
            "     |          client.create_registered_model(name, tags, desc)\n",
            "     |          model = client.get_registered_model(name)\n",
            "     |          print_model_info(model)\n",
            "     |      \n",
            "     |          client.set_registered_model_tag(name, \"nlp.framework2\", \"VADER\")\n",
            "     |          model = client.get_registered_model(name)\n",
            "     |          print_model_info(model)\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |          :caption: Output\n",
            "     |      \n",
            "     |          --\n",
            "     |          name: SocialMediaTextAnalyzer\n",
            "     |          tags: {'nlp.framework1': 'Spark NLP'}\n",
            "     |          --\n",
            "     |          name: SocialMediaTextAnalyzer\n",
            "     |          tags: {'nlp.framework1': 'Spark NLP', 'nlp.framework2': 'VADER'}\n",
            "     |  \n",
            "     |  set_tag(self, run_id: str, key: str, value: Any) -> None\n",
            "     |      Set a tag on the run with the specified ID. Value is converted to a string.\n",
            "     |      \n",
            "     |      :param run_id: String ID of the run.\n",
            "     |      :param key: Tag name (string). This string may only contain alphanumerics,\n",
            "     |                  underscores (_), dashes (-), periods (.), spaces ( ), and slashes (/).\n",
            "     |                  All backend stores will support keys up to length 250, but some may\n",
            "     |                  support larger keys.\n",
            "     |      :param value: Tag value (string, but will be string-ified if not).\n",
            "     |                    All backend stores will support values up to length 5000, but some\n",
            "     |                    may support larger values.\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Example\n",
            "     |      \n",
            "     |          from mlflow import MlflowClient\n",
            "     |      \n",
            "     |          def print_run_info(run):\n",
            "     |              print(\"run_id: {}\".format(run.info.run_id))\n",
            "     |              print(\"Tags: {}\".format(run.data.tags))\n",
            "     |      \n",
            "     |          # Create a run under the default experiment (whose id is '0').\n",
            "     |          client = MlflowClient()\n",
            "     |          experiment_id = \"0\"\n",
            "     |          run = client.create_run(experiment_id)\n",
            "     |          print_run_info(run)\n",
            "     |          print(\"--\")\n",
            "     |      \n",
            "     |          # Set a tag and fetch updated run info\n",
            "     |          client.set_tag(run.info.run_id, \"nlp.framework\", \"Spark NLP\")\n",
            "     |          run = client.get_run(run.info.run_id)\n",
            "     |          print_run_info(run)\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |          :caption: Output\n",
            "     |      \n",
            "     |          run_id: 4f226eb5758145e9b28f78514b59a03b\n",
            "     |          Tags: {}\n",
            "     |          --\n",
            "     |          run_id: 4f226eb5758145e9b28f78514b59a03b\n",
            "     |          Tags: {'nlp.framework': 'Spark NLP'}\n",
            "     |  \n",
            "     |  set_terminated(self, run_id: str, status: Union[str, NoneType] = None, end_time: Union[int, NoneType] = None) -> None\n",
            "     |      Set a run's status to terminated.\n",
            "     |      \n",
            "     |      :param status: A string value of :py:class:`mlflow.entities.RunStatus`.\n",
            "     |                     Defaults to \"FINISHED\".\n",
            "     |      :param end_time: If not provided, defaults to the current time.\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Example\n",
            "     |      \n",
            "     |          from mlflow import MlflowClient\n",
            "     |      \n",
            "     |          def print_run_info(r):\n",
            "     |              print(\"run_id: {}\".format(r.info.run_id))\n",
            "     |              print(\"status: {}\".format(r.info.status))\n",
            "     |      \n",
            "     |          # Create a run under the default experiment (whose id is '0').\n",
            "     |          # Since this is low-level CRUD operation, this method will create a run.\n",
            "     |          # To end the run, you'll have to explicitly terminate it.\n",
            "     |          client = MlflowClient()\n",
            "     |          experiment_id = \"0\"\n",
            "     |          run = client.create_run(experiment_id)\n",
            "     |          print_run_info(run)\n",
            "     |          print(\"--\")\n",
            "     |      \n",
            "     |          # Terminate the run and fetch updated status. By default,\n",
            "     |          # the status is set to \"FINISHED\". Other values you can\n",
            "     |          # set are \"KILLED\", \"FAILED\", \"RUNNING\", or \"SCHEDULED\".\n",
            "     |          client.set_terminated(run.info.run_id, status=\"KILLED\")\n",
            "     |          run = client.get_run(run.info.run_id)\n",
            "     |          print_run_info(run)\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |          :caption: Output\n",
            "     |      \n",
            "     |          run_id: 575fb62af83f469e84806aee24945973\n",
            "     |          status: RUNNING\n",
            "     |          --\n",
            "     |          run_id: 575fb62af83f469e84806aee24945973\n",
            "     |          status: KILLED\n",
            "     |  \n",
            "     |  transition_model_version_stage(self, name: str, version: str, stage: str, archive_existing_versions: bool = False) -> mlflow.entities.model_registry.model_version.ModelVersion\n",
            "     |      Update model version stage.\n",
            "     |      \n",
            "     |      :param name: Registered model name.\n",
            "     |      :param version: Registered model version.\n",
            "     |      :param stage: New desired stage for this model version.\n",
            "     |      :param archive_existing_versions: If this flag is set to ``True``, all existing model\n",
            "     |          versions in the stage will be automatically moved to the \"archived\" stage. Only valid\n",
            "     |          when ``stage`` is ``\"staging\"`` or ``\"production\"`` otherwise an error will be raised.\n",
            "     |      \n",
            "     |      :return: A single :py:class:`mlflow.entities.model_registry.ModelVersion` object.\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Example\n",
            "     |      \n",
            "     |          import mlflow.sklearn\n",
            "     |          from mlflow import MlflowClient\n",
            "     |          from sklearn.ensemble import RandomForestRegressor\n",
            "     |      \n",
            "     |          def print_model_version_info(mv):\n",
            "     |              print(\"Name: {}\".format(mv.name))\n",
            "     |              print(\"Version: {}\".format(mv.version))\n",
            "     |              print(\"Description: {}\".format(mv.description))\n",
            "     |              print(\"Stage: {}\".format(mv.current_stage))\n",
            "     |      \n",
            "     |          mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
            "     |          params = {\"n_estimators\": 3, \"random_state\": 42}\n",
            "     |          name = \"RandomForestRegression\"\n",
            "     |          desc = \"A new version of the model using ensemble trees\"\n",
            "     |          rfr = RandomForestRegressor(**params).fit([[0, 1]], [1])\n",
            "     |      \n",
            "     |          # Log MLflow entities\n",
            "     |          with mlflow.start_run() as run:\n",
            "     |              mlflow.log_params(params)\n",
            "     |              mlflow.sklearn.log_model(rfr, artifact_path=\"sklearn-model\")\n",
            "     |      \n",
            "     |           # Register model name in the model registry\n",
            "     |          client = MlflowClient()\n",
            "     |          client.create_registered_model(name)\n",
            "     |      \n",
            "     |           # Create a new version of the rfr model under the registered model name\n",
            "     |          model_uri = \"runs:/{}/sklearn-model\".format(run.info.run_id)\n",
            "     |          mv = client.create_model_version(name, model_uri, run.info.run_id, description=desc)\n",
            "     |          print_model_version_info(mv)\n",
            "     |          print(\"--\")\n",
            "     |      \n",
            "     |          # transition model version from None -> staging\n",
            "     |          mv = client.transition_model_version_stage(name, mv.version, \"staging\")\n",
            "     |          print_model_version_info(mv)\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |          :caption: Output\n",
            "     |      \n",
            "     |          Name: RandomForestRegression\n",
            "     |          Version: 1\n",
            "     |          Description: A new version of the model using ensemble trees\n",
            "     |          Stage: None\n",
            "     |          --\n",
            "     |          Name: RandomForestRegression\n",
            "     |          Version: 1\n",
            "     |          Description: A new version of the model using ensemble trees\n",
            "     |          Stage: Staging\n",
            "     |  \n",
            "     |  update_model_version(self, name: str, version: str, description: Union[str, NoneType] = None) -> mlflow.entities.model_registry.model_version.ModelVersion\n",
            "     |      Update metadata associated with a model version in backend.\n",
            "     |      \n",
            "     |      :param name: Name of the containing registered model.\n",
            "     |      :param version: Version number of the model version.\n",
            "     |      :param description: New description.\n",
            "     |      \n",
            "     |      :return: A single :py:class:`mlflow.entities.model_registry.ModelVersion` object.\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Example\n",
            "     |      \n",
            "     |          import mlflow.sklearn\n",
            "     |          from mlflow import MlflowClient\n",
            "     |          from sklearn.ensemble import RandomForestRegressor\n",
            "     |      \n",
            "     |          def print_model_version_info(mv):\n",
            "     |              print(\"Name: {}\".format(mv.name))\n",
            "     |              print(\"Version: {}\".format(mv.version))\n",
            "     |              print(\"Description: {}\".format(mv.description))\n",
            "     |      \n",
            "     |          mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
            "     |          params = {\"n_estimators\": 3, \"random_state\": 42}\n",
            "     |          name = \"RandomForestRegression\"\n",
            "     |          rfr = RandomForestRegressor(**params).fit([[0, 1]], [1])\n",
            "     |      \n",
            "     |          # Log MLflow entities\n",
            "     |          with mlflow.start_run() as run:\n",
            "     |              mlflow.log_params(params)\n",
            "     |              mlflow.sklearn.log_model(rfr, artifact_path=\"sklearn-model\")\n",
            "     |      \n",
            "     |          # Register model name in the model registry\n",
            "     |          client = MlflowClient()\n",
            "     |          client.create_registered_model(name)\n",
            "     |      \n",
            "     |          # Create a new version of the rfr model under the registered model name\n",
            "     |          model_uri = \"runs:/{}/sklearn-model\".format(run.info.run_id)\n",
            "     |          mv = client.create_model_version(name, model_uri, run.info.run_id)\n",
            "     |          print_model_version_info(mv)\n",
            "     |          print(\"--\")\n",
            "     |      \n",
            "     |          # Update model version's description\n",
            "     |          desc = \"A new version of the model using ensemble trees\"\n",
            "     |          mv = client.update_model_version(name, mv.version, desc)\n",
            "     |          print_model_version_info(mv)\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |          :caption: Output\n",
            "     |      \n",
            "     |          Name: RandomForestRegression\n",
            "     |          Version: 1\n",
            "     |          Description: None\n",
            "     |          --\n",
            "     |          Name: RandomForestRegression\n",
            "     |          Version: 1\n",
            "     |          Description: A new version of the model using ensemble trees\n",
            "     |  \n",
            "     |  update_registered_model(self, name: str, description: Union[str, NoneType] = None) -> mlflow.entities.model_registry.registered_model.RegisteredModel\n",
            "     |      Updates metadata for RegisteredModel entity. Input field ``description`` should be non-None.\n",
            "     |      Backend raises exception if a registered model with given name does not exist.\n",
            "     |      \n",
            "     |      :param name: Name of the registered model to update.\n",
            "     |      :param description: (Optional) New description.\n",
            "     |      :return: A single updated :py:class:`mlflow.entities.model_registry.RegisteredModel` object.\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |          :caption: Example\n",
            "     |      \n",
            "     |          def print_registered_model_info(rm):\n",
            "     |              print(\"name: {}\".format(rm.name))\n",
            "     |              print(\"tags: {}\".format(rm.tags))\n",
            "     |              print(\"description: {}\".format(rm.description))\n",
            "     |      \n",
            "     |          name = \"SocialMediaTextAnalyzer\"\n",
            "     |          tags = {\"nlp.framework\": \"Spark NLP\"}\n",
            "     |          desc = \"This sentiment analysis model classifies the tone-happy, sad, angry.\"\n",
            "     |      \n",
            "     |          mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
            "     |          client = MlflowClient()\n",
            "     |          client.create_registered_model(name, tags, desc)\n",
            "     |          print_registered_model_info(client.get_registered_model(name))\n",
            "     |          print(\"--\")\n",
            "     |      \n",
            "     |          # Update the model's description\n",
            "     |          desc = \"This sentiment analysis model classifies tweets' tone: happy, sad, angry.\"\n",
            "     |          client.update_registered_model(name, desc)\n",
            "     |          print_registered_model_info(client.get_registered_model(name))\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |          :caption: Output\n",
            "     |      \n",
            "     |          name: SocialMediaTextAnalyzer\n",
            "     |          tags: {'nlp.framework': 'Spark NLP'}\n",
            "     |          description: This sentiment analysis model classifies the tone-happy, sad, angry.\n",
            "     |          --\n",
            "     |          name: SocialMediaTextAnalyzer\n",
            "     |          tags: {'nlp.framework': 'Spark NLP'}\n",
            "     |          description: This sentiment analysis model classifies tweets' tone: happy, sad, angry.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors defined here:\n",
            "     |  \n",
            "     |  __dict__\n",
            "     |      dictionary for instance variables (if defined)\n",
            "     |  \n",
            "     |  __weakref__\n",
            "     |      list of weak references to the object (if defined)\n",
            "     |  \n",
            "     |  tracking_uri\n",
            "\n",
            "FUNCTIONS\n",
            "    active_run() -> Union[mlflow.tracking.fluent.ActiveRun, NoneType]\n",
            "        Get the currently active ``Run``, or None if no such run exists.\n",
            "        \n",
            "        **Note**: You cannot access currently-active run attributes\n",
            "        (parameters, metrics, etc.) through the run returned by ``mlflow.active_run``. In order\n",
            "        to access such attributes, use the :py:class:`mlflow.client.MlflowClient` as follows:\n",
            "        \n",
            "        .. code-block:: python\n",
            "            :caption: Example\n",
            "        \n",
            "            import mlflow\n",
            "        \n",
            "            mlflow.start_run()\n",
            "            run = mlflow.active_run()\n",
            "            print(\"Active run_id: {}\".format(run.info.run_id))\n",
            "            mlflow.end_run()\n",
            "        \n",
            "        .. code-block:: text\n",
            "            :caption: Output\n",
            "        \n",
            "            Active run_id: 6f252757005748708cd3aad75d1ff462\n",
            "    \n",
            "    autolog(log_input_examples: bool = False, log_model_signatures: bool = True, log_models: bool = True, disable: bool = False, exclusive: bool = False, disable_for_unsupported_versions: bool = False, silent: bool = False) -> None\n",
            "        Enables (or disables) and configures autologging for all supported integrations.\n",
            "        \n",
            "        The parameters are passed to any autologging integrations that support them.\n",
            "        \n",
            "        See the :ref:`tracking docs <automatic-logging>` for a list of supported autologging\n",
            "        integrations.\n",
            "        \n",
            "        Note that framework-specific configurations set at any point will take precedence over\n",
            "        any configurations set by this function. For example:\n",
            "        \n",
            "        .. code-block:: python\n",
            "        \n",
            "            mlflow.autolog(log_models=False, exclusive=True)\n",
            "            import sklearn\n",
            "        \n",
            "        would enable autologging for `sklearn` with `log_models=False` and `exclusive=True`,\n",
            "        but\n",
            "        \n",
            "        .. code-block:: python\n",
            "        \n",
            "            mlflow.autolog(log_models=False, exclusive=True)\n",
            "            import sklearn\n",
            "            mlflow.sklearn.autolog(log_models=True)\n",
            "        \n",
            "        would enable autologging for `sklearn` with `log_models=True` and `exclusive=False`,\n",
            "        the latter resulting from the default value for `exclusive` in `mlflow.sklearn.autolog`;\n",
            "        other framework autolog functions (e.g. `mlflow.tensorflow.autolog`) would use the\n",
            "        configurations set by `mlflow.autolog` (in this instance, `log_models=False`, `exclusive=True`),\n",
            "        until they are explicitly called by the user.\n",
            "        \n",
            "        :param log_input_examples: If ``True``, input examples from training datasets are collected and\n",
            "                                   logged along with model artifacts during training. If ``False``,\n",
            "                                   input examples are not logged.\n",
            "                                   Note: Input examples are MLflow model attributes\n",
            "                                   and are only collected if ``log_models`` is also ``True``.\n",
            "        :param log_model_signatures: If ``True``,\n",
            "                                     :py:class:`ModelSignatures <mlflow.models.ModelSignature>`\n",
            "                                     describing model inputs and outputs are collected and logged along\n",
            "                                     with model artifacts during training. If ``False``, signatures are\n",
            "                                     not logged. Note: Model signatures are MLflow model attributes\n",
            "                                     and are only collected if ``log_models`` is also ``True``.\n",
            "        :param log_models: If ``True``, trained models are logged as MLflow model artifacts.\n",
            "                           If ``False``, trained models are not logged.\n",
            "                           Input examples and model signatures, which are attributes of MLflow models,\n",
            "                           are also omitted when ``log_models`` is ``False``.\n",
            "        :param disable: If ``True``, disables all supported autologging integrations. If ``False``,\n",
            "                        enables all supported autologging integrations.\n",
            "        :param exclusive: If ``True``, autologged content is not logged to user-created fluent runs.\n",
            "                          If ``False``, autologged content is logged to the active fluent run,\n",
            "                          which may be user-created.\n",
            "        :param disable_for_unsupported_versions: If ``True``, disable autologging for versions of\n",
            "                          all integration libraries that have not been tested against this version\n",
            "                          of the MLflow client or are incompatible.\n",
            "        :param silent: If ``True``, suppress all event logs and warnings from MLflow during autologging\n",
            "                       setup and training execution. If ``False``, show all events and warnings during\n",
            "                       autologging setup and training execution.\n",
            "        \n",
            "        .. code-block:: python\n",
            "            :caption: Example\n",
            "        \n",
            "            import numpy as np\n",
            "            import mlflow.sklearn\n",
            "            from mlflow import MlflowClient\n",
            "            from sklearn.linear_model import LinearRegression\n",
            "        \n",
            "            def print_auto_logged_info(r):\n",
            "                tags = {k: v for k, v in r.data.tags.items() if not k.startswith(\"mlflow.\")}\n",
            "                artifacts = [f.path for f in MlflowClient().list_artifacts(r.info.run_id, \"model\")]\n",
            "                print(\"run_id: {}\".format(r.info.run_id))\n",
            "                print(\"artifacts: {}\".format(artifacts))\n",
            "                print(\"params: {}\".format(r.data.params))\n",
            "                print(\"metrics: {}\".format(r.data.metrics))\n",
            "                print(\"tags: {}\".format(tags))\n",
            "        \n",
            "            # prepare training data\n",
            "            X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
            "            y = np.dot(X, np.array([1, 2])) + 3\n",
            "        \n",
            "            # Auto log all the parameters, metrics, and artifacts\n",
            "            mlflow.autolog()\n",
            "            model = LinearRegression()\n",
            "            with mlflow.start_run() as run:\n",
            "                model.fit(X, y)\n",
            "        \n",
            "            # fetch the auto logged parameters and metrics for ended run\n",
            "            print_auto_logged_info(mlflow.get_run(run_id=run.info.run_id))\n",
            "        \n",
            "        .. code-block:: text\n",
            "            :caption: Output\n",
            "        \n",
            "            run_id: fd10a17d028c47399a55ab8741721ef7\n",
            "            artifacts: ['model/MLmodel', 'model/conda.yaml', 'model/model.pkl']\n",
            "            params: {'copy_X': 'True',\n",
            "                     'normalize': 'False',\n",
            "                     'fit_intercept': 'True',\n",
            "                     'n_jobs': 'None'}\n",
            "            metrics: {'training_score': 1.0,\n",
            "                      'training_rmse': 4.440892098500626e-16,\n",
            "                      'training_r2_score': 1.0,\n",
            "                      'training_mae': 2.220446049250313e-16,\n",
            "                      'training_mse': 1.9721522630525295e-31}\n",
            "            tags: {'estimator_class': 'sklearn.linear_model._base.LinearRegression',\n",
            "                   'estimator_name': 'LinearRegression'}\n",
            "    \n",
            "    create_experiment(name: str, artifact_location: Union[str, NoneType] = None, tags: Union[Dict[str, Any], NoneType] = None) -> str\n",
            "        Create an experiment.\n",
            "        \n",
            "        :param name: The experiment name, which must be unique and is case sensitive\n",
            "        :param artifact_location: The location to store run artifacts.\n",
            "                                  If not provided, the server picks an appropriate default.\n",
            "        :param tags: An optional dictionary of string keys and values to set as\n",
            "                                tags on the experiment.\n",
            "        :return: String ID of the created experiment.\n",
            "        \n",
            "        .. code-block:: python\n",
            "            :caption: Example\n",
            "        \n",
            "            import mlflow\n",
            "            from pathlib import Path\n",
            "        \n",
            "            # Create an experiment name, which must be unique and case sensitive\n",
            "            experiment_id = mlflow.create_experiment(\n",
            "                \"Social NLP Experiments\",\n",
            "                artifact_location=Path.cwd().joinpath(\"mlruns\").as_uri(),\n",
            "                tags={\"version\": \"v1\", \"priority\": \"P1\"},\n",
            "            )\n",
            "            experiment = mlflow.get_experiment(experiment_id)\n",
            "            print(\"Name: {}\".format(experiment.name))\n",
            "            print(\"Experiment_id: {}\".format(experiment.experiment_id))\n",
            "            print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
            "            print(\"Tags: {}\".format(experiment.tags))\n",
            "            print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))\n",
            "        \n",
            "        .. code-block:: text\n",
            "            :caption: Output\n",
            "        \n",
            "            Name: Social NLP Experiments\n",
            "            Experiment_id: 1\n",
            "            Artifact Location: file:///.../mlruns\n",
            "            Tags: {'version': 'v1', 'priority': 'P1'}\n",
            "            Lifecycle_stage: active\n",
            "    \n",
            "    delete_experiment(experiment_id: str) -> None\n",
            "        Delete an experiment from the backend store.\n",
            "        \n",
            "        :param experiment_id: The The string-ified experiment ID returned from ``create_experiment``.\n",
            "        \n",
            "        .. code-block:: python\n",
            "            :caption: Example\n",
            "        \n",
            "            import mlflow\n",
            "        \n",
            "            experiment_id = mlflow.create_experiment(\"New Experiment\")\n",
            "            mlflow.delete_experiment(experiment_id)\n",
            "        \n",
            "            # Examine the deleted experiment details.\n",
            "            experiment = mlflow.get_experiment(experiment_id)\n",
            "            print(\"Name: {}\".format(experiment.name))\n",
            "            print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
            "            print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))\n",
            "        \n",
            "        .. code-block:: text\n",
            "            :caption: Output\n",
            "        \n",
            "            Name: New Experiment\n",
            "            Artifact Location: file:///.../mlruns/2\n",
            "            Lifecycle_stage: deleted\n",
            "    \n",
            "    delete_run(run_id: str) -> None\n",
            "        Deletes a run with the given ID.\n",
            "        \n",
            "        :param run_id: Unique identifier for the run to delete.\n",
            "        \n",
            "        .. code-block:: python\n",
            "            :caption: Example\n",
            "        \n",
            "            import mlflow\n",
            "        \n",
            "            with mlflow.start_run() as run:\n",
            "                mlflow.log_param(\"p\", 0)\n",
            "        \n",
            "            run_id = run.info.run_id\n",
            "            mlflow.delete_run(run_id)\n",
            "        \n",
            "            print(\"run_id: {}; lifecycle_stage: {}\".format(run_id,\n",
            "                mlflow.get_run(run_id).info.lifecycle_stage))\n",
            "        \n",
            "        .. code-block:: text\n",
            "            :caption: Output\n",
            "        \n",
            "            run_id: 45f4af3e6fd349e58579b27fcb0b8277; lifecycle_stage: deleted\n",
            "    \n",
            "    delete_tag(key: str) -> None\n",
            "        Delete a tag from a run. This is irreversible. If no run is active, this method\n",
            "        will create a new active run.\n",
            "        \n",
            "        :param key: Name of the tag\n",
            "        \n",
            "        .. code-block:: python\n",
            "            :caption: Example\n",
            "        \n",
            "            import mlflow\n",
            "        \n",
            "            tags = {\"engineering\": \"ML Platform\",\n",
            "                    \"engineering_remote\": \"ML Platform\"}\n",
            "        \n",
            "            with mlflow.start_run() as run:\n",
            "                mlflow.set_tags(tags)\n",
            "        \n",
            "            with mlflow.start_run(run_id=run.info.run_id):\n",
            "                mlflow.delete_tag(\"engineering_remote\")\n",
            "    \n",
            "    end_run(status: str = 'FINISHED') -> None\n",
            "        End an active MLflow run (if there is one).\n",
            "        \n",
            "        .. code-block:: python\n",
            "            :caption: Example\n",
            "        \n",
            "            import mlflow\n",
            "        \n",
            "            # Start run and get status\n",
            "            mlflow.start_run()\n",
            "            run = mlflow.active_run()\n",
            "            print(\"run_id: {}; status: {}\".format(run.info.run_id, run.info.status))\n",
            "        \n",
            "            # End run and get status\n",
            "            mlflow.end_run()\n",
            "            run = mlflow.get_run(run.info.run_id)\n",
            "            print(\"run_id: {}; status: {}\".format(run.info.run_id, run.info.status))\n",
            "            print(\"--\")\n",
            "        \n",
            "            # Check for any active runs\n",
            "            print(\"Active run: {}\".format(mlflow.active_run()))\n",
            "        \n",
            "        .. code-block:: text\n",
            "            :caption: Output\n",
            "        \n",
            "            run_id: b47ee4563368419880b44ad8535f6371; status: RUNNING\n",
            "            run_id: b47ee4563368419880b44ad8535f6371; status: FINISHED\n",
            "            --\n",
            "            Active run: None\n",
            "    \n",
            "    evaluate(model: Union[str, ForwardRef('mlflow.pyfunc.PyFuncModel')], data, *, targets, model_type: str, dataset_name=None, dataset_path=None, feature_names: list = None, evaluators=None, evaluator_config=None, custom_metrics=None)\n",
            "        .. Note:: Experimental: This method may change or be removed in a future release without warning.\n",
            "        \n",
            "        \n",
            "        Evaluate a PyFunc model on the specified dataset using one or more specified ``evaluators``, and\n",
            "        log resulting metrics & artifacts to MLflow Tracking. For additional overview information, see\n",
            "        :ref:`the Model Evaluation documentation <model-evaluation>`.\n",
            "        \n",
            "        Default Evaluator behavior:\n",
            "         - The default evaluator, which can be invoked with ``evaluators=\"default\"`` or\n",
            "           ``evaluators=None``, supports the ``\"regressor\"`` and ``\"classifier\"`` model types.\n",
            "           It generates a variety of model performance metrics, model performance plots, and\n",
            "           model explanations.\n",
            "        \n",
            "         - For both the ``\"regressor\"`` and ``\"classifier\"`` model types, the default evaluator\n",
            "           generates model summary plots and feature importance plots using\n",
            "           `SHAP <https://shap.readthedocs.io/en/latest/index.html>`_.\n",
            "        \n",
            "         - For regressor models, the default evaluator additionally logs:\n",
            "            - **metrics**: example_count, mean_absolute_error, mean_squared_error,\n",
            "              root_mean_squared_error, sum_on_label, mean_on_label, r2_score, max_error,\n",
            "              mean_absolute_percentage_error.\n",
            "        \n",
            "         - For binary classifiers, the default evaluator additionally logs:\n",
            "            - **metrics**: true_negatives, false_positives, false_negatives, true_positives, recall,\n",
            "              precision, f1_score, accuracy, example_count, log_loss, roc_auc, precision_recall_auc.\n",
            "            - **artifacts**: lift curve plot, precision-recall plot, ROC plot.\n",
            "        \n",
            "         - For multiclass classifiers, the default evaluator additionally logs:\n",
            "            - **metrics**: accuracy, example_count, f1_score_micro, f1_score_macro, log_loss\n",
            "            - **artifacts**: A CSV file for \"per_class_metrics\" (per-class metrics includes\n",
            "              true_negatives/false_positives/false_negatives/true_positives/recall/precision/roc_auc,\n",
            "              precision_recall_auc), precision-recall merged curves plot, ROC merged curves plot.\n",
            "        \n",
            "         - For sklearn models, the default evaluator additionally logs the model's evaluation criterion\n",
            "           (e.g. mean accuracy for a classifier) computed by `model.score` method.\n",
            "        \n",
            "         - The logged MLflow metric keys are constructed using the format:\n",
            "           ``{metric_name}_on_{dataset_name}``. Any preexisting metrics with the same name are\n",
            "           overwritten.\n",
            "        \n",
            "         - The metrics/artifacts listed above are logged to the active MLflow run.\n",
            "           If no active run exists, a new MLflow run is created for logging these metrics and\n",
            "           artifacts.\n",
            "        \n",
            "         - Additionally, information about the specified dataset - hash, name (if specified), path\n",
            "           (if specified), and the UUID of the model that evaluated it - is logged to the\n",
            "           ``mlflow.datasets`` tag.\n",
            "        \n",
            "         - The available ``evaluator_config`` options for the default evaluator include:\n",
            "            - **log_model_explainability**: A boolean value specifying whether or not to log model\n",
            "              explainability insights, default value is True.\n",
            "            - **explainability_algorithm**: A string to specify the SHAP Explainer algorithm for model\n",
            "              explainability. Supported algorithm includes: 'exact', 'permutation', 'partition',\n",
            "              'kernel'.\n",
            "              If not set, ``shap.Explainer`` is used with the \"auto\" algorithm, which chooses the best\n",
            "              Explainer based on the model.\n",
            "            - **explainability_nsamples**: The number of sample rows to use for computing model\n",
            "              explainability insights. Default value is 2000.\n",
            "            - **explainability_kernel_link**: The kernel link function used by shap kernal explainer.\n",
            "              Available values are \"identity\" and \"logit\". Default value is \"identity\".\n",
            "            - **max_classes_for_multiclass_roc_pr**:\n",
            "              For multiclass classification tasks, the maximum number of classes for which to log\n",
            "              the per-class ROC curve and Precision-Recall curve. If the number of classes is\n",
            "              larger than the configured maximum, these curves are not logged.\n",
            "        \n",
            "         - Limitations of evaluation dataset:\n",
            "            - For classification tasks, dataset labels are used to infer the total number of classes.\n",
            "            - For binary classification tasks, the negative label value must be 0 or -1 or False, and\n",
            "              the positive label value must be 1 or True.\n",
            "        \n",
            "         - Limitations of metrics/artifacts computation:\n",
            "            - For classification tasks, some metric and artifact computations require the model to\n",
            "              output class probabilities. Currently, for scikit-learn models, the default evaluator\n",
            "              calls the ``predict_proba`` method on the underlying model to obtain probabilities. For\n",
            "              other model types, the default evaluator does not compute metrics/artifacts that require\n",
            "              probability outputs.\n",
            "        \n",
            "         - Limitations of default evaluator logging model explainability insights:\n",
            "            - The ``shap.Explainer`` ``auto`` algorithm uses the ``Linear`` explainer for linear models\n",
            "              and the ``Tree`` explainer for tree models. Because SHAP's ``Linear`` and ``Tree``\n",
            "              explainers do not support multi-class classification, the default evaluator falls back to\n",
            "              using the ``Exact`` or ``Permutation`` explainers for multi-class classification tasks.\n",
            "            - Logging model explainability insights is not currently supported for PySpark models.\n",
            "            - The evaluation dataset label values must be numeric or boolean, all feature values\n",
            "              must be numeric, and each feature column must only contain scalar values.\n",
            "        \n",
            "        :param model: A pyfunc model instance, or a URI referring to such a model.\n",
            "        \n",
            "        :param data: One of the following:\n",
            "        \n",
            "                     - A numpy array or list of evaluation features, excluding labels.\n",
            "        \n",
            "                     - A Pandas DataFrame or Spark DataFrame, containing evaluation features and\n",
            "                       labels. If ``feature_names`` argument not specified, all columns are regarded\n",
            "                       as feature columns. Otherwise, only column names present in ``feature_names``\n",
            "                       are regarded as feature columns. If it is Spark DataFrame, only the first 10000\n",
            "                       rows in the Spark DataFrame will be used as evaluation data.\n",
            "        \n",
            "        :param targets: If ``data`` is a numpy array or list, a numpy array or list of evaluation\n",
            "                        labels. If ``data`` is a DataFrame, the string name of a column from ``data``\n",
            "                        that contains evaluation labels.\n",
            "        \n",
            "        :param model_type: A string describing the model type. The default evaluator\n",
            "                           supports ``\"regressor\"`` and ``\"classifier\"`` as model types.\n",
            "        \n",
            "        :param dataset_name: (Optional) The name of the dataset, must not contain double quotes (``“``).\n",
            "                             The name is logged to the ``mlflow.datasets`` tag for lineage tracking\n",
            "                             purposes. If not specified, the dataset hash is used as the dataset name.\n",
            "        \n",
            "        :param dataset_path: (Optional) The path where the data is stored. Must not contain double\n",
            "                             quotes (``“``). If specified, the path is logged to the ``mlflow.datasets``\n",
            "                             tag for lineage tracking purposes.\n",
            "        \n",
            "        :param feature_names: (Optional) If the ``data`` argument is a feature data numpy array or list,\n",
            "                              ``feature_names`` is a list of the feature names for each feature. If\n",
            "                              ``None``, then the ``feature_names`` are generated using the format\n",
            "                              ``feature_{feature_index}``. If the ``data`` argument is a Pandas\n",
            "                              DataFrame or a Spark DataFrame, ``feature_names`` is a list of the names\n",
            "                              of the feature columns in the DataFrame. If ``None``, then all columns\n",
            "                              except the label column are regarded as feature columns.\n",
            "        \n",
            "        :param evaluators: The name of the evaluator to use for model evaluation, or a list of\n",
            "                           evaluator names. If unspecified, all evaluators capable of evaluating the\n",
            "                           specified model on the specified dataset are used. The default evaluator\n",
            "                           can be referred to by the name ``\"default\"``. To see all available\n",
            "                           evaluators, call :py:func:`mlflow.models.list_evaluators`.\n",
            "        \n",
            "        :param evaluator_config: A dictionary of additional configurations to supply to the evaluator.\n",
            "                                 If multiple evaluators are specified, each configuration should be\n",
            "                                 supplied as a nested dictionary whose key is the evaluator name.\n",
            "        \n",
            "        :param custom_metrics: (Optional) A list of custom metric functions. A custom metric\n",
            "                               function is required to take in two parameters:\n",
            "        \n",
            "                               - ``Union[pandas.Dataframe, pyspark.sql.DataFrame]``: The first being a\n",
            "                                 Pandas or Spark DataFrame containing ``prediction`` and ``target``\n",
            "                                 column. The ``prediction`` column contains the predictions made by\n",
            "                                 the model. The ``target`` column contains the corresponding labels\n",
            "                                 to the predictions made on that row.\n",
            "                               - ``Dict``: The second is a dictionary containing the metrics calculated\n",
            "                                 by the default evaluator. The keys are the names of the metrics\n",
            "                                 and the values are the scalar values of the metrics. Refer to the\n",
            "                                 DefaultEvaluator behavior section for what metrics will be returned\n",
            "                                 based on the type of model (i.e. classifier or regressor).\n",
            "                               - (Optional) ``str``: the path to a temporary directory that can be used\n",
            "                                 by the custom metric function to temporarily store produced artifacts.\n",
            "                                 The directory will be deleted after the artifacts are logged.\n",
            "        \n",
            "                               A custom metric function can return in the following format:\n",
            "        \n",
            "                               - ``Dict[AnyStr, Union[int, float, np.number]``: a singular dictionary of\n",
            "                                 custom metrics, where the keys are the names of the metrics, and the\n",
            "                                 values are the scalar values of the metrics.\n",
            "                               - ``Tuple[Dict[AnyStr, Union[int,float,np.number]], Dict[AnyStr,Any]]``:\n",
            "                                 a tuple of a dict containing the custom metrics, and a dict of\n",
            "                                 artifacts, where the keys are the names of the artifacts, and the\n",
            "                                 values are objects representing the artifacts.\n",
            "        \n",
            "                               Object types that artifacts can be represented as:\n",
            "        \n",
            "                               - A string uri representing the file path to the artifact. MLflow will\n",
            "                                 infer the type of the artifact based on the file extension.\n",
            "                               - A string representation of a JSON object. This will be saved as a\n",
            "                                 .json artifact.\n",
            "                               - Pandas DataFrame. This will be resolved as a CSV artifact.\n",
            "                               - Numpy array. This will be saved as a .npy artifact.\n",
            "                               - Matplotlib Figure. This will be saved as an image artifact. Note that\n",
            "                                 ``matplotlib.pyplot.savefig`` is called behind the scene with default\n",
            "                                 configurations. To customize, either save the figure with the desired\n",
            "                                 configurations and return its file path or define customizations\n",
            "                                 through environment variables in ``matplotlib.rcParams``.\n",
            "                               - Other objects will be attempted to be pickled with the default\n",
            "                                 protocol.\n",
            "        \n",
            "                               .. code-block:: python\n",
            "                                   :caption: Custom Metric Function Boilerplate\n",
            "        \n",
            "                                   def custom_metrics_boilerplate(eval_df, builtin_metrics):\n",
            "                                       # ...\n",
            "                                       metrics: Dict[AnyStr, Union[int, float, np.number]] = some_dict\n",
            "                                       artifacts: Dict[AnyStr, Any] = some_artifact_dict\n",
            "                                       # ...\n",
            "                                       if artifacts is not None:\n",
            "                                           return metrics, artifacts\n",
            "                                       return metrics\n",
            "        \n",
            "                               .. code-block:: python\n",
            "                                   :caption: Example usage of custom metrics\n",
            "        \n",
            "                                   def squared_diff_plus_one(eval_df, builtin_metrics):\n",
            "                                       return {\n",
            "                                           \"squared_diff_plus_one\": (\n",
            "                                               np.sum(\n",
            "                                                   np.abs(\n",
            "                                                       eval_df[\"prediction\"] - eval_df[\"target\"] + 1\n",
            "                                                   ) ** 2\n",
            "                                               )\n",
            "                                           )\n",
            "                                       }\n",
            "        \n",
            "                                   def scatter_plot(eval_df, builtin_metrics, artifacts_dir):\n",
            "                                       import tempfile\n",
            "                                       plt.scatter(eval_df['prediction'], eval_df['target'])\n",
            "                                       plt.xlabel('Targets')\n",
            "                                       plt.ylabel('Predictions')\n",
            "                                       plt.title(\"Targets vs. Predictions\")\n",
            "                                       plt.savefig(os.path.join(artifacts_dir, \"example.png\"))\n",
            "                                       return {}, {\n",
            "                                           \"pred_target_scatter\": os.path.join(\n",
            "                                                artifacts_dir, \"example.png\"\n",
            "                                           )\n",
            "                                       }\n",
            "        \n",
            "                                   with mlflow.start_run():\n",
            "                                       mlflow.evaluate(\n",
            "                                           model,\n",
            "                                           data,\n",
            "                                           targets,\n",
            "                                           model_type,\n",
            "                                           dataset_name,\n",
            "                                           evaluators,\n",
            "                                           custom_metrics=[squared_diff_plus_one, scatter_plot],\n",
            "                                       )\n",
            "        \n",
            "        :return: An :py:class:`mlflow.models.EvaluationResult` instance containing\n",
            "                 evaluation results.\n",
            "    \n",
            "    get_artifact_uri(artifact_path: Union[str, NoneType] = None) -> str\n",
            "        Get the absolute URI of the specified artifact in the currently active run.\n",
            "        If `path` is not specified, the artifact root URI of the currently active\n",
            "        run will be returned; calls to ``log_artifact`` and ``log_artifacts`` write\n",
            "        artifact(s) to subdirectories of the artifact root URI.\n",
            "        \n",
            "        If no run is active, this method will create a new active run.\n",
            "        \n",
            "        :param artifact_path: The run-relative artifact path for which to obtain an absolute URI.\n",
            "                              For example, \"path/to/artifact\". If unspecified, the artifact root URI\n",
            "                              for the currently active run will be returned.\n",
            "        :return: An *absolute* URI referring to the specified artifact or the currently active run's\n",
            "                 artifact root. For example, if an artifact path is provided and the currently active\n",
            "                 run uses an S3-backed store, this may be a uri of the form\n",
            "                 ``s3://<bucket_name>/path/to/artifact/root/path/to/artifact``. If an artifact path\n",
            "                 is not provided and the currently active run uses an S3-backed store, this may be a\n",
            "                 URI of the form ``s3://<bucket_name>/path/to/artifact/root``.\n",
            "        \n",
            "        .. code-block:: python\n",
            "            :caption: Example\n",
            "        \n",
            "            import mlflow\n",
            "        \n",
            "            features = \"rooms, zipcode, median_price, school_rating, transport\"\n",
            "            with open(\"features.txt\", 'w') as f:\n",
            "                f.write(features)\n",
            "        \n",
            "            # Log the artifact in a directory \"features\" under the root artifact_uri/features\n",
            "            with mlflow.start_run():\n",
            "                mlflow.log_artifact(\"features.txt\", artifact_path=\"features\")\n",
            "        \n",
            "                # Fetch the artifact uri root directory\n",
            "                artifact_uri = mlflow.get_artifact_uri()\n",
            "                print(\"Artifact uri: {}\".format(artifact_uri))\n",
            "        \n",
            "                # Fetch a specific artifact uri\n",
            "                artifact_uri = mlflow.get_artifact_uri(artifact_path=\"features/features.txt\")\n",
            "                print(\"Artifact uri: {}\".format(artifact_uri))\n",
            "        \n",
            "        .. code-block:: text\n",
            "            :caption: Output\n",
            "        \n",
            "            Artifact uri: file:///.../0/a46a80f1c9644bd8f4e5dd5553fffce/artifacts\n",
            "            Artifact uri: file:///.../0/a46a80f1c9644bd8f4e5dd5553fffce/artifacts/features/features.txt\n",
            "    \n",
            "    get_experiment(experiment_id: str) -> mlflow.entities.experiment.Experiment\n",
            "        Retrieve an experiment by experiment_id from the backend store\n",
            "        \n",
            "        :param experiment_id: The string-ified experiment ID returned from ``create_experiment``.\n",
            "        :return: :py:class:`mlflow.entities.Experiment`\n",
            "        \n",
            "        .. code-block:: python\n",
            "            :caption: Example\n",
            "        \n",
            "            import mlflow\n",
            "        \n",
            "            experiment = mlflow.get_experiment(\"0\")\n",
            "            print(\"Name: {}\".format(experiment.name))\n",
            "            print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
            "            print(\"Tags: {}\".format(experiment.tags))\n",
            "            print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))\n",
            "        \n",
            "        .. code-block:: text\n",
            "            :caption: Output\n",
            "        \n",
            "            Name: Default\n",
            "            Artifact Location: file:///.../mlruns/0\n",
            "            Tags: {}\n",
            "            Lifecycle_stage: active\n",
            "    \n",
            "    get_experiment_by_name(name: str) -> Union[mlflow.entities.experiment.Experiment, NoneType]\n",
            "        Retrieve an experiment by experiment name from the backend store\n",
            "        \n",
            "        :param name: The case sensitive experiment name.\n",
            "        :return: An instance of :py:class:`mlflow.entities.Experiment`\n",
            "                 if an experiment with the specified name exists, otherwise None.\n",
            "        \n",
            "        .. code-block:: python\n",
            "            :caption: Example\n",
            "        \n",
            "            import mlflow\n",
            "        \n",
            "            # Case sensitive name\n",
            "            experiment = mlflow.get_experiment_by_name(\"Default\")\n",
            "            print(\"Experiment_id: {}\".format(experiment.experiment_id))\n",
            "            print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
            "            print(\"Tags: {}\".format(experiment.tags))\n",
            "            print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))\n",
            "        \n",
            "        .. code-block:: text\n",
            "            :caption: Output\n",
            "        \n",
            "            Experiment_id: 0\n",
            "            Artifact Location: file:///.../mlruns/0\n",
            "            Tags: {}\n",
            "            Lifecycle_stage: active\n",
            "    \n",
            "    get_registry_uri() -> str\n",
            "        Get the current registry URI. If none has been specified, defaults to the tracking URI.\n",
            "        \n",
            "        :return: The registry URI.\n",
            "        \n",
            "        .. code-block:: python\n",
            "            :caption: Example\n",
            "        \n",
            "            # Get the current model registry uri\n",
            "            mr_uri = mlflow.get_registry_uri()\n",
            "            print(\"Current model registry uri: {}\".format(mr_uri))\n",
            "        \n",
            "            # Get the current tracking uri\n",
            "            tracking_uri = mlflow.get_tracking_uri()\n",
            "            print(\"Current tracking uri: {}\".format(tracking_uri))\n",
            "        \n",
            "            # They should be the same\n",
            "            assert mr_uri == tracking_uri\n",
            "        \n",
            "        .. code-block:: text\n",
            "            :caption: Output\n",
            "        \n",
            "            Current model registry uri: file:///.../mlruns\n",
            "            Current tracking uri: file:///.../mlruns\n",
            "    \n",
            "    get_run(run_id: str) -> mlflow.entities.run.Run\n",
            "        Fetch the run from backend store. The resulting :py:class:`Run <mlflow.entities.Run>`\n",
            "        contains a collection of run metadata -- :py:class:`RunInfo <mlflow.entities.RunInfo>`,\n",
            "        as well as a collection of run parameters, tags, and metrics --\n",
            "        :py:class:`RunData <mlflow.entities.RunData>`. In the case where multiple metrics with the\n",
            "        same key are logged for the run, the :py:class:`RunData <mlflow.entities.RunData>` contains\n",
            "        the most recently logged value at the largest step for each metric.\n",
            "        \n",
            "        :param run_id: Unique identifier for the run.\n",
            "        \n",
            "        :return: A single :py:class:`mlflow.entities.Run` object, if the run exists. Otherwise,\n",
            "                    raises an exception.\n",
            "        \n",
            "        .. code-block:: python\n",
            "            :caption: Example\n",
            "        \n",
            "            import mlflow\n",
            "        \n",
            "            with mlflow.start_run() as run:\n",
            "                mlflow.log_param(\"p\", 0)\n",
            "        \n",
            "            run_id = run.info.run_id\n",
            "            print(\"run_id: {}; lifecycle_stage: {}\".format(run_id,\n",
            "                mlflow.get_run(run_id).info.lifecycle_stage))\n",
            "        \n",
            "        .. code-block:: text\n",
            "            :caption: Output\n",
            "        \n",
            "            run_id: 7472befefc754e388e8e922824a0cca5; lifecycle_stage: active\n",
            "    \n",
            "    get_tracking_uri() -> str\n",
            "        Get the current tracking URI. This may not correspond to the tracking URI of\n",
            "        the currently active run, since the tracking URI can be updated via ``set_tracking_uri``.\n",
            "        \n",
            "        :return: The tracking URI.\n",
            "        \n",
            "        .. code-block:: python\n",
            "            :caption: Example\n",
            "        \n",
            "            import mlflow\n",
            "        \n",
            "            # Get the current tracking uri\n",
            "            tracking_uri = mlflow.get_tracking_uri()\n",
            "            print(\"Current tracking uri: {}\".format(tracking_uri))\n",
            "        \n",
            "        .. code-block:: text\n",
            "            :caption: Output\n",
            "        \n",
            "            Current tracking uri: file:///.../mlruns\n",
            "    \n",
            "    is_tracking_uri_set()\n",
            "        Returns True if the tracking URI has been set, False otherwise.\n",
            "    \n",
            "    last_active_run() -> Union[mlflow.entities.run.Run, NoneType]\n",
            "        Gets the most recent active run.\n",
            "        \n",
            "        Examples:\n",
            "        \n",
            "        .. code-block:: python\n",
            "            :caption: To retrieve the most recent autologged run:\n",
            "        \n",
            "            import mlflow\n",
            "        \n",
            "            from sklearn.model_selection import train_test_split\n",
            "            from sklearn.datasets import load_diabetes\n",
            "            from sklearn.ensemble import RandomForestRegressor\n",
            "        \n",
            "            mlflow.autolog()\n",
            "        \n",
            "            db = load_diabetes()\n",
            "            X_train, X_test, y_train, y_test = train_test_split(db.data, db.target)\n",
            "        \n",
            "            # Create and train models.\n",
            "            rf = RandomForestRegressor(n_estimators = 100, max_depth = 6, max_features = 3)\n",
            "            rf.fit(X_train, y_train)\n",
            "        \n",
            "            # Use the model to make predictions on the test dataset.\n",
            "            predictions = rf.predict(X_test)\n",
            "            autolog_run = mlflow.last_active_run()\n",
            "        \n",
            "        .. code-block:: python\n",
            "            :caption: To get the most recently active run that ended:\n",
            "        \n",
            "            import mlflow\n",
            "        \n",
            "            mlflow.start_run()\n",
            "            mlflow.end_run()\n",
            "            run = mlflow.last_active_run()\n",
            "        \n",
            "        .. code-block:: python\n",
            "            :caption: To retrieve the currently active run:\n",
            "        \n",
            "            import mlflow\n",
            "        \n",
            "            mlflow.start_run()\n",
            "            run = mlflow.last_active_run()\n",
            "            mlflow.end_run()\n",
            "        \n",
            "        :return: The active run (this is equivalent to ``mlflow.active_run()``) if one exists.\n",
            "                 Otherwise, the last run started from the current Python process that reached\n",
            "                 a terminal status (i.e. FINISHED, FAILED, or KILLED).\n",
            "    \n",
            "    list_experiments(view_type: int = 1, max_results: Union[int, NoneType] = None) -> List[mlflow.entities.experiment.Experiment]\n",
            "        :param view_type: Qualify requested type of experiments.\n",
            "        :param max_results: If passed, specifies the maximum number of experiments desired. If not\n",
            "                            passed, all experiments will be returned.\n",
            "        :return: A list of :py:class:`Experiment <mlflow.entities.Experiment>` objects.\n",
            "    \n",
            "    list_run_infos(experiment_id: str, run_view_type: int = 1, max_results: int = 1000, order_by: Union[List[str], NoneType] = None) -> List[mlflow.entities.run_info.RunInfo]\n",
            "        Return run information for runs which belong to the experiment_id.\n",
            "        \n",
            "        :param experiment_id: The experiment id which to search\n",
            "        :param run_view_type: ACTIVE_ONLY, DELETED_ONLY, or ALL runs\n",
            "        :param max_results: Maximum number of results desired.\n",
            "        :param order_by: List of order_by clauses. Currently supported values are\n",
            "               are ``metric.key``, ``parameter.key``, ``tag.key``, ``attribute.key``.\n",
            "               For example, ``order_by=[\"tag.release ASC\", \"metric.click_rate DESC\"]``.\n",
            "        \n",
            "        :return: A list of :py:class:`RunInfo <mlflow.entities.RunInfo>` objects that satisfy the\n",
            "            search expressions.\n",
            "        \n",
            "        .. code-block:: python\n",
            "            :caption: Example\n",
            "        \n",
            "            import mlflow\n",
            "            from mlflow.entities import ViewType\n",
            "        \n",
            "            # Create two runs\n",
            "            with mlflow.start_run() as run1:\n",
            "                mlflow.log_param(\"p\", 0)\n",
            "        \n",
            "            with mlflow.start_run() as run2:\n",
            "                mlflow.log_param(\"p\", 1)\n",
            "        \n",
            "            # Delete the last run\n",
            "            mlflow.delete_run(run2.info.run_id)\n",
            "        \n",
            "            def print_run_infos(run_infos):\n",
            "                for r in run_infos:\n",
            "                    print(\"- run_id: {}, lifecycle_stage: {}\".format(r.run_id, r.lifecycle_stage))\n",
            "        \n",
            "            print(\"Active runs:\")\n",
            "            print_run_infos(mlflow.list_run_infos(\"0\", run_view_type=ViewType.ACTIVE_ONLY))\n",
            "        \n",
            "            print(\"Deleted runs:\")\n",
            "            print_run_infos(mlflow.list_run_infos(\"0\", run_view_type=ViewType.DELETED_ONLY))\n",
            "        \n",
            "            print(\"All runs:\")\n",
            "            print_run_infos(mlflow.list_run_infos(\"0\", run_view_type=ViewType.ALL))\n",
            "        \n",
            "        .. code-block:: text\n",
            "            :caption: Output\n",
            "        \n",
            "            Active runs:\n",
            "            - run_id: 4937823b730640d5bed9e3e5057a2b34, lifecycle_stage: active\n",
            "            Deleted runs:\n",
            "            - run_id: b13f1badbed842cf9975c023d23da300, lifecycle_stage: deleted\n",
            "            All runs:\n",
            "            - run_id: b13f1badbed842cf9975c023d23da300, lifecycle_stage: deleted\n",
            "            - run_id: 4937823b730640d5bed9e3e5057a2b34, lifecycle_stage: active\n",
            "    \n",
            "    log_artifact(local_path: str, artifact_path: Union[str, NoneType] = None) -> None\n",
            "        Log a local file or directory as an artifact of the currently active run. If no run is\n",
            "        active, this method will create a new active run.\n",
            "        \n",
            "        :param local_path: Path to the file to write.\n",
            "        :param artifact_path: If provided, the directory in ``artifact_uri`` to write to.\n",
            "        \n",
            "        .. code-block:: python\n",
            "            :caption: Example\n",
            "        \n",
            "            import mlflow\n",
            "        \n",
            "            # Create a features.txt artifact file\n",
            "            features = \"rooms, zipcode, median_price, school_rating, transport\"\n",
            "            with open(\"features.txt\", 'w') as f:\n",
            "                f.write(features)\n",
            "        \n",
            "            # With artifact_path=None write features.txt under\n",
            "            # root artifact_uri/artifacts directory\n",
            "            with mlflow.start_run():\n",
            "                mlflow.log_artifact(\"features.txt\")\n",
            "    \n",
            "    log_artifacts(local_dir: str, artifact_path: Union[str, NoneType] = None) -> None\n",
            "        Log all the contents of a local directory as artifacts of the run. If no run is active,\n",
            "        this method will create a new active run.\n",
            "        \n",
            "        :param local_dir: Path to the directory of files to write.\n",
            "        :param artifact_path: If provided, the directory in ``artifact_uri`` to write to.\n",
            "        \n",
            "        .. code-block:: python\n",
            "            :caption: Example\n",
            "        \n",
            "            import os\n",
            "            import mlflow\n",
            "        \n",
            "            # Create some files to preserve as artifacts\n",
            "            features = \"rooms, zipcode, median_price, school_rating, transport\"\n",
            "            data = {\"state\": \"TX\", \"Available\": 25, \"Type\": \"Detached\"}\n",
            "        \n",
            "            # Create couple of artifact files under the directory \"data\"\n",
            "            os.makedirs(\"data\", exist_ok=True)\n",
            "            with open(\"data/data.json\", 'w', encoding='utf-8') as f:\n",
            "                json.dump(data, f, indent=2)\n",
            "            with open(\"data/features.txt\", 'w') as f:\n",
            "                f.write(features)\n",
            "        \n",
            "            # Write all files in \"data\" to root artifact_uri/states\n",
            "            with mlflow.start_run():\n",
            "                mlflow.log_artifacts(\"data\", artifact_path=\"states\")\n",
            "    \n",
            "    log_dict(dictionary: Any, artifact_file: str) -> None\n",
            "        Log a JSON/YAML-serializable object (e.g. `dict`) as an artifact. The serialization\n",
            "        format (JSON or YAML) is automatically inferred from the extension of `artifact_file`.\n",
            "        If the file extension doesn't exist or match any of [\".json\", \".yml\", \".yaml\"],\n",
            "        JSON format is used.\n",
            "        \n",
            "        :param dictionary: Dictionary to log.\n",
            "        :param artifact_file: The run-relative artifact file path in posixpath format to which\n",
            "                              the dictionary is saved (e.g. \"dir/data.json\").\n",
            "        \n",
            "        .. code-block:: python\n",
            "            :caption: Example\n",
            "        \n",
            "            import mlflow\n",
            "        \n",
            "            dictionary = {\"k\": \"v\"}\n",
            "        \n",
            "            with mlflow.start_run():\n",
            "                # Log a dictionary as a JSON file under the run's root artifact directory\n",
            "                mlflow.log_dict(dictionary, \"data.json\")\n",
            "        \n",
            "                # Log a dictionary as a YAML file in a subdirectory of the run's root artifact directory\n",
            "                mlflow.log_dict(dictionary, \"dir/data.yml\")\n",
            "        \n",
            "                # If the file extension doesn't exist or match any of [\".json\", \".yaml\", \".yml\"],\n",
            "                # JSON format is used.\n",
            "                mlflow.log_dict(dictionary, \"data\")\n",
            "                mlflow.log_dict(dictionary, \"data.txt\")\n",
            "    \n",
            "    log_figure(figure: Union[ForwardRef('matplotlib.figure.Figure'), ForwardRef('plotly.graph_objects.Figure')], artifact_file: str) -> None\n",
            "        Log a figure as an artifact. The following figure objects are supported:\n",
            "        \n",
            "        - `matplotlib.figure.Figure`_\n",
            "        - `plotly.graph_objects.Figure`_\n",
            "        \n",
            "        .. _matplotlib.figure.Figure:\n",
            "            https://matplotlib.org/api/_as_gen/matplotlib.figure.Figure.html\n",
            "        \n",
            "        .. _plotly.graph_objects.Figure:\n",
            "            https://plotly.com/python-api-reference/generated/plotly.graph_objects.Figure.html\n",
            "        \n",
            "        :param figure: Figure to log.\n",
            "        :param artifact_file: The run-relative artifact file path in posixpath format to which\n",
            "                              the figure is saved (e.g. \"dir/file.png\").\n",
            "        \n",
            "        .. code-block:: python\n",
            "            :caption: Matplotlib Example\n",
            "        \n",
            "            import mlflow\n",
            "            import matplotlib.pyplot as plt\n",
            "        \n",
            "            fig, ax = plt.subplots()\n",
            "            ax.plot([0, 1], [2, 3])\n",
            "        \n",
            "            with mlflow.start_run():\n",
            "                mlflow.log_figure(fig, \"figure.png\")\n",
            "        \n",
            "        .. code-block:: python\n",
            "            :caption: Plotly Example\n",
            "        \n",
            "            import mlflow\n",
            "            from plotly import graph_objects as go\n",
            "        \n",
            "            fig = go.Figure(go.Scatter(x=[0, 1], y=[2, 3]))\n",
            "        \n",
            "            with mlflow.start_run():\n",
            "                mlflow.log_figure(fig, \"figure.html\")\n",
            "    \n",
            "    log_image(image: Union[ForwardRef('numpy.ndarray'), ForwardRef('PIL.Image.Image')], artifact_file: str) -> None\n",
            "        Log an image as an artifact. The following image objects are supported:\n",
            "        \n",
            "        - `numpy.ndarray`_\n",
            "        - `PIL.Image.Image`_\n",
            "        \n",
            "        .. _numpy.ndarray:\n",
            "            https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html\n",
            "        \n",
            "        .. _PIL.Image.Image:\n",
            "            https://pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.Image\n",
            "        \n",
            "        Numpy array support\n",
            "            - data type (( ) represents a valid value range):\n",
            "        \n",
            "                - bool\n",
            "                - integer (0 ~ 255)\n",
            "                - unsigned integer (0 ~ 255)\n",
            "                - float (0.0 ~ 1.0)\n",
            "        \n",
            "                .. warning::\n",
            "        \n",
            "                    - Out-of-range integer values will be **clipped** to [0, 255].\n",
            "                    - Out-of-range float values will be **clipped** to [0, 1].\n",
            "        \n",
            "            - shape (H: height, W: width):\n",
            "        \n",
            "                - H x W (Grayscale)\n",
            "                - H x W x 1 (Grayscale)\n",
            "                - H x W x 3 (an RGB channel order is assumed)\n",
            "                - H x W x 4 (an RGBA channel order is assumed)\n",
            "        \n",
            "        :param image: Image to log.\n",
            "        :param artifact_file: The run-relative artifact file path in posixpath format to which\n",
            "                              the image is saved (e.g. \"dir/image.png\").\n",
            "        \n",
            "        .. code-block:: python\n",
            "            :caption: Numpy Example\n",
            "        \n",
            "            import mlflow\n",
            "            import numpy as np\n",
            "        \n",
            "            image = np.random.randint(0, 256, size=(100, 100, 3), dtype=np.uint8)\n",
            "        \n",
            "            with mlflow.start_run():\n",
            "                mlflow.log_image(image, \"image.png\")\n",
            "        \n",
            "        .. code-block:: python\n",
            "            :caption: Pillow Example\n",
            "        \n",
            "            import mlflow\n",
            "            from PIL import Image\n",
            "        \n",
            "            image = Image.new(\"RGB\", (100, 100))\n",
            "        \n",
            "            with mlflow.start_run():\n",
            "                mlflow.log_image(image, \"image.png\")\n",
            "    \n",
            "    log_metric(key: str, value: float, step: Union[int, NoneType] = None) -> None\n",
            "        Log a metric under the current run. If no run is active, this method will create\n",
            "        a new active run.\n",
            "        \n",
            "        :param key: Metric name (string). This string may only contain alphanumerics, underscores (_),\n",
            "                    dashes (-), periods (.), spaces ( ), and slashes (/).\n",
            "                    All backend stores will support keys up to length 250, but some may\n",
            "                    support larger keys.\n",
            "        :param value: Metric value (float). Note that some special values such as +/- Infinity may be\n",
            "                      replaced by other values depending on the store. For example, the\n",
            "                      SQLAlchemy store replaces +/- Infinity with max / min float values.\n",
            "                      All backend stores will support values up to length 5000, but some\n",
            "                      may support larger values.\n",
            "        :param step: Metric step (int). Defaults to zero if unspecified.\n",
            "        \n",
            "        .. code-block:: python\n",
            "            :caption: Example\n",
            "        \n",
            "            import mlflow\n",
            "        \n",
            "            with mlflow.start_run():\n",
            "                mlflow.log_metric(\"mse\", 2500.00)\n",
            "    \n",
            "    log_metrics(metrics: Dict[str, float], step: Union[int, NoneType] = None) -> None\n",
            "        Log multiple metrics for the current run. If no run is active, this method will create a new\n",
            "        active run.\n",
            "        \n",
            "        :param metrics: Dictionary of metric_name: String -> value: Float. Note that some special\n",
            "                        values such as +/- Infinity may be replaced by other values depending on\n",
            "                        the store. For example, sql based store may replace +/- Infinity with\n",
            "                        max / min float values.\n",
            "        :param step: A single integer step at which to log the specified\n",
            "                     Metrics. If unspecified, each metric is logged at step zero.\n",
            "        \n",
            "        :returns: None\n",
            "        \n",
            "        .. code-block:: python\n",
            "            :caption: Example\n",
            "        \n",
            "            import mlflow\n",
            "        \n",
            "            metrics = {\"mse\": 2500.00, \"rmse\": 50.00}\n",
            "        \n",
            "            # Log a batch of metrics\n",
            "            with mlflow.start_run():\n",
            "                mlflow.log_metrics(metrics)\n",
            "    \n",
            "    log_param(key: str, value: Any) -> None\n",
            "        Log a parameter (e.g. model hyperparameter) under the current run. If no run is active,\n",
            "        this method will create a new active run.\n",
            "        \n",
            "        :param key: Parameter name (string). This string may only contain alphanumerics,\n",
            "                    underscores (_), dashes (-), periods (.), spaces ( ), and slashes (/).\n",
            "                    All backend stores support keys up to length 250, but some may\n",
            "                    support larger keys.\n",
            "        :param value: Parameter value (string, but will be string-ified if not).\n",
            "                      All backend stores support values up to length 500, but some\n",
            "                      may support larger values.\n",
            "        \n",
            "        .. code-block:: python\n",
            "            :caption: Example\n",
            "        \n",
            "            import mlflow\n",
            "        \n",
            "            with mlflow.start_run():\n",
            "                mlflow.log_param(\"learning_rate\", 0.01)\n",
            "    \n",
            "    log_params(params: Dict[str, Any]) -> None\n",
            "        Log a batch of params for the current run. If no run is active, this method will create a\n",
            "        new active run.\n",
            "        \n",
            "        :param params: Dictionary of param_name: String -> value: (String, but will be string-ified if\n",
            "                       not)\n",
            "        :returns: None\n",
            "        \n",
            "        .. code-block:: python\n",
            "            :caption: Example\n",
            "        \n",
            "            import mlflow\n",
            "        \n",
            "            params = {\"learning_rate\": 0.01, \"n_estimators\": 10}\n",
            "        \n",
            "            # Log a batch of parameters\n",
            "            with mlflow.start_run():\n",
            "                mlflow.log_params(params)\n",
            "    \n",
            "    log_text(text: str, artifact_file: str) -> None\n",
            "        Log text as an artifact.\n",
            "        \n",
            "        :param text: String containing text to log.\n",
            "        :param artifact_file: The run-relative artifact file path in posixpath format to which\n",
            "                              the text is saved (e.g. \"dir/file.txt\").\n",
            "        \n",
            "        .. code-block:: python\n",
            "            :caption: Example\n",
            "        \n",
            "            import mlflow\n",
            "        \n",
            "            with mlflow.start_run():\n",
            "                # Log text to a file under the run's root artifact directory\n",
            "                mlflow.log_text(\"text1\", \"file1.txt\")\n",
            "        \n",
            "                # Log text in a subdirectory of the run's root artifact directory\n",
            "                mlflow.log_text(\"text2\", \"dir/file2.txt\")\n",
            "        \n",
            "                # Log HTML text\n",
            "                mlflow.log_text(\"<h1>header</h1>\", \"index.html\")\n",
            "    \n",
            "    register_model(model_uri, name, await_registration_for=300, *, tags: Union[Dict[str, Any], NoneType] = None) -> mlflow.entities.model_registry.model_version.ModelVersion\n",
            "        Create a new model version in model registry for the model files specified by ``model_uri``.\n",
            "        Note that this method assumes the model registry backend URI is the same as that of the\n",
            "        tracking backend.\n",
            "        \n",
            "        :param model_uri: URI referring to the MLmodel directory. Use a ``runs:/`` URI if you want to\n",
            "                          record the run ID with the model in model registry. ``models:/`` URIs are\n",
            "                          currently not supported.\n",
            "        :param name: Name of the registered model under which to create a new model version. If a\n",
            "                     registered model with the given name does not exist, it will be created\n",
            "                     automatically.\n",
            "        :param await_registration_for: Number of seconds to wait for the model version to finish\n",
            "                                being created and is in ``READY`` status. By default, the function\n",
            "                                waits for five minutes. Specify 0 or None to skip waiting.\n",
            "        :param tags: A dictionary of key-value pairs that are converted into\n",
            "                     :py:class:`mlflow.entities.model_registry.ModelVersionTag` objects.\n",
            "        :return: Single :py:class:`mlflow.entities.model_registry.ModelVersion` object created by\n",
            "                 backend.\n",
            "        \n",
            "        .. code-block:: python\n",
            "            :caption: Example\n",
            "        \n",
            "            import mlflow.sklearn\n",
            "            from sklearn.ensemble import RandomForestRegressor\n",
            "        \n",
            "            mlflow.set_tracking_uri(\"sqlite:////tmp/mlruns.db\")\n",
            "            params = {\"n_estimators\": 3, \"random_state\": 42}\n",
            "        \n",
            "            # Log MLflow entities\n",
            "            with mlflow.start_run() as run:\n",
            "               rfr = RandomForestRegressor(**params).fit([[0, 1]], [1])\n",
            "               mlflow.log_params(params)\n",
            "               mlflow.sklearn.log_model(rfr, artifact_path=\"sklearn-model\")\n",
            "        \n",
            "            model_uri = \"runs:/{}/sklearn-model\".format(run.info.run_id)\n",
            "            mv = mlflow.register_model(model_uri, \"RandomForestRegressionModel\")\n",
            "            print(\"Name: {}\".format(mv.name))\n",
            "            print(\"Version: {}\".format(mv.version))\n",
            "        \n",
            "        .. code-block:: text\n",
            "            :caption: Output\n",
            "        \n",
            "            Name: RandomForestRegressionModel\n",
            "            Version: 1\n",
            "    \n",
            "    run(uri, entry_point='main', version=None, parameters=None, docker_args=None, experiment_name=None, experiment_id=None, backend='local', backend_config=None, use_conda=None, storage_dir=None, synchronous=True, run_id=None, run_name=None, env_manager=None)\n",
            "        Run an MLflow project. The project can be local or stored at a Git URI.\n",
            "        \n",
            "        MLflow provides built-in support for running projects locally or remotely on a Databricks or\n",
            "        Kubernetes cluster. You can also run projects against other targets by installing an appropriate\n",
            "        third-party plugin. See `Community Plugins <../plugins.html#community-plugins>`_ for more\n",
            "        information.\n",
            "        \n",
            "        For information on using this method in chained workflows, see `Building Multistep Workflows\n",
            "        <../projects.html#building-multistep-workflows>`_.\n",
            "        \n",
            "        :raises: :py:class:`mlflow.exceptions.ExecutionException` If a run launched in blocking mode\n",
            "                 is unsuccessful.\n",
            "        \n",
            "        :param uri: URI of project to run. A local filesystem path\n",
            "                    or a Git repository URI (e.g. https://github.com/mlflow/mlflow-example)\n",
            "                    pointing to a project directory containing an MLproject file.\n",
            "        :param entry_point: Entry point to run within the project. If no entry point with the specified\n",
            "                            name is found, runs the project file ``entry_point`` as a script,\n",
            "                            using \"python\" to run ``.py`` files and the default shell (specified by\n",
            "                            environment variable ``$SHELL``) to run ``.sh`` files.\n",
            "        :param version: For Git-based projects, either a commit hash or a branch name.\n",
            "        :param parameters: Parameters (dictionary) for the entry point command.\n",
            "        :param docker_args: Arguments (dictionary) for the docker command.\n",
            "        :param experiment_name: Name of experiment under which to launch the run.\n",
            "        :param experiment_id: ID of experiment under which to launch the run.\n",
            "        :param backend: Execution backend for the run: MLflow provides built-in support for \"local\",\n",
            "                        \"databricks\", and \"kubernetes\" (experimental) backends. If running against\n",
            "                        Databricks, will run against a Databricks workspace determined as follows:\n",
            "                        if a Databricks tracking URI of the form ``databricks://profile`` has been set\n",
            "                        (e.g. by setting the MLFLOW_TRACKING_URI environment variable), will run\n",
            "                        against the workspace specified by <profile>. Otherwise, runs against the\n",
            "                        workspace specified by the default Databricks CLI profile.\n",
            "        :param backend_config: A dictionary, or a path to a JSON file (must end in '.json'), which will\n",
            "                               be passed as config to the backend. The exact content which should be\n",
            "                               provided is different for each execution backend and is documented\n",
            "                               at https://www.mlflow.org/docs/latest/projects.html.\n",
            "        :param use_conda: This argument is deprecated. Use `env_manager='local'` instead.\n",
            "                          If True (the default), create a new Conda environment for the run and\n",
            "                          install project dependencies within that environment. Otherwise, run the\n",
            "                          project in the current environment without installing any project\n",
            "                          dependencies.\n",
            "        :param storage_dir: Used only if ``backend`` is \"local\". MLflow downloads artifacts from\n",
            "                            distributed URIs passed to parameters of type ``path`` to subdirectories of\n",
            "                            ``storage_dir``.\n",
            "        :param synchronous: Whether to block while waiting for a run to complete. Defaults to True.\n",
            "                            Note that if ``synchronous`` is False and ``backend`` is \"local\", this\n",
            "                            method will return, but the current process will block when exiting until\n",
            "                            the local run completes. If the current process is interrupted, any\n",
            "                            asynchronous runs launched via this method will be terminated. If\n",
            "                            ``synchronous`` is True and the run fails, the current process will\n",
            "                            error out as well.\n",
            "        :param run_id: Note: this argument is used internally by the MLflow project APIs and should\n",
            "                       not be specified. If specified, the run ID will be used instead of\n",
            "                       creating a new run.\n",
            "        :param run_name: The name to give the MLflow Run associated with the project execution.\n",
            "                         If ``None``, the MLflow Run name is left unset.\n",
            "        :param env_manager: Specify an environment manager to create a new environment for the run and\n",
            "                            install project dependencies within that environment. The following values\n",
            "                            are supported:\n",
            "        \n",
            "                            - local: use the local environment\n",
            "                            - conda: use conda\n",
            "                            - virtualenv: use virtualenv (and pyenv for Python version management)\n",
            "        \n",
            "                            If unspecified, default to conda.\n",
            "        :return: :py:class:`mlflow.projects.SubmittedRun` exposing information (e.g. run ID)\n",
            "                 about the launched run.\n",
            "        \n",
            "        .. code-block:: python\n",
            "            :caption: Example\n",
            "        \n",
            "            import mlflow\n",
            "        \n",
            "            project_uri = \"https://github.com/mlflow/mlflow-example\"\n",
            "            params = {\"alpha\": 0.5, \"l1_ratio\": 0.01}\n",
            "        \n",
            "            # Run MLflow project and create a reproducible conda environment\n",
            "            # on a local host\n",
            "            mlflow.run(project_uri, parameters=params)\n",
            "        \n",
            "        .. code-block:: text\n",
            "            :caption: Output\n",
            "        \n",
            "            ...\n",
            "            ...\n",
            "            Elasticnet model (alpha=0.500000, l1_ratio=0.010000):\n",
            "            RMSE: 0.788347345611717\n",
            "            MAE: 0.6155576449938276\n",
            "            R2: 0.19729662005412607\n",
            "            ... mlflow.projects: === Run (ID '6a5109febe5e4a549461e149590d0a7c') succeeded ===\n",
            "    \n",
            "    search_experiments(view_type: int = 1, max_results: Union[int, NoneType] = None, filter_string: Union[str, NoneType] = None, order_by: Union[List[str], NoneType] = None) -> List[mlflow.entities.experiment.Experiment]\n",
            "        .. Note:: Experimental: This method may change or be removed in a future release without warning.\n",
            "        \n",
            "        \n",
            "        Search for experiments that match the specified search query.\n",
            "        \n",
            "        :param view_type: One of enum values ``ACTIVE_ONLY``, ``DELETED_ONLY``, or ``ALL``\n",
            "                          defined in :py:class:`mlflow.entities.ViewType`.\n",
            "        :param max_results: If passed, specifies the maximum number of experiments desired. If not\n",
            "                            passed, all experiments will be returned.\n",
            "        :param filter_string:\n",
            "            Filter query string (e.g., ``\"name = 'my_experiment'\"``), defaults to searching for all\n",
            "            experiments. The following identifiers, comparators, and logical operators are supported.\n",
            "        \n",
            "            Identifiers\n",
            "              - ``name``: Experiment name.\n",
            "              - ``tags.<tag_key>``: Experiment tag. If ``tag_key`` contains\n",
            "                spaces, it must be wrapped with backticks (e.g., ``\"tags.`extra key`\"``).\n",
            "        \n",
            "            Comparators\n",
            "              - ``=``: Equal to.\n",
            "              - ``!=``: Not equal to.\n",
            "              - ``LIKE``: Case-sensitive pattern match.\n",
            "              - ``ILIKE``: Case-insensitive pattern match.\n",
            "        \n",
            "            Logical operators\n",
            "              - ``AND``: Combines two sub-queries and returns True if both of them are True.\n",
            "        \n",
            "        :param order_by:\n",
            "            List of columns to order by. The ``order_by`` column can contain an optional ``DESC`` or\n",
            "            ``ASC`` value (e.g., ``\"name DESC\"``). The default is ``ASC`` so ``\"name\"`` is equivalent to\n",
            "            ``\"name ASC\"``. The following fields are supported.\n",
            "        \n",
            "                - ``name``: Experiment name.\n",
            "                - ``experiment_id``: Experiment ID.\n",
            "        \n",
            "        :return: A list of :py:class:`Experiment <mlflow.entities.Experiment>` objects.\n",
            "        \n",
            "        .. code-block:: python\n",
            "            :caption: Example\n",
            "        \n",
            "            import mlflow\n",
            "        \n",
            "        \n",
            "            def assert_experiment_names_equal(experiments, expected_names):\n",
            "                actual_names = [e.name for e in experiments if e.name != \"Default\"]\n",
            "                assert actual_names == expected_names, (actual_names, expected_names)\n",
            "        \n",
            "        \n",
            "            mlflow.set_tracking_uri(\"sqlite:///:memory:\")\n",
            "        \n",
            "            # Create experiments\n",
            "            for name, tags in [\n",
            "                (\"a\", None),\n",
            "                (\"b\", None),\n",
            "                (\"ab\", {\"k\": \"v\"}),\n",
            "                (\"bb\", {\"k\": \"V\"}),\n",
            "            ]:\n",
            "                mlflow.create_experiment(name, tags=tags)\n",
            "        \n",
            "            # Search for experiments with name \"a\"\n",
            "            experiments = mlflow.search_experiments(filter_string=\"name = 'a'\")\n",
            "            assert_experiment_names_equal(experiments, [\"a\"])\n",
            "        \n",
            "            # Search for experiments with name starting with \"a\"\n",
            "            experiments = mlflow.search_experiments(filter_string=\"name LIKE 'a%'\")\n",
            "            assert_experiment_names_equal(experiments, [\"ab\", \"a\"])\n",
            "        \n",
            "            # Search for experiments with tag key \"k\" and value ending with \"v\" or \"V\"\n",
            "            experiments = mlflow.search_experiments(filter_string=\"tags.k ILIKE '%v'\")\n",
            "            assert_experiment_names_equal(experiments, [\"bb\", \"ab\"])\n",
            "        \n",
            "            # Search for experiments with name ending with \"b\" and tag {\"k\": \"v\"}\n",
            "            experiments = mlflow.search_experiments(filter_string=\"name LIKE '%b' AND tags.k = 'v'\")\n",
            "            assert_experiment_names_equal(experiments, [\"ab\"])\n",
            "        \n",
            "            # Sort experiments by name in ascending order\n",
            "            experiments = mlflow.search_experiments(order_by=[\"name\"])\n",
            "            assert_experiment_names_equal(experiments, [\"a\", \"ab\", \"b\", \"bb\"])\n",
            "        \n",
            "            # Sort experiments by ID in descending order\n",
            "            experiments = mlflow.search_experiments(order_by=[\"experiment_id DESC\"])\n",
            "            assert_experiment_names_equal(experiments, [\"bb\", \"ab\", \"b\", \"a\"])\n",
            "    \n",
            "    search_runs(experiment_ids: Union[List[str], NoneType] = None, filter_string: str = '', run_view_type: int = 1, max_results: int = 100000, order_by: Union[List[str], NoneType] = None, output_format: str = 'pandas', search_all_experiments: bool = False, experiment_names: Union[List[str], NoneType] = None) -> Union[List[mlflow.entities.run.Run], ForwardRef('pandas.DataFrame')]\n",
            "        Get a pandas DataFrame of runs that fit the search criteria.\n",
            "        \n",
            "        :param experiment_ids: List of experiment IDs. Search can work with experiment IDs or\n",
            "                               experiment names, but not both in the same call. Values other than\n",
            "                               ``None`` or ``[]`` will result in error if ``experiment_names`` is\n",
            "                               also not ``None`` or ``[]``. ``None`` will default to the active\n",
            "                               experiment if ``experiment_names`` is ``None`` or ``[]``.\n",
            "        :param filter_string: Filter query string, defaults to searching all runs.\n",
            "        :param run_view_type: one of enum values ``ACTIVE_ONLY``, ``DELETED_ONLY``, or ``ALL`` runs\n",
            "                                defined in :py:class:`mlflow.entities.ViewType`.\n",
            "        :param max_results: The maximum number of runs to put in the dataframe. Default is 100,000\n",
            "                            to avoid causing out-of-memory issues on the user's machine.\n",
            "        :param order_by: List of columns to order by (e.g., \"metrics.rmse\"). The ``order_by`` column\n",
            "                         can contain an optional ``DESC`` or ``ASC`` value. The default is ``ASC``.\n",
            "                         The default ordering is to sort by ``start_time DESC``, then ``run_id``.\n",
            "        :param output_format: The output format to be returned. If ``pandas``, a ``pandas.DataFrame``\n",
            "                              is returned and, if ``list``, a list of :py:class:`mlflow.entities.Run`\n",
            "                              is returned.\n",
            "        :param search_all_experiments: Boolean specifying whether all experiments should be searched.\n",
            "            Only honored if ``experiment_ids`` is ``[]`` or ``None``.\n",
            "        :param experiment_names: List of experiment names. Search can work with experiment IDs or\n",
            "                                 experiment names, but not both in the same call. Values other\n",
            "                                 than ``None`` or ``[]`` will result in error if ``experiment_ids``\n",
            "                                 is also not ``None`` or ``[]``. ``None`` will default to the active\n",
            "                                 experiment if ``experiment_ids`` is ``None`` or ``[]``.\n",
            "        :return: If output_format is ``list``: a list of :py:class:`mlflow.entities.Run`. If\n",
            "                 output_format is ``pandas``: ``pandas.DataFrame`` of runs, where each metric,\n",
            "                 parameter, and tag is expanded into its own column named metrics.*, params.*, or\n",
            "                 tags.* respectively. For runs that don't have a particular metric, parameter, or tag,\n",
            "                 the value for the corresponding column is (NumPy) ``Nan``, ``None``, or ``None``\n",
            "                 respectively.\n",
            "        \n",
            "        .. code-block:: python\n",
            "            :caption: Example\n",
            "        \n",
            "            import mlflow\n",
            "        \n",
            "            # Create an experiment and log two runs under it\n",
            "            experiment_name = \"Social NLP Experiments\"\n",
            "            experiment_id = mlflow.create_experiment(experiment_name)\n",
            "            with mlflow.start_run(experiment_id=experiment_id):\n",
            "                mlflow.log_metric(\"m\", 1.55)\n",
            "                mlflow.set_tag(\"s.release\", \"1.1.0-RC\")\n",
            "            with mlflow.start_run(experiment_id=experiment_id):\n",
            "                mlflow.log_metric(\"m\", 2.50)\n",
            "                mlflow.set_tag(\"s.release\", \"1.2.0-GA\")\n",
            "        \n",
            "            # Search for all the runs in the experiment with the given experiment ID\n",
            "            df = mlflow.search_runs([experiment_id], order_by=[\"metrics.m DESC\"])\n",
            "            print(df[[\"metrics.m\", \"tags.s.release\", \"run_id\"]])\n",
            "            print(\"--\")\n",
            "        \n",
            "            # Search the experiment_id using a filter_string with tag\n",
            "            # that has a case insensitive pattern\n",
            "            filter_string = \"tags.s.release ILIKE '%rc%'\"\n",
            "            df = mlflow.search_runs([experiment_id], filter_string=filter_string)\n",
            "            print(df[[\"metrics.m\", \"tags.s.release\", \"run_id\"]])\n",
            "            print(\"--\")\n",
            "        \n",
            "            # Search for all the runs in the experiment with the given experiment name\n",
            "            df = mlflow.search_runs(experiment_names=[experiment_name], order_by=[\"metrics.m DESC\"])\n",
            "            print(df[[\"metrics.m\", \"tags.s.release\", \"run_id\"]])\n",
            "        \n",
            "        \n",
            "        .. code-block:: text\n",
            "            :caption: Output\n",
            "        \n",
            "               metrics.m tags.s.release                            run_id\n",
            "            0       2.50       1.2.0-GA  147eed886ab44633902cc8e19b2267e2\n",
            "            1       1.55       1.1.0-RC  5cc7feaf532f496f885ad7750809c4d4\n",
            "            --\n",
            "               metrics.m tags.s.release                            run_id\n",
            "            0       1.55       1.1.0-RC  5cc7feaf532f496f885ad7750809c4d4\n",
            "            --\n",
            "               metrics.m tags.s.release                            run_id\n",
            "            0       2.50       1.2.0-GA  147eed886ab44633902cc8e19b2267e2\n",
            "            1       1.55       1.1.0-RC  5cc7feaf532f496f885ad7750809c4d4\n",
            "    \n",
            "    set_experiment(experiment_name: str = None, experiment_id: str = None) -> mlflow.entities.experiment.Experiment\n",
            "        Set the given experiment as the active experiment. The experiment must either be specified by\n",
            "        name via `experiment_name` or by ID via `experiment_id`. The experiment name and ID cannot\n",
            "        both be specified.\n",
            "        \n",
            "        :param experiment_name: Case sensitive name of the experiment to be activated. If an experiment\n",
            "                                with this name does not exist, a new experiment wth this name is\n",
            "                                created.\n",
            "        :param experiment_id: ID of the experiment to be activated. If an experiment with this ID\n",
            "                              does not exist, an exception is thrown.\n",
            "        :return: An instance of :py:class:`mlflow.entities.Experiment` representing the new active\n",
            "                 experiment.\n",
            "        \n",
            "        .. code-block:: python\n",
            "            :caption: Example\n",
            "        \n",
            "            import mlflow\n",
            "        \n",
            "            # Set an experiment name, which must be unique and case-sensitive.\n",
            "            experiment = mlflow.set_experiment(\"Social NLP Experiments\")\n",
            "        \n",
            "            # Get Experiment Details\n",
            "            print(\"Experiment_id: {}\".format(experiment.experiment_id))\n",
            "            print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
            "            print(\"Tags: {}\".format(experiment.tags))\n",
            "            print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))\n",
            "        \n",
            "        .. code-block:: text\n",
            "            :caption: Output\n",
            "        \n",
            "            Experiment_id: 1\n",
            "            Artifact Location: file:///.../mlruns/1\n",
            "            Tags: {}\n",
            "            Lifecycle_stage: active\n",
            "    \n",
            "    set_experiment_tag(key: str, value: Any) -> None\n",
            "        Set a tag on the current experiment. Value is converted to a string.\n",
            "        \n",
            "        :param key: Tag name (string). This string may only contain alphanumerics, underscores\n",
            "                    (_), dashes (-), periods (.), spaces ( ), and slashes (/).\n",
            "                    All backend stores will support keys up to length 250, but some may\n",
            "                    support larger keys.\n",
            "        :param value: Tag value (string, but will be string-ified if not).\n",
            "                      All backend stores will support values up to length 5000, but some\n",
            "                      may support larger values.\n",
            "        \n",
            "        .. code-block:: python\n",
            "            :caption: Example\n",
            "        \n",
            "            import mlflow\n",
            "        \n",
            "            with mlflow.start_run():\n",
            "               mlflow.set_experiment_tag(\"release.version\", \"2.2.0\")\n",
            "    \n",
            "    set_experiment_tags(tags: Dict[str, Any]) -> None\n",
            "        Set tags for the current active experiment.\n",
            "        \n",
            "        :param tags: Dictionary containing tag names and corresponding values.\n",
            "        \n",
            "        .. code-block:: python\n",
            "            :caption: Example\n",
            "        \n",
            "            import mlflow\n",
            "        \n",
            "            tags = {\"engineering\": \"ML Platform\",\n",
            "                    \"release.candidate\": \"RC1\",\n",
            "                    \"release.version\": \"2.2.0\"}\n",
            "        \n",
            "            # Set a batch of tags\n",
            "            with mlflow.start_run():\n",
            "                mlflow.set_experiment_tags(tags)\n",
            "    \n",
            "    set_registry_uri(uri: str) -> None\n",
            "        Set the registry server URI. This method is especially useful if you have a registry server\n",
            "        that's different from the tracking server.\n",
            "        \n",
            "        :param uri:\n",
            "        \n",
            "                    - An empty string, or a local file path, prefixed with ``file:/``. Data is stored\n",
            "                      locally at the provided file (or ``./mlruns`` if empty).\n",
            "                    - An HTTP URI like ``https://my-tracking-server:5000``.\n",
            "                    - A Databricks workspace, provided as the string \"databricks\" or, to use a\n",
            "                      Databricks CLI\n",
            "                      `profile <https://github.com/databricks/databricks-cli#installation>`_,\n",
            "                      \"databricks://<profileName>\".\n",
            "        \n",
            "        .. code-block:: python\n",
            "            :caption: Example\n",
            "        \n",
            "            import mflow\n",
            "        \n",
            "            # Set model registry uri, fetch the set uri, and compare\n",
            "            # it with the tracking uri. They should be different\n",
            "            mlflow.set_registry_uri(\"sqlite:////tmp/registry.db\")\n",
            "            mr_uri = mlflow.get_registry_uri()\n",
            "            print(\"Current registry uri: {}\".format(mr_uri))\n",
            "            tracking_uri = mlflow.get_tracking_uri()\n",
            "            print(\"Current tracking uri: {}\".format(tracking_uri))\n",
            "        \n",
            "            # They should be different\n",
            "            assert tracking_uri != mr_uri\n",
            "        \n",
            "        .. code-block:: text\n",
            "            :caption: Output\n",
            "        \n",
            "            Current registry uri: sqlite:////tmp/registry.db\n",
            "            Current tracking uri: file:///.../mlruns\n",
            "    \n",
            "    set_tag(key: str, value: Any) -> None\n",
            "        Set a tag under the current run. If no run is active, this method will create a\n",
            "        new active run.\n",
            "        \n",
            "        :param key: Tag name (string). This string may only contain alphanumerics, underscores\n",
            "                    (_), dashes (-), periods (.), spaces ( ), and slashes (/).\n",
            "                    All backend stores will support keys up to length 250, but some may\n",
            "                    support larger keys.\n",
            "        :param value: Tag value (string, but will be string-ified if not).\n",
            "                      All backend stores will support values up to length 5000, but some\n",
            "                      may support larger values.\n",
            "        \n",
            "        .. code-block:: python\n",
            "            :caption: Example\n",
            "        \n",
            "            import mlflow\n",
            "        \n",
            "            with mlflow.start_run():\n",
            "               mlflow.set_tag(\"release.version\", \"2.2.0\")\n",
            "    \n",
            "    set_tags(tags: Dict[str, Any]) -> None\n",
            "        Log a batch of tags for the current run. If no run is active, this method will create a\n",
            "        new active run.\n",
            "        \n",
            "        :param tags: Dictionary of tag_name: String -> value: (String, but will be string-ified if\n",
            "                     not)\n",
            "        :returns: None\n",
            "        \n",
            "        .. code-block:: python\n",
            "            :caption: Example\n",
            "        \n",
            "            import mlflow\n",
            "        \n",
            "            tags = {\"engineering\": \"ML Platform\",\n",
            "                    \"release.candidate\": \"RC1\",\n",
            "                    \"release.version\": \"2.2.0\"}\n",
            "        \n",
            "            # Set a batch of tags\n",
            "            with mlflow.start_run():\n",
            "                mlflow.set_tags(tags)\n",
            "    \n",
            "    set_tracking_uri(uri: Union[str, pathlib.Path]) -> None\n",
            "        Set the tracking server URI. This does not affect the\n",
            "        currently active run (if one exists), but takes effect for successive runs.\n",
            "        \n",
            "        :param uri:\n",
            "        \n",
            "                    - An empty string, or a local file path, prefixed with ``file:/``. Data is stored\n",
            "                      locally at the provided file (or ``./mlruns`` if empty).\n",
            "                    - An HTTP URI like ``https://my-tracking-server:5000``.\n",
            "                    - A Databricks workspace, provided as the string \"databricks\" or, to use a\n",
            "                      Databricks CLI\n",
            "                      `profile <https://github.com/databricks/databricks-cli#installation>`_,\n",
            "                      \"databricks://<profileName>\".\n",
            "                    - A :py:class:`pathlib.Path` instance\n",
            "        \n",
            "        .. code-block:: python\n",
            "            :caption: Example\n",
            "        \n",
            "            import mlflow\n",
            "        \n",
            "            mlflow.set_tracking_uri(\"file:///tmp/my_tracking\")\n",
            "            tracking_uri = mlflow.get_tracking_uri()\n",
            "            print(\"Current tracking uri: {}\".format(tracking_uri))\n",
            "        \n",
            "        .. code-block:: text\n",
            "            :caption: Output\n",
            "        \n",
            "            Current tracking uri: file:///tmp/my_tracking\n",
            "    \n",
            "    start_run(run_id: str = None, experiment_id: Union[str, NoneType] = None, run_name: Union[str, NoneType] = None, nested: bool = False, tags: Union[Dict[str, Any], NoneType] = None, description: Union[str, NoneType] = None) -> mlflow.tracking.fluent.ActiveRun\n",
            "        Start a new MLflow run, setting it as the active run under which metrics and parameters\n",
            "        will be logged. The return value can be used as a context manager within a ``with`` block;\n",
            "        otherwise, you must call ``end_run()`` to terminate the current run.\n",
            "        \n",
            "        If you pass a ``run_id`` or the ``MLFLOW_RUN_ID`` environment variable is set,\n",
            "        ``start_run`` attempts to resume a run with the specified run ID and\n",
            "        other parameters are ignored. ``run_id`` takes precedence over ``MLFLOW_RUN_ID``.\n",
            "        \n",
            "        If resuming an existing run, the run status is set to ``RunStatus.RUNNING``.\n",
            "        \n",
            "        MLflow sets a variety of default tags on the run, as defined in\n",
            "        :ref:`MLflow system tags <system_tags>`.\n",
            "        \n",
            "        :param run_id: If specified, get the run with the specified UUID and log parameters\n",
            "                         and metrics under that run. The run's end time is unset and its status\n",
            "                         is set to running, but the run's other attributes (``source_version``,\n",
            "                         ``source_type``, etc.) are not changed.\n",
            "        :param experiment_id: ID of the experiment under which to create the current run (applicable\n",
            "                              only when ``run_id`` is not specified). If ``experiment_id`` argument\n",
            "                              is unspecified, will look for valid experiment in the following order:\n",
            "                              activated using ``set_experiment``, ``MLFLOW_EXPERIMENT_NAME``\n",
            "                              environment variable, ``MLFLOW_EXPERIMENT_ID`` environment variable,\n",
            "                              or the default experiment as defined by the tracking server.\n",
            "        :param run_name: Name of new run (stored as a ``mlflow.runName`` tag).\n",
            "                         Used only when ``run_id`` is unspecified.\n",
            "        :param nested: Controls whether run is nested in parent run. ``True`` creates a nested run.\n",
            "        :param tags: An optional dictionary of string keys and values to set as tags on the run.\n",
            "                     If a run is being resumed, these tags are set on the resumed run. If a new run is\n",
            "                     being created, these tags are set on the new run.\n",
            "        :param description: An optional string that populates the description box of the run.\n",
            "                            If a run is being resumed, the description is set on the resumed run.\n",
            "                            If a new run is being created, the description is set on the new run.\n",
            "        :return: :py:class:`mlflow.ActiveRun` object that acts as a context manager wrapping\n",
            "                 the run's state.\n",
            "        \n",
            "        .. code-block:: python\n",
            "            :caption: Example\n",
            "        \n",
            "            import mlflow\n",
            "        \n",
            "            # Create nested runs\n",
            "            experiment_id = mlflow.create_experiment(\"experiment1\")\n",
            "            with mlflow.start_run(\n",
            "                run_name=\"PARENT_RUN\",\n",
            "                experiment_id=experiment_id,\n",
            "                tags={\"version\": \"v1\", \"priority\": \"P1\"},\n",
            "                description=\"parent\",\n",
            "            ) as parent_run:\n",
            "                mlflow.log_param(\"parent\", \"yes\")\n",
            "                with mlflow.start_run(\n",
            "                    run_name=\"CHILD_RUN\",\n",
            "                    experiment_id=experiment_id,\n",
            "                    description=\"child\",\n",
            "                    nested=True,\n",
            "                ) as child_run:\n",
            "                    mlflow.log_param(\"child\", \"yes\")\n",
            "        \n",
            "            print(\"parent run:\")\n",
            "        \n",
            "            print(\"run_id: {}\".format(parent_run.info.run_id))\n",
            "            print(\"description: {}\".format(parent_run.data.tags.get(\"mlflow.note.content\")))\n",
            "            print(\"version tag value: {}\".format(parent_run.data.tags.get(\"version\")))\n",
            "            print(\"priority tag value: {}\".format(parent_run.data.tags.get(\"priority\")))\n",
            "            print(\"--\")\n",
            "        \n",
            "            # Search all child runs with a parent id\n",
            "            query = \"tags.mlflow.parentRunId = '{}'\".format(parent_run.info.run_id)\n",
            "            results = mlflow.search_runs(experiment_ids=[experiment_id], filter_string=query)\n",
            "            print(\"child runs:\")\n",
            "            print(results[[\"run_id\", \"params.child\", \"tags.mlflow.runName\"]])\n",
            "        \n",
            "        .. code-block:: text\n",
            "            :caption: Output\n",
            "        \n",
            "            parent run:\n",
            "            run_id: 8979459433a24a52ab3be87a229a9cdf\n",
            "            description: starting a parent for experiment 7\n",
            "            version tag value: v1\n",
            "            priority tag value: P1\n",
            "            --\n",
            "            child runs:\n",
            "                                         run_id params.child tags.mlflow.runName\n",
            "            0  7d175204675e40328e46d9a6a5a7ee6a          yes           CHILD_RUN\n",
            "\n",
            "DATA\n",
            "    __all__ = ['ActiveRun', 'log_param', 'log_params', 'log_metric', 'log_...\n",
            "\n",
            "VERSION\n",
            "    1.28.0\n",
            "\n",
            "FILE\n",
            "    /usr/local/lib/python3.7/dist-packages/mlflow/__init__.py\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run(run_name=\"\"):\n",
        "    mlflow.set_experiment(\"helloWorld\")\n",
        "    \n",
        "    with mlflow.start_run() as r:\n",
        "        print(\"Running helloWorld.ipynb\")\n",
        "        print(\"Model run: \", r.info.run_uuid)\n",
        "        mlflow.set_tag(\"mlflow.runName\", run_name)\n",
        "        mlflow.log_param(\"param1\", randint(0, 100))\n",
        "\n",
        "        mlflow.log_metric(\"foo\", random())\n",
        "        mlflow.log_metric(\"foo1\", random() + 1)\n",
        "\n",
        "        mlflow.set_tag(\"run_origin\", \"jupyter_notebook\")\n",
        "\n",
        "        if not os.path.exists(\"outputs\"):\n",
        "            os.makedirs(\"outputs\")\n",
        "        with open(\"outputs/test.txt\", \"w\") as f:\n",
        "            f.write(\"hello world!\")\n",
        "\n",
        "        mlflow.log_artifacts(\"outputs\", artifact_path=\"artifact\")\n",
        "\n",
        "        mlflow.end_run()"
      ],
      "metadata": {
        "id": "OCtAJQ_Oc0IA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UxVKLZZc0Fd",
        "outputId": "ce0da257-b2be-42c6-a3f6-b009a13f92a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022/08/13 09:15:28 INFO mlflow.tracking.fluent: Experiment with name 'helloWorld' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running helloWorld.ipynb\n",
            "Model run:  49e65aff25d545f48a857a9a5d1bd38a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run(\"colabrun\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-COluBBc0C-",
        "outputId": "84f230d3-36e6-47f3-b60e-72a3a08e0b36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running helloWorld.ipynb\n",
            "Model run:  613f4b567761498a977a422f685dd8a4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kgBnygrDcz-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regression Example:"
      ],
      "metadata": {
        "id": "iGlagMqIg2P1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import ElasticNet\n",
        "import os"
      ],
      "metadata": {
        "id": "8ojjvJ9Scz7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Source: https://archive.ics.uci.edu/ml/datasets/Auto+MPG"
      ],
      "metadata": {
        "id": "8a7wrIMKhVar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# reading the dataset\n",
        "\n",
        "df = pd.read_csv('auto-mpg.data', sep='\\n', header=None)\n",
        "\n",
        "df[[0, 'car_name']] = df[0].str.split('\\t', expand=True)\n",
        "\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "t1lX8h0Wcz5E",
        "outputId": "b20c8c3b-c185-4891-db2b-b288c508b2d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   0  \\\n",
              "0  18.0   8   307.0      130.0      3504.      12...   \n",
              "1  15.0   8   350.0      165.0      3693.      11...   \n",
              "2  18.0   8   318.0      150.0      3436.      11...   \n",
              "3  16.0   8   304.0      150.0      3433.      12...   \n",
              "4  17.0   8   302.0      140.0      3449.      10...   \n",
              "\n",
              "                      car_name  \n",
              "0  \"chevrolet chevelle malibu\"  \n",
              "1          \"buick skylark 320\"  \n",
              "2         \"plymouth satellite\"  \n",
              "3              \"amc rebel sst\"  \n",
              "4                \"ford torino\"  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9203ceeb-44bf-4317-a1e8-3c3d9274fd48\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>car_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>18.0   8   307.0      130.0      3504.      12...</td>\n",
              "      <td>\"chevrolet chevelle malibu\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15.0   8   350.0      165.0      3693.      11...</td>\n",
              "      <td>\"buick skylark 320\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>18.0   8   318.0      150.0      3436.      11...</td>\n",
              "      <td>\"plymouth satellite\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16.0   8   304.0      150.0      3433.      12...</td>\n",
              "      <td>\"amc rebel sst\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17.0   8   302.0      140.0      3449.      10...</td>\n",
              "      <td>\"ford torino\"</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9203ceeb-44bf-4317-a1e8-3c3d9274fd48')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9203ceeb-44bf-4317-a1e8-3c3d9274fd48 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9203ceeb-44bf-4317-a1e8-3c3d9274fd48');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# defining column names\n",
        "columns = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year', 'origin']\n",
        "\n",
        "# refining the dataframe\n",
        "df[columns] = df[0].str.split(expand=True)\n",
        "df.drop(columns=[0], inplace=True)\n",
        "df['car_name'] = df['car_name'].apply(lambda x: x.replace('\"', ''))\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "qk-4xgvJcz2g",
        "outputId": "f6dcff57-8941-4c4c-b4bb-a6fb421f8f8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    car_name   mpg cylinders displacement horsepower weight  \\\n",
              "0  chevrolet chevelle malibu  18.0         8        307.0      130.0  3504.   \n",
              "1          buick skylark 320  15.0         8        350.0      165.0  3693.   \n",
              "2         plymouth satellite  18.0         8        318.0      150.0  3436.   \n",
              "3              amc rebel sst  16.0         8        304.0      150.0  3433.   \n",
              "4                ford torino  17.0         8        302.0      140.0  3449.   \n",
              "\n",
              "  acceleration model_year origin  \n",
              "0         12.0         70      1  \n",
              "1         11.5         70      1  \n",
              "2         11.0         70      1  \n",
              "3         12.0         70      1  \n",
              "4         10.5         70      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cae33b84-172b-4f8b-9493-98535082014c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>car_name</th>\n",
              "      <th>mpg</th>\n",
              "      <th>cylinders</th>\n",
              "      <th>displacement</th>\n",
              "      <th>horsepower</th>\n",
              "      <th>weight</th>\n",
              "      <th>acceleration</th>\n",
              "      <th>model_year</th>\n",
              "      <th>origin</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>chevrolet chevelle malibu</td>\n",
              "      <td>18.0</td>\n",
              "      <td>8</td>\n",
              "      <td>307.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>3504.</td>\n",
              "      <td>12.0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>buick skylark 320</td>\n",
              "      <td>15.0</td>\n",
              "      <td>8</td>\n",
              "      <td>350.0</td>\n",
              "      <td>165.0</td>\n",
              "      <td>3693.</td>\n",
              "      <td>11.5</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>plymouth satellite</td>\n",
              "      <td>18.0</td>\n",
              "      <td>8</td>\n",
              "      <td>318.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>3436.</td>\n",
              "      <td>11.0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>amc rebel sst</td>\n",
              "      <td>16.0</td>\n",
              "      <td>8</td>\n",
              "      <td>304.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>3433.</td>\n",
              "      <td>12.0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ford torino</td>\n",
              "      <td>17.0</td>\n",
              "      <td>8</td>\n",
              "      <td>302.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>3449.</td>\n",
              "      <td>10.5</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cae33b84-172b-4f8b-9493-98535082014c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cae33b84-172b-4f8b-9493-98535082014c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cae33b84-172b-4f8b-9493-98535082014c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# converting columns to float type\n",
        "for col in df.columns:\n",
        "    if col not in ['mpg', 'car_name']:\n",
        "        df = df[pd.to_numeric(df[col], errors='coerce').notnull()]\n",
        "        df[col] = df[col].astype(float)\n",
        "\n",
        "# seperating dependant and independant variables\n",
        "X = df[['cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year', 'origin']]\n",
        "y = df['mpg']"
      ],
      "metadata": {
        "id": "_EbgGKhAcz0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train test split\n",
        "train_X, test_X, train_y, test_y = train_test_split(X,y,random_state=0)"
      ],
      "metadata": {
        "id": "KMG_UIubczyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to evaluate model performance\n",
        "def eval_metrics(actual, pred):\n",
        "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
        "    mae = mean_absolute_error(actual, pred)\n",
        "    return rmse, mae"
      ],
      "metadata": {
        "id": "Zu0qRVFXczqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conventional Way for Model evaluation"
      ],
      "metadata": {
        "id": "YKv9xNT8jRC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "alpha, l1_ratio = 0.01, 0.15\n",
        "    \n",
        "# initiating an elastic net model\n",
        "lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n",
        "\n",
        "# fitting the model with train dataset\n",
        "lr.fit(train_X, train_y)\n",
        "\n",
        "# making predictions on test set\n",
        "y_pred = lr.predict(test_X)\n",
        "\n",
        "# obtaining the model performance\n",
        "rmse, mae = eval_metrics(test_y, y_pred)\n",
        "\n",
        "print('Hyperparameters: Alpha =  {}, L1 Ratio = {} \\n'.format(alpha, l1_ratio))\n",
        "\n",
        "print('Model Performance on test set: RMSE = {}, MAE = {} \\n'.format(rmse, mae))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JX8XgRCczn8",
        "outputId": "13d16081-e6ac-4550-c99a-7a910d73edbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hyperparameters: Alpha =  0.01, L1 Ratio = 0.15 \n",
            "\n",
            "Model Performance on test set: RMSE = 3.2640850592427535, MAE = 2.442825267353496 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alphas, l1_ratios = [0.01, 0.02, 0.5], [0.15, 0.2, 0.5]\n",
        "    \n",
        "for alpha in alphas:\n",
        "    for l1_ratio in l1_ratios:\n",
        "        # initiating an elastic net model\n",
        "        lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n",
        "\n",
        "        # fitting the model with train dataset\n",
        "        lr.fit(train_X, train_y)\n",
        "\n",
        "        # making predictions on test set\n",
        "        y_pred = lr.predict(test_X)\n",
        "\n",
        "        # obtaining the model performance\n",
        "        rmse, mae = eval_metrics(test_y, y_pred)\n",
        "\n",
        "        print('Hyperparameters: Alpha =  {}, L1 Ratio = {} \\n'.format(alpha, l1_ratio))\n",
        "\n",
        "        print('Model Performance on test set: RMSE = {}, MAE = {} \\n'.format(rmse, mae))\n",
        "        \n",
        "        print ('-'*50,'\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shnM12A-czlM",
        "outputId": "70f85b84-c57d-4951-ac27-cabae224cca4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hyperparameters: Alpha =  0.01, L1 Ratio = 0.15 \n",
            "\n",
            "Model Performance on test set: RMSE = 3.2640850592427535, MAE = 2.442825267353496 \n",
            "\n",
            "-------------------------------------------------- \n",
            "\n",
            "Hyperparameters: Alpha =  0.01, L1 Ratio = 0.2 \n",
            "\n",
            "Model Performance on test set: RMSE = 3.2641081943690287, MAE = 2.442779799335202 \n",
            "\n",
            "-------------------------------------------------- \n",
            "\n",
            "Hyperparameters: Alpha =  0.01, L1 Ratio = 0.5 \n",
            "\n",
            "Model Performance on test set: RMSE = 3.264253936304378, MAE = 2.442505372857683 \n",
            "\n",
            "-------------------------------------------------- \n",
            "\n",
            "Hyperparameters: Alpha =  0.02, L1 Ratio = 0.15 \n",
            "\n",
            "Model Performance on test set: RMSE = 3.2682306618265717, MAE = 2.4462236246381988 \n",
            "\n",
            "-------------------------------------------------- \n",
            "\n",
            "Hyperparameters: Alpha =  0.02, L1 Ratio = 0.2 \n",
            "\n",
            "Model Performance on test set: RMSE = 3.268290119727705, MAE = 2.446143110178125 \n",
            "\n",
            "-------------------------------------------------- \n",
            "\n",
            "Hyperparameters: Alpha =  0.02, L1 Ratio = 0.5 \n",
            "\n",
            "Model Performance on test set: RMSE = 3.268674967967475, MAE = 2.4456545533936804 \n",
            "\n",
            "-------------------------------------------------- \n",
            "\n",
            "Hyperparameters: Alpha =  0.5, L1 Ratio = 0.15 \n",
            "\n",
            "Model Performance on test set: RMSE = 3.393387034540801, MAE = 2.556767395061808 \n",
            "\n",
            "-------------------------------------------------- \n",
            "\n",
            "Hyperparameters: Alpha =  0.5, L1 Ratio = 0.2 \n",
            "\n",
            "Model Performance on test set: RMSE = 3.396458991035912, MAE = 2.5595987553371016 \n",
            "\n",
            "-------------------------------------------------- \n",
            "\n",
            "Hyperparameters: Alpha =  0.5, L1 Ratio = 0.5 \n",
            "\n",
            "Model Performance on test set: RMSE = 3.418455637049289, MAE = 2.5797626917276975 \n",
            "\n",
            "-------------------------------------------------- \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Track using MLFLow"
      ],
      "metadata": {
        "id": "nbMze06xjeAk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defining a new experiment\n",
        "experiment_name = 'PlainRegression'\n",
        "# returns experiment ID\n",
        "try:\n",
        "    # creating a new experiment\n",
        "    exp_id = mlflow.create_experiment(name=experiment_name)\n",
        "except Exception as e:\n",
        "    exp_id = mlflow.get_experiment_by_name(experiment_name).experiment_id"
      ],
      "metadata": {
        "id": "wqnT5fxNcziS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if 'images' not in os.listdir():\n",
        "    os.mkdir('images')\n",
        "\n",
        "with mlflow.start_run(experiment_id=exp_id):\n",
        "    \n",
        "    # simulating EDA process by creating distribution plots for all the features\n",
        "    train_X.plot(kind='box', subplots=True, layout=(2,4), figsize=(16,9), title='Box plot of each feature')\n",
        "    \n",
        "    # saving the image to images folder\n",
        "    plt.savefig('images/distribution_plot_all_features.png')\n",
        "\n",
        "    # logging artifacts -> saves the image and enables tracking for later use\n",
        "    mlflow.log_artifacts('images')\n",
        "    \n",
        "    # defining alpha and l1 ratio\n",
        "    alpha, l1_ratio = 0.02, 0.15\n",
        "    \n",
        "    # initiating an elastic net model\n",
        "    lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n",
        "\n",
        "    # fitting the model with train dataset\n",
        "    lr.fit(train_X, train_y)\n",
        "\n",
        "    # making predictions on test set\n",
        "    y_pred = lr.predict(test_X)\n",
        "\n",
        "    # obtaining the model performance\n",
        "    rmse, mae = eval_metrics(test_y, y_pred)\n",
        "    \n",
        "    # logging the parameters \n",
        "    mlflow.log_param('alpha', alpha)\n",
        "    mlflow.log_param('l1_ratio', l1_ratio)\n",
        "    \n",
        "    # logging the metrics\n",
        "    mlflow.log_metric('rmse', rmse)\n",
        "    mlflow.log_metric('mae', mae)\n",
        "    \n",
        "    # saving the model for later use\n",
        "    mlflow.sklearn.log_model(lr, \"PlainRegression_Model\")\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        },
        "id": "f_jCD-ptczfZ",
        "outputId": "1b1f16b7-8425-4ebf-8140-57fccf6818bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x648 with 8 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyper Parametr Tuning using MLFlow"
      ],
      "metadata": {
        "id": "FBXJTt6tjnTv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defining a new experiment\n",
        "experiment_name = 'PlainRegression_HyperParameter_Search'\n",
        "# returns experiment ID\n",
        "try:\n",
        "    # creating a new experiment\n",
        "    exp_id = mlflow.create_experiment(name=experiment_name)\n",
        "except Exception as e:\n",
        "    exp_id = mlflow.get_experiment_by_name(experiment_name).experiment_id"
      ],
      "metadata": {
        "id": "ccE2PQkOczVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining alpha and l1 ratio\n",
        "alphas, l1_ratios = [0.01, 0.05, 0.1, 0.02, 0.03], [0.15, 0.1, 0.2, 0.25]\n",
        "\n",
        "for alpha in alphas:\n",
        "    for l1_ratio in l1_ratios:\n",
        "        # starting an mlflow run, and tracking them under the experiment defined above\n",
        "        with mlflow.start_run(experiment_id=exp_id):\n",
        "\n",
        "            # logging artifacts -> saves the image and enables tracking for later use\n",
        "            mlflow.log_artifacts('images')\n",
        "\n",
        "            # initiating an elastic net model\n",
        "            lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n",
        "\n",
        "            # fitting the model with train dataset\n",
        "            lr.fit(train_X, train_y)\n",
        "\n",
        "            # making predictions on test set\n",
        "            y_pred = lr.predict(test_X)\n",
        "\n",
        "            # obtaining the model performance\n",
        "            rmse, mae = eval_metrics(test_y, y_pred)\n",
        "\n",
        "            # logging hyperparameters defined above\n",
        "            mlflow.log_param(\"alpha\", alpha)\n",
        "            mlflow.log_param(\"l1_ratio\", l1_ratio)\n",
        "\n",
        "            # logging performance of the model\n",
        "            mlflow.log_metric(\"rmse\", rmse)\n",
        "            mlflow.log_metric(\"mae\", mae)\n",
        "    "
      ],
      "metadata": {
        "id": "d3oFflHxjkFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-thudIoBjkCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classification example "
      ],
      "metadata": {
        "id": "acwcvMq3kEuA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import os"
      ],
      "metadata": {
        "id": "mtmoYhNyjj_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Data source: https://archive.ics.uci.edu/ml/datasets/Car+Evaluation"
      ],
      "metadata": {
        "id": "dHRUZMLukJqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reading the dataset\n",
        "df = pd.read_csv('car.data', sep='\\n', header=None)\n",
        "\n",
        "# # defining column names\n",
        "columns = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'evaluation']\n",
        "\n",
        "# # refining the dataframe\n",
        "df[columns] = df[0].str.split(',', expand=True)\n",
        "df.drop(columns=[0], inplace=True)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "0hMlXrBCjj9I",
        "outputId": "80d7bc84-1dd6-443a-f970-3798c465e556"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  buying  maint doors persons lug_boot safety evaluation\n",
              "0  vhigh  vhigh     2       2    small    low      unacc\n",
              "1  vhigh  vhigh     2       2    small    med      unacc\n",
              "2  vhigh  vhigh     2       2    small   high      unacc\n",
              "3  vhigh  vhigh     2       2      med    low      unacc\n",
              "4  vhigh  vhigh     2       2      med    med      unacc"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e24f910e-d140-4c4b-83b0-019f0a0d6c46\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>buying</th>\n",
              "      <th>maint</th>\n",
              "      <th>doors</th>\n",
              "      <th>persons</th>\n",
              "      <th>lug_boot</th>\n",
              "      <th>safety</th>\n",
              "      <th>evaluation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>vhigh</td>\n",
              "      <td>vhigh</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>small</td>\n",
              "      <td>low</td>\n",
              "      <td>unacc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>vhigh</td>\n",
              "      <td>vhigh</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>small</td>\n",
              "      <td>med</td>\n",
              "      <td>unacc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>vhigh</td>\n",
              "      <td>vhigh</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>small</td>\n",
              "      <td>high</td>\n",
              "      <td>unacc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>vhigh</td>\n",
              "      <td>vhigh</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>med</td>\n",
              "      <td>low</td>\n",
              "      <td>unacc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>vhigh</td>\n",
              "      <td>vhigh</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>med</td>\n",
              "      <td>med</td>\n",
              "      <td>unacc</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e24f910e-d140-4c4b-83b0-019f0a0d6c46')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e24f910e-d140-4c4b-83b0-019f0a0d6c46 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e24f910e-d140-4c4b-83b0-019f0a0d6c46');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# seperating dependant and independant variables\n",
        "\n",
        "X = df[['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety']]\n",
        "y = df['evaluation']"
      ],
      "metadata": {
        "id": "Dm9XiUaEjj6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train test split\n",
        "train_X, test_X, train_y, test_y = train_test_split(X,y,random_state=0)"
      ],
      "metadata": {
        "id": "WVgmSYHajj3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining a new experiment\n",
        "experiment_name = 'SimpleClassification'\n",
        "# returns experiment ID\n",
        "try:\n",
        "    # creating a new experiment\n",
        "    exp_id = mlflow.create_experiment(name=experiment_name)\n",
        "except Exception as e:\n",
        "    exp_id = mlflow.get_experiment_by_name(experiment_name).experiment_id"
      ],
      "metadata": {
        "id": "WrAhI2Yajj0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if 'data_processed' not in os.listdir():\n",
        "    os.mkdir('data_processed')\n",
        "\n",
        "# starting an mlflow run, and tracking them under the experiment defined above\n",
        "with mlflow.start_run(experiment_id=exp_id, run_name='First_Classification_Model'):\n",
        "    \n",
        "    # adding tags to the run\n",
        "    mlflow.set_tag('Description','Simple Classification Model')\n",
        "    mlflow.set_tags({'ProblemType': 'Classification', 'ModelType': 'DecisionTree', 'ModelLibrary': 'Scikit-Learn'})\n",
        "    \n",
        "    # using one hot encoder to encode the categories\n",
        "    encoder = OneHotEncoder(handle_unknown='ignore')\n",
        "    \n",
        "    X_encoded_train = encoder.fit_transform(train_X)\n",
        "    train_x_encoded = pd.DataFrame(X_encoded_train.toarray())\n",
        "    \n",
        "    X_encoded_test = encoder.transform(test_X)\n",
        "    test_x_encoded = pd.DataFrame(X_encoded_test.toarray())\n",
        "    \n",
        "    # saving a copy of the encoded data\n",
        "    train_x_encoded.to_csv('data_processed/encoded_train.csv', sep='|', index=False)\n",
        "    test_x_encoded.to_csv('data_processed/encoded_test.csv', sep='|', index=False)\n",
        "    \n",
        "    # logging artifacts -> saves the copy of the data and enables tracking for later use\n",
        "    mlflow.log_artifacts('data_processed')\n",
        "    \n",
        "    # defining alpha and l1 ratio\n",
        "    max_depth, max_features = 5, 15\n",
        "    \n",
        "    # initiating an decision tree model\n",
        "    clf = DecisionTreeClassifier(random_state=0, max_depth=5, max_features=19)\n",
        "    \n",
        "    # fitting the model with train dataset\n",
        "    clf.fit(train_x_encoded, train_y)\n",
        "    \n",
        "    # logging explaination of the model\n",
        "    # mlflow.shap.log_explanation(clf.predict_proba, train_x_encoded)\n",
        "    \n",
        "    # making predictions on test set\n",
        "    clf.predict(test_x_encoded)\n",
        "\n",
        "    # obtaining the model performance\n",
        "    accuracy = clf.score(test_x_encoded, test_y)\n",
        "    \n",
        "    # logging hyperparameters defined above\n",
        "    mlflow.log_param(\"max_depth\", max_depth)\n",
        "    mlflow.log_param(\"max_features\", max_features)\n",
        "    \n",
        "    # logging performance of the model\n",
        "    mlflow.log_metric(\"accuracy\", accuracy)\n",
        "    \n",
        "    mlflow.sklearn.log_model(clf, 'SimpleClassification_Model')\n",
        "    "
      ],
      "metadata": {
        "id": "ZhkMKdu3jjxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.classes_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNiSo86tjjuO",
        "outputId": "6f3eaf99-a139-46fb-f756-85748dbd268a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['acc', 'good', 'unacc', 'vgood'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Searching Runs using code \n"
      ],
      "metadata": {
        "id": "LgjSU8Rik6tC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-y2Lg8wUjjrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the search_runs method by default returns a dataframe of of the runs executed under a particular experiment ID\n",
        "mlflow.search_runs(['0'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "ZE8Nx_lujjn3",
        "outputId": "334fad06-bf18-4b2c-bf1e-240c757f86a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [run_id, experiment_id, status, artifact_uri, start_time, end_time]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-90280c89-e12c-4186-a62d-f1a41b9daac9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>run_id</th>\n",
              "      <th>experiment_id</th>\n",
              "      <th>status</th>\n",
              "      <th>artifact_uri</th>\n",
              "      <th>start_time</th>\n",
              "      <th>end_time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-90280c89-e12c-4186-a62d-f1a41b9daac9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-90280c89-e12c-4186-a62d-f1a41b9daac9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-90280c89-e12c-4186-a62d-f1a41b9daac9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# these runs can be queried by passing in an additional parameter\n",
        "\n",
        "search_query = 'metrics.rmse < 3.27 and metrics.mae < 2.45'\n",
        "mlflow.search_runs(['0'], search_query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "7JqKJx8ujjd9",
        "outputId": "c964a7a4-903c-4d30-c535-94438ddf53bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [run_id, experiment_id, status, artifact_uri, start_time, end_time]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e5763ede-d26e-4741-817c-2e5034b2661a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>run_id</th>\n",
              "      <th>experiment_id</th>\n",
              "      <th>status</th>\n",
              "      <th>artifact_uri</th>\n",
              "      <th>start_time</th>\n",
              "      <th>end_time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e5763ede-d26e-4741-817c-2e5034b2661a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e5763ede-d26e-4741-817c-2e5034b2661a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e5763ede-d26e-4741-817c-2e5034b2661a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print ('Run IDs with least MAE are: \\n')\n",
        "\n",
        "for run in df['run_id'][df['metrics.mae']==df['metrics.mae'].min()].values:\n",
        "    print(run, end=', ' )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "id": "WKlWsJE_lRT3",
        "outputId": "fed0a2d4-612e-4a72-c1a2-5354f1737e62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run IDs with least MAE are: \n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'run_id'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-1e14982854d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Run IDs with least MAE are: \\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mrun\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'run_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metrics.mae'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metrics.mae'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m', '\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'run_id'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the output can be read as a dataframe, which can be used for further analysis\n",
        "\n",
        "search_query = 'metrics.rmse < 3.27 and metrics.mae < 2.45'\n",
        "df = mlflow.search_runs(['0'], search_query)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "YytIDsZAlRQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Getting details of the Run"
      ],
      "metadata": {
        "id": "IXym8c6GlZAY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = mlflow.tracking.MlflowClient()"
      ],
      "metadata": {
        "id": "4M4f0bNwlRNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client.get_run('6872d876df034cd0b0b690fdbeb2d427')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "Vrio9kMelRK7",
        "outputId": "8c36bf2b-c7f2-4842-cf20-6a03306e3c2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MlflowException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-3284f9d6e583>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'6872d876df034cd0b0b690fdbeb2d427'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/mlflow/tracking/client.py\u001b[0m in \u001b[0;36mget_run\u001b[0;34m(self, run_id)\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \"\"\"\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tracking_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_metric_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mMetric\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/mlflow/tracking/_tracking_service/client.py\u001b[0m in \u001b[0;36mget_run\u001b[0;34m(self, run_id)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \"\"\"\n\u001b[1;32m     71\u001b[0m         \u001b[0m_validate_run_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_metric_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/mlflow/store/tracking/file_store.py\u001b[0m in \u001b[0;36mget_run\u001b[0;34m(self, run_id)\u001b[0m\n\u001b[1;32m    600\u001b[0m         \"\"\"\n\u001b[1;32m    601\u001b[0m         \u001b[0m_validate_run_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mrun_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_run_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_info\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             raise MlflowException(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/mlflow/store/tracking/file_store.py\u001b[0m in \u001b[0;36m_get_run_info\u001b[0;34m(self, run_uuid)\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_dir\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m             raise MlflowException(\n\u001b[0;32m--> 622\u001b[0;31m                 \u001b[0;34m\"Run '%s' not found\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mrun_uuid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatabricks_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRESOURCE_DOES_NOT_EXIST\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m             )\n\u001b[1;32m    624\u001b[0m         \u001b[0mrun_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_run_info_from_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMlflowException\u001b[0m: Run '6872d876df034cd0b0b690fdbeb2d427' not found"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Serving the model"
      ],
      "metadata": {
        "id": "p64dLzSllir3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# filling in the required details\n",
        "\n",
        "!mlflow models serve --model-uri mlruns/0/6872d876df034cd0b0b690fdbeb2d427/artifacts/PlainRegression_Model -p 5600"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdmEPpf6lRH8",
        "outputId": "da6982c3-6d1a-4c25-ddf7-8327528c683d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/mlflow\", line 8, in <module>\n",
            "    sys.exit(cli())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 829, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 782, in main\n",
            "    rv = self.invoke(ctx)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 1259, in invoke\n",
            "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 1259, in invoke\n",
            "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 1066, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 610, in invoke\n",
            "    return callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/mlflow/models/cli.py\", line 69, in serve\n",
            "    model_uri, env_manager=env_manager, workers=workers, install_mlflow=install_mlflow\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/mlflow/models/cli.py\", line 228, in _get_flavor_backend\n",
            "    append_to_uri_path(underlying_model_uri, MLMODEL_FILE_NAME), output_path=tmp.path()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/mlflow/tracking/artifact_utils.py\", line 101, in _download_artifact_from_uri\n",
            "    artifact_path=artifact_path, dst_path=output_path\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/mlflow/store/artifact/local_artifact_repo.py\", line 74, in download_artifacts\n",
            "    return super().download_artifacts(artifact_path, dst_path)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/mlflow/store/artifact/artifact_repo.py\", line 268, in download_artifacts\n",
            "    failures=failed_downloads,\n",
            "mlflow.exceptions.MlflowException: The following failures occurred while downloading one or more artifacts from mlruns/0/6872d876df034cd0b0b690fdbeb2d427/artifacts/PlainRegression_Model: {'MLmodel': \"FileNotFoundError(2, 'No such file or directory')\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dJiKxlAhlp9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CURL Command to post requests\n",
        "curl http://127.0.0.1:{port_number}/invocations -H 'Content-Type: application/json' -d '{ \"columns\": ['col1', 'col2', 'col3', 'col4', 'col5'], \"data\": [[x1, x2, x3, x4, x5], [b1, b2, b3, b4, b5]] }'"
      ],
      "metadata": {
        "id": "klrp6Jszlqhq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl http://127.0.0.1:5600/invocations -H 'Content-Type: application/json' -d '{ \"columns\": [\"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\", \"model_year\", \"origin\"], \"data\": [[8, 350.0, 165.0, 3693.0, 11.5, 70, 1]] }'"
      ],
      "metadata": {
        "id": "vzz5rONVlRE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nDqjYEW1lRCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Directly running some other code from Gith Hub - with no setup and extra effort."
      ],
      "metadata": {
        "id": "weo-9sxslzpk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using ml projects and tracking the runs as a new experiment\n",
        "\n",
        "# use set experiment method to either create a new experiment or set it as the experiment to record runs\n",
        "mlflow.set_experiment('ProjectsFileExample')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGmH47KllQ_Q",
        "outputId": "ebda1348-3e5c-444b-c175-cae7e655ba21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022/08/13 09:44:56 INFO mlflow.tracking.fluent: Experiment with name 'ProjectsFileExample' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='file:///content/mlruns/5', experiment_id='5', lifecycle_stage='active', name='ProjectsFileExample', tags={}>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "project_uri = \"https://github.com/mlflow/mlflow-example\"\n",
        "params = {\"alpha\": 0.5, \"l1_ratio\": 0.01}\n",
        "\n",
        "# Run MLflow project and create a reproducible conda environment\n",
        "# on a local host\n",
        "mlflow.run(project_uri, parameters=params) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "Eo-nXxavlQ8h",
        "outputId": "6780610a-a90e-45da-b915-f575bf7673e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022/08/13 09:46:18 INFO mlflow.projects.utils: === Fetching project from https://github.com/mlflow/mlflow-example into /tmp/tmpor9k34i2 ===\n",
            "2022/08/13 09:46:18 INFO mlflow.projects.utils: Fetched 'master' branch\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ExecutionException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/mlflow/utils/conda.py\u001b[0m in \u001b[0;36mget_or_create_conda_env\u001b[0;34m(conda_env_path, env_id, capture_output, env_root_dir)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exec_cmd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconda_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"--help\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthrow_on_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/mlflow/utils/process.py\u001b[0m in \u001b[0;36m_exec_cmd\u001b[0;34m(cmd, throw_on_error, extra_env, capture_output, synchronous, stream_output, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     )\n",
            "\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[1;32m    799\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    801\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1550\u001b[0m                             \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'conda': 'conda'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mExecutionException\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-d0446b6c7037>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Run MLflow project and create a reproducible conda environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# on a local host\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mno\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mconda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/mlflow/projects/__init__.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(uri, entry_point, version, parameters, docker_args, experiment_name, experiment_id, backend, backend_config, use_conda, storage_dir, synchronous, run_id, run_name, env_manager)\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0mstorage_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0msynchronous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronous\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0mrun_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m     )\n\u001b[1;32m    345\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msynchronous\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/mlflow/projects/__init__.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(uri, experiment_id, entry_point, version, parameters, docker_args, backend_name, backend_config, storage_dir, env_manager, synchronous, run_name)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mbackend_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0mtracking_store_uri\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                 \u001b[0mexperiment_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             )\n\u001b[1;32m    104\u001b[0m             tracking.MlflowClient().set_tag(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/mlflow/projects/backend/local.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, project_uri, entry_point, params, version, backend_config, tracking_uri, experiment_id)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMlflowClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactive_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMLFLOW_PROJECT_ENV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"conda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mcommand_separator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" && \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0mconda_env_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_or_create_conda_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_config_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m             \u001b[0mcommand_args\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mget_conda_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconda_env_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/mlflow/utils/conda.py\u001b[0m in \u001b[0;36mget_or_create_conda_env\u001b[0;34m(conda_env_path, env_id, capture_output, env_root_dir)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;34m\"You can also configure MLflow to look for a specific \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;34m\"Conda executable by setting the {1} environment variable \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m             \u001b[0;34m\"to the path of the Conda executable\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconda_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMLFLOW_CONDA_HOME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m         )\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mExecutionException\u001b[0m: Could not find Conda executable at conda. Ensure Conda is installed as per the instructions at https://conda.io/projects/conda/en/latest/user-guide/install/index.html. You can also configure MLflow to look for a specific Conda executable by setting the MLFLOW_CONDA_HOME environment variable to the path of the Conda executable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "project_uri = \"https://github.com/mlflow/mlflow-example\"\n",
        "params = {\"alpha\": 0.2, \"l1_ratio\": 0.01}\n",
        "\n",
        "# running again with different parameters\n",
        "mlflow.run(project_uri, parameters=params, experiment_name='ProjectsFileExample')"
      ],
      "metadata": {
        "id": "ZOsAqEbQlQ5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "V1oR5tUalQ2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cssu5aNOlQzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZOBTkIu4lQw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0WycrfmOlQuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GdkE0RPDlQrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "l_cp5uKklQoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gRdwzPq2lQlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4mXnwlsslQh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MiVBRudnlQey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7Us-P14LlQbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ETD_tNl1lQYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Npz5nyxtlEH3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}